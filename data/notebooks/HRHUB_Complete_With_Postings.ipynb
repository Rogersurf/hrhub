{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ HRHUB - Complete Bilateral Matching System\n",
    "\n",
    "## üéØ System Architecture:\n",
    "\n",
    "```\n",
    "Candidates (9.5K) ‚Üê‚Üí Postings (700) ‚Üê‚Üí Companies (180K)\n",
    "         ‚Üì                ‚Üì                  ‚Üì\n",
    "    Skills text    Job requirements    Enriched profiles\n",
    "         ‚Üì                ‚Üì                  ‚Üì\n",
    "    Embeddings ‚Üê‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï SAME SPACE ‚Ñù¬≥‚Å∏‚Å¥ ‚Äï‚Äï‚Äï‚Äï‚Äï‚Üí\n",
    "```\n",
    "\n",
    "## üîë Key Innovation:\n",
    "\n",
    "**Use postings to enrich company profiles** so they speak the same language as candidates!\n",
    "\n",
    "- Companies describe: \"We are in tech industry\"\n",
    "- Postings translate: \"We need Python, AWS, React\"\n",
    "- Result: Companies can match with candidates!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers plotly anthropic scikit-learn umap-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All packages ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Step 2: Load ALL Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìÇ Loading all datasets...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load candidates\n",
    "candidates = pd.read_csv('resume_data.csv')\n",
    "print(f\"‚úÖ Candidates: {len(candidates):,} rows √ó {len(candidates.columns)} columns\")\n",
    "\n",
    "# Load companies base\n",
    "companies_base = pd.read_csv('companies/companies.csv')\n",
    "print(f\"‚úÖ Companies (base): {len(companies_base):,} rows\")\n",
    "\n",
    "# Load company enrichment data\n",
    "company_industries = pd.read_csv('companies/company_industries.csv')\n",
    "print(f\"‚úÖ Company industries: {len(company_industries):,} rows\")\n",
    "\n",
    "company_specialties = pd.read_csv('companies/company_specialties.csv')\n",
    "print(f\"‚úÖ Company specialties: {len(company_specialties):,} rows\")\n",
    "\n",
    "employee_counts = pd.read_csv('companies/employee_counts.csv')\n",
    "print(f\"‚úÖ Employee counts: {len(employee_counts):,} rows\")\n",
    "\n",
    "# Load POSTINGS (THE BRIDGE!)\n",
    "postings = pd.read_csv('postings.csv', on_bad_lines='skip')\n",
    "print(f\"‚úÖ Postings: {len(postings):,} rows √ó {len(postings.columns)} columns\")\n",
    "\n",
    "# Load job-related tables\n",
    "try:\n",
    "    job_skills = pd.read_csv('jobs/job_skills.csv')\n",
    "    print(f\"‚úÖ Job skills: {len(job_skills):,} rows\")\n",
    "except:\n",
    "    job_skills = None\n",
    "    print(\"‚ö†Ô∏è  Job skills not found (optional)\")\n",
    "\n",
    "try:\n",
    "    job_industries = pd.read_csv('jobs/job_industries.csv')\n",
    "    print(f\"‚úÖ Job industries: {len(job_industries):,} rows\")\n",
    "except:\n",
    "    job_industries = None\n",
    "    print(\"‚ö†Ô∏è  Job industries not found (optional)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ All datasets loaded!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Step 3: Merge Company Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîó Merging company data...\\n\")\n",
    "\n",
    "# Aggregate industries\n",
    "company_industries_agg = company_industries.groupby('company_id')['industry_id'].apply(\n",
    "    lambda x: ', '.join(map(str, x.tolist()))\n",
    ").reset_index()\n",
    "company_industries_agg.columns = ['company_id', 'industries_list']\n",
    "print(f\"‚úÖ Aggregated industries for {len(company_industries_agg):,} companies\")\n",
    "\n",
    "# Aggregate specialties\n",
    "company_specialties_agg = company_specialties.groupby('company_id')['specialty'].apply(\n",
    "    lambda x: ' | '.join(x.astype(str).tolist())\n",
    ").reset_index()\n",
    "company_specialties_agg.columns = ['company_id', 'specialties_list']\n",
    "print(f\"‚úÖ Aggregated specialties for {len(company_specialties_agg):,} companies\")\n",
    "\n",
    "# Start with base\n",
    "companies_merged = companies_base.copy()\n",
    "\n",
    "# Merge industries\n",
    "companies_merged = companies_merged.merge(\n",
    "    company_industries_agg, \n",
    "    on='company_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge specialties\n",
    "companies_merged = companies_merged.merge(\n",
    "    company_specialties_agg, \n",
    "    on='company_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge employee counts\n",
    "companies_merged = companies_merged.merge(\n",
    "    employee_counts, \n",
    "    on='company_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Base company merge complete: {len(companies_merged):,} companies\")\n",
    "print(f\"üìä Columns: {companies_merged.columns.tolist()[:10]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåâ Step 4: Enrich Companies with Postings (THE BRIDGE!)\n",
    "\n",
    "**This is the key step!** Postings tell us what companies actually need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üåâ Enriching companies with job posting data...\\n\")\n",
    "print(\"=\" * 70)\n",
    "print(\"KEY INSIGHT: Postings contain the 'requirements language'\")\n",
    "print(\"that bridges companies and candidates!\")\n",
    "print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "# Clean postings\n",
    "postings = postings.fillna('')\n",
    "\n",
    "# Aggregate postings per company\n",
    "postings_agg = postings.groupby('company_id').agg({\n",
    "    'title': lambda x: ' | '.join(x.astype(str).tolist()[:10]),  # Top 10 job titles\n",
    "    'description': lambda x: ' '.join(x.astype(str).tolist()[:5]),  # Top 5 descriptions (truncated)\n",
    "    'skills_desc': lambda x: ' | '.join(x.dropna().astype(str).tolist()),  # All skills\n",
    "    'formatted_experience_level': lambda x: ' | '.join(x.dropna().unique().astype(str)),\n",
    "    'formatted_work_type': lambda x: ' | '.join(x.dropna().unique().astype(str))\n",
    "}).reset_index()\n",
    "\n",
    "postings_agg.columns = [\n",
    "    'company_id', \n",
    "    'posted_job_titles', \n",
    "    'posted_descriptions',\n",
    "    'required_skills',\n",
    "    'experience_levels',\n",
    "    'work_types'\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Aggregated postings for {len(postings_agg):,} companies\")\n",
    "print(f\"\\nüí° These {len(postings_agg):,} companies have explicit requirements!\\n\")\n",
    "\n",
    "# Merge postings into companies\n",
    "companies_full = companies_merged.merge(\n",
    "    postings_agg,\n",
    "    on='company_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN\n",
    "companies_full = companies_full.fillna('')\n",
    "\n",
    "print(f\"‚úÖ ENRICHED COMPANIES CREATED!\")\n",
    "print(f\"üìä Final: {len(companies_full):,} companies √ó {len(companies_full.columns)} columns\")\n",
    "print(f\"\\nüìã New columns from postings:\")\n",
    "print(f\"   - posted_job_titles\")\n",
    "print(f\"   - posted_descriptions\")\n",
    "print(f\"   - required_skills ‚Üê KEY FOR MATCHING!\")\n",
    "print(f\"   - experience_levels\")\n",
    "print(f\"   - work_types\\n\")\n",
    "\n",
    "# Show sample\n",
    "print(\"üëÄ Sample enriched company:\")\n",
    "sample_with_postings = companies_full[companies_full['required_skills'] != ''].iloc[0]\n",
    "print(f\"\\nCompany: {sample_with_postings.get('name', 'N/A')}\")\n",
    "print(f\"Industries: {str(sample_with_postings.get('industries_list', ''))[:100]}...\")\n",
    "print(f\"Required Skills: {str(sample_with_postings.get('required_skills', ''))[:100]}...\")\n",
    "print(f\"Job Titles Posted: {str(sample_with_postings.get('posted_job_titles', ''))[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Step 5: Load & Clean Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean candidates\n",
    "candidates = candidates.fillna('')\n",
    "\n",
    "print(f\"‚úÖ Candidates cleaned: {len(candidates):,} rows\")\n",
    "print(f\"üìã Columns: {candidates.columns.tolist()[:10]}...\")\n",
    "candidates.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Step 6: Create Aligned Text Representations\n",
    "\n",
    "**CRITICAL:** Both entities must use the same vocabulary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìù Creating ALIGNED text representations...\\n\")\n",
    "print(\"=\" * 70)\n",
    "print(\"ALIGNMENT STRATEGY:\")\n",
    "print(\"‚Ä¢ Candidates: Describe skills, experience, education\")\n",
    "print(\"‚Ä¢ Companies: Describe what they NEED (from postings!)\")\n",
    "print(\"‚Ä¢ Result: Both use 'skills language' ‚Üí same vector space!\")\n",
    "print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "# ========================================================================\n",
    "# CANDIDATE TEXT - Professional offering\n",
    "# ========================================================================\n",
    "def make_candidate_text(row):\n",
    "    \"\"\"\n",
    "    Candidate text focuses on:\n",
    "    - What skills I have\n",
    "    - What experience I bring\n",
    "    - What value I offer\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Professional identity\n",
    "    if row.get('career_objective'):\n",
    "        parts.append(f\"Professional seeking: {row['career_objective']}\")\n",
    "    \n",
    "    if row.get('job_position_name'):\n",
    "        parts.append(f\"Target role: {row['job_position_name']}\")\n",
    "    \n",
    "    # SKILLS (most important for matching!)\n",
    "    all_skills = []\n",
    "    if row.get('skills'): \n",
    "        all_skills.append(row['skills'])\n",
    "    if row.get('related_skills_in_job'): \n",
    "        all_skills.append(row['related_skills_in_job'])\n",
    "    if row.get('certification_skills'): \n",
    "        all_skills.append(row['certification_skills'])\n",
    "    if row.get('skills_required'):  # Skills they're looking for in jobs\n",
    "        all_skills.append(row['skills_required'])\n",
    "    \n",
    "    if all_skills:\n",
    "        parts.append(f\"Skills and expertise: {' | '.join(all_skills)}\")\n",
    "    \n",
    "    # EXPERIENCE\n",
    "    if row.get('positions'):\n",
    "        parts.append(f\"Experience in roles: {row['positions']}\")\n",
    "    \n",
    "    if row.get('professional_company_names'):\n",
    "        parts.append(f\"Companies worked at: {row['professional_company_names']}\")\n",
    "    \n",
    "    if row.get('responsibilities'):\n",
    "        resp = str(row['responsibilities'])[:250]\n",
    "        parts.append(f\"Responsibilities: {resp}\")\n",
    "    \n",
    "    # EDUCATION\n",
    "    edu_parts = []\n",
    "    if row.get('degree_names'): \n",
    "        edu_parts.append(row['degree_names'])\n",
    "    if row.get('major_field_of_studies'): \n",
    "        edu_parts.append(f\"in {row['major_field_of_studies']}\")\n",
    "    if row.get('educational_institution_name'): \n",
    "        edu_parts.append(f\"from {row['educational_institution_name']}\")\n",
    "    \n",
    "    if edu_parts:\n",
    "        parts.append(f\"Education: {' '.join(edu_parts)}\")\n",
    "    \n",
    "    # ADDITIONAL\n",
    "    if row.get('languages'):\n",
    "        parts.append(f\"Languages: {row['languages']}\")\n",
    "    \n",
    "    if row.get('certification_providers'):\n",
    "        parts.append(f\"Certifications from: {row['certification_providers']}\")\n",
    "    \n",
    "    if row.get('extra_curricular_activity_types'):\n",
    "        parts.append(f\"Activities: {row['extra_curricular_activity_types']}\")\n",
    "    \n",
    "    return ' || '.join(parts) if parts else \"Professional profile\"\n",
    "\n",
    "\n",
    "# ========================================================================\n",
    "# COMPANY TEXT - Job requirements (enriched with postings!)\n",
    "# ========================================================================\n",
    "def make_company_text(row):\n",
    "    \"\"\"\n",
    "    Company text focuses on:\n",
    "    - What skills we need (from postings!)\n",
    "    - What roles we're hiring for\n",
    "    - What our company does\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Company identity\n",
    "    if row.get('name'):\n",
    "        parts.append(f\"Company: {row['name']}\")\n",
    "    \n",
    "    # REQUIRED SKILLS (from postings - KEY!)\n",
    "    if row.get('required_skills'):\n",
    "        parts.append(f\"Looking for skills: {row['required_skills']}\")\n",
    "    \n",
    "    # JOB TITLES (from postings)\n",
    "    if row.get('posted_job_titles'):\n",
    "        parts.append(f\"Hiring for roles: {row['posted_job_titles']}\")\n",
    "    \n",
    "    # EXPERIENCE LEVELS (from postings)\n",
    "    if row.get('experience_levels'):\n",
    "        parts.append(f\"Experience levels: {row['experience_levels']}\")\n",
    "    \n",
    "    # Industries & specialties\n",
    "    if row.get('industries_list'):\n",
    "        parts.append(f\"Industries: {row['industries_list']}\")\n",
    "    \n",
    "    if row.get('specialties_list'):\n",
    "        parts.append(f\"Specialties: {row['specialties_list']}\")\n",
    "    \n",
    "    # Company description\n",
    "    if row.get('description'):\n",
    "        desc = str(row['description'])[:300]\n",
    "        parts.append(f\"About: {desc}\")\n",
    "    \n",
    "    # Posted descriptions (gives context)\n",
    "    if row.get('posted_descriptions'):\n",
    "        posted_desc = str(row['posted_descriptions'])[:200]\n",
    "        parts.append(f\"Job descriptions: {posted_desc}\")\n",
    "    \n",
    "    # Company size\n",
    "    if row.get('employee_count'):\n",
    "        parts.append(f\"Company size: {row['employee_count']} employees\")\n",
    "    \n",
    "    # Location\n",
    "    loc = []\n",
    "    if row.get('city'): loc.append(row['city'])\n",
    "    if row.get('state'): loc.append(row['state'])\n",
    "    if row.get('country'): loc.append(row['country'])\n",
    "    if loc:\n",
    "        parts.append(f\"Location: {', '.join(loc)}\")\n",
    "    \n",
    "    # Work types\n",
    "    if row.get('work_types'):\n",
    "        parts.append(f\"Work arrangement: {row['work_types']}\")\n",
    "    \n",
    "    return ' || '.join(parts) if parts else \"Company profile\"\n",
    "\n",
    "\n",
    "# ========================================================================\n",
    "# APPLY TO DATAFRAMES\n",
    "# ========================================================================\n",
    "print(\"üîÑ Generating candidate texts...\")\n",
    "candidates['text'] = candidates.apply(make_candidate_text, axis=1)\n",
    "\n",
    "print(\"üîÑ Generating company texts...\")\n",
    "companies_full['text'] = companies_full.apply(make_company_text, axis=1)\n",
    "\n",
    "print(\"\\n‚úÖ ALIGNED texts created!\\n\")\n",
    "\n",
    "# Compare vocabularies\n",
    "print(\"=\" * 70)\n",
    "print(\"CANDIDATE SAMPLE:\")\n",
    "print(candidates['text'].iloc[0][:500])\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPANY SAMPLE (with postings data):\")\n",
    "# Find company with postings\n",
    "company_with_postings = companies_full[companies_full['required_skills'] != ''].iloc[0]\n",
    "print(company_with_postings['text'][:500])\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüí° Notice: Both now use SKILLS LANGUAGE!\")\n",
    "print(\"   Candidate: 'Skills and expertise: Python, Java'\")\n",
    "print(\"   Company: 'Looking for skills: Python, AWS'\")\n",
    "print(\"   ‚Üí They can now be compared in the same space!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Step 7: Generate Embeddings (‚Ñù¬≥‚Å∏‚Å¥)\n",
    "\n",
    "Transform aligned text ‚Üí vectors in same mathematical space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß† Loading embedding model...\\n\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "embedding_dim = model.get_sentence_embedding_dimension()\n",
    "print(f\"‚úÖ Model loaded! Embedding dimension: ‚Ñù^{embedding_dim}\\n\")\n",
    "\n",
    "print(\"üîÑ Generating candidate vectors...\")\n",
    "print(f\"   ({len(candidates):,} candidates √ó ~2-3 minutes)\\n\")\n",
    "cand_vectors = model.encode(\n",
    "    candidates['text'].tolist(), \n",
    "    show_progress_bar=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"\\nüîÑ Generating company vectors...\")\n",
    "print(f\"   ({len(companies_full):,} companies √ó ~15-20 minutes)\\n\")\n",
    "comp_vectors = model.encode(\n",
    "    companies_full['text'].tolist(), \n",
    "    show_progress_bar=True,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ VECTORS CREATED IN SAME SPACE!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"üìä Candidate vectors: {cand_vectors.shape}\")\n",
    "print(f\"üìä Company vectors: {comp_vectors.shape}\")\n",
    "print(f\"\\nüéØ Both live in ‚Ñù^{embedding_dim}!\")\n",
    "print(f\"üéØ Now companies with 'Python' requirements will be\")\n",
    "print(f\"   CLOSE to candidates with 'Python' skills!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 8: Matching Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def find_top_matches(candidate_idx, top_k=10):\n",
    "    \"\"\"\n",
    "    Find top K company matches for a candidate.\n",
    "    \n",
    "    Returns: List of (company_idx, similarity_score)\n",
    "    \"\"\"\n",
    "    cand_vec = cand_vectors[candidate_idx]\n",
    "    \n",
    "    scores = []\n",
    "    for i, comp_vec in enumerate(comp_vectors):\n",
    "        score = cosine_similarity(cand_vec, comp_vec)\n",
    "        scores.append((i, score))\n",
    "    \n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scores[:top_k]\n",
    "\n",
    "print(\"‚úÖ Matching engine ready!\")\n",
    "print(f\"üìä Can match {len(candidates):,} candidates with {len(companies_full):,} companies\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 9: Test Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Finding top 10 matches for Candidate #0...\\n\")\n",
    "\n",
    "matches = find_top_matches(0, top_k=10)\n",
    "\n",
    "print(\"üéØ Top 10 Company Matches:\\n\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"{'Rank':<6} {'Score':<8} {'Company':<35} {'Skills Needed':<40}\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "for rank, (comp_idx, score) in enumerate(matches, 1):\n",
    "    company = companies_full.iloc[comp_idx]\n",
    "    name = company.get('name', 'N/A')[:33]\n",
    "    skills = company.get('required_skills', 'N/A')[:38]\n",
    "    print(f\"{rank:<6} {score:.4f}   {name:<35} {skills}\")\n",
    "\n",
    "print(\"=\" * 90)\n",
    "\n",
    "print(\"\\nüí° If scores are good (>0.5), the alignment worked!\")\n",
    "print(\"   High scores = Company needs match candidate skills\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 10: Visualize Vector Space\n",
    "\n",
    "See where candidates and companies live in ‚Ñù¬≥‚Å∏‚Å¥ (projected to ‚Ñù¬≤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üé® VECTOR SPACE VISUALIZATION\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Sample for visualization\n",
    "n_cand_viz = min(500, len(candidates))\n",
    "n_comp_viz = min(2000, len(companies_full))\n",
    "\n",
    "print(f\"üìä Visualizing:\")\n",
    "print(f\"   ‚Ä¢ {n_cand_viz} candidates\")\n",
    "print(f\"   ‚Ä¢ {n_comp_viz} companies\")\n",
    "print(f\"   ‚Ä¢ From ‚Ñù^{embedding_dim} ‚Üí ‚Ñù¬≤ (t-SNE projection)\\n\")\n",
    "\n",
    "# Sample vectors\n",
    "cand_sample = cand_vectors[:n_cand_viz]\n",
    "comp_sample = comp_vectors[:n_comp_viz]\n",
    "\n",
    "# Combine\n",
    "all_vectors = np.vstack([cand_sample, comp_sample])\n",
    "\n",
    "print(\"üîÑ Running t-SNE (2-3 minutes)...\")\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=30,\n",
    "    random_state=42,\n",
    "    n_iter=1000,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "vectors_2d = tsne.fit_transform(all_vectors)\n",
    "\n",
    "# Split\n",
    "cand_2d = vectors_2d[:n_cand_viz]\n",
    "comp_2d = vectors_2d[n_cand_viz:]\n",
    "\n",
    "print(\"\\n‚úÖ t-SNE complete!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Companies (red)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=comp_2d[:, 0],\n",
    "    y=comp_2d[:, 1],\n",
    "    mode='markers',\n",
    "    name='Companies',\n",
    "    marker=dict(\n",
    "        size=6,\n",
    "        color='#ff6b6b',\n",
    "        opacity=0.6\n",
    "    ),\n",
    "    text=[f\"Company {i}: {companies_full.iloc[i].get('name', 'N/A')[:30]}\" \n",
    "          for i in range(n_comp_viz)],\n",
    "    hovertemplate='<b>%{text}</b><extra></extra>'\n",
    "))\n",
    "\n",
    "# Candidates (green)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=cand_2d[:, 0],\n",
    "    y=cand_2d[:, 1],\n",
    "    mode='markers',\n",
    "    name='Candidates',\n",
    "    marker=dict(\n",
    "        size=10,\n",
    "        color='#00ff00',\n",
    "        opacity=0.8,\n",
    "        line=dict(width=1, color='white')\n",
    "    ),\n",
    "    text=[f\"Candidate {i}\" for i in range(n_cand_viz)],\n",
    "    hovertemplate='<b>%{text}</b><extra></extra>'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Vector Space: Candidates & Companies (with Postings Enrichment)',\n",
    "    xaxis_title='Dimension 1',\n",
    "    yaxis_title='Dimension 2',\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    plot_bgcolor='#1a1a1a',\n",
    "    paper_bgcolor='#0d0d0d',\n",
    "    font=dict(color='white')\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úÖ Visualization complete!\\n\")\n",
    "print(\"üí° KEY OBSERVATIONS:\")\n",
    "print(\"   ‚Ä¢ Green = Candidates | Red = Companies\")\n",
    "print(\"   ‚Ä¢ If they OVERLAP ‚Üí Good! Alignment worked!\")\n",
    "print(\"   ‚Ä¢ If still separated ‚Üí Need more postings data\")\n",
    "print(\"   ‚Ä¢ Clusters = Similar skill profiles grouped\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 11: Highlight Specific Candidate + Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_candidate = 0\n",
    "\n",
    "print(f\"üîç Analyzing Candidate #{target_candidate}...\\n\")\n",
    "\n",
    "matches = find_top_matches(target_candidate, top_k=10)\n",
    "match_indices = [comp_idx for comp_idx, score in matches if comp_idx < n_comp_viz]\n",
    "\n",
    "# Create highlighted plot\n",
    "fig2 = go.Figure()\n",
    "\n",
    "# All companies (background)\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=comp_2d[:, 0],\n",
    "    y=comp_2d[:, 1],\n",
    "    mode='markers',\n",
    "    name='All Companies',\n",
    "    marker=dict(size=4, color='#ff6b6b', opacity=0.3),\n",
    "    showlegend=True\n",
    "))\n",
    "\n",
    "# Top matches (highlighted)\n",
    "if match_indices:\n",
    "    match_positions = comp_2d[match_indices]\n",
    "    fig2.add_trace(go.Scatter(\n",
    "        x=match_positions[:, 0],\n",
    "        y=match_positions[:, 1],\n",
    "        mode='markers',\n",
    "        name='Top Matches',\n",
    "        marker=dict(\n",
    "            size=15,\n",
    "            color='#ff0000',\n",
    "            line=dict(width=2, color='white')\n",
    "        ),\n",
    "        text=[f\"Match #{i+1}: {companies_full.iloc[match_indices[i]].get('name', 'N/A')[:30]}<br>Score: {matches[i][1]:.3f}\" \n",
    "              for i in range(len(match_indices))],\n",
    "        hovertemplate='<b>%{text}</b><extra></extra>'\n",
    "    ))\n",
    "\n",
    "# Target candidate\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=[cand_2d[target_candidate, 0]],\n",
    "    y=[cand_2d[target_candidate, 1]],\n",
    "    mode='markers',\n",
    "    name=f'Candidate #{target_candidate}',\n",
    "    marker=dict(\n",
    "        size=25,\n",
    "        color='#00ff00',\n",
    "        symbol='star',\n",
    "        line=dict(width=3, color='white')\n",
    "    )\n",
    "))\n",
    "\n",
    "# Connection lines\n",
    "for i, match_idx in enumerate(match_indices[:5]):\n",
    "    fig2.add_trace(go.Scatter(\n",
    "        x=[cand_2d[target_candidate, 0], comp_2d[match_idx, 0]],\n",
    "        y=[cand_2d[target_candidate, 1], comp_2d[match_idx, 1]],\n",
    "        mode='lines',\n",
    "        line=dict(color='yellow', width=1, dash='dot'),\n",
    "        opacity=0.5,\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "fig2.update_layout(\n",
    "    title=f'Candidate #{target_candidate} and Top Matches',\n",
    "    xaxis_title='Dimension 1',\n",
    "    yaxis_title='Dimension 2',\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    plot_bgcolor='#1a1a1a',\n",
    "    paper_bgcolor='#0d0d0d',\n",
    "    font=dict(color='white')\n",
    ")\n",
    "\n",
    "fig2.show()\n",
    "\n",
    "print(\"‚úÖ Highlighted visualization created!\")\n",
    "print(f\"   ‚≠ê Green star = Candidate #{target_candidate}\")\n",
    "print(f\"   üî¥ Red dots = Top matches\")\n",
    "print(f\"   üíõ Yellow lines = Connections in vector space\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 12: Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate matches for sample\n",
    "results = []\n",
    "export_sample = min(500, len(candidates))\n",
    "\n",
    "print(f\"üíæ Generating matches for {export_sample} candidates...\\n\")\n",
    "\n",
    "for i in range(export_sample):\n",
    "    if i % 50 == 0:\n",
    "        print(f\"   Progress: {i}/{export_sample}\")\n",
    "    \n",
    "    matches = find_top_matches(i, top_k=10)\n",
    "    \n",
    "    for rank, (comp_idx, score) in enumerate(matches, 1):\n",
    "        company = companies_full.iloc[comp_idx]\n",
    "        results.append({\n",
    "            'candidate_id': i,\n",
    "            'company_id': company.get('company_id'),\n",
    "            'company_name': company.get('name', 'N/A'),\n",
    "            'rank': rank,\n",
    "            'similarity_score': float(score),\n",
    "            'required_skills': company.get('required_skills', 'N/A')[:100],\n",
    "            'posted_jobs': company.get('posted_job_titles', 'N/A')[:100]\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('hrhub_matches_with_postings.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Exported {len(results_df):,} matches!\")\n",
    "print(f\"üìÑ File: hrhub_matches_with_postings.csv\\n\")\n",
    "results_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ COMPLETE!\n",
    "\n",
    "### ‚úÖ What you have:\n",
    "\n",
    "1. **Enriched companies** with job posting data (requirements, skills needed)\n",
    "2. **Aligned text representations** (both use \"skills language\")\n",
    "3. **Vectors in same space** ‚Ñù¬≥‚Å∏‚Å¥\n",
    "4. **Cosine similarity matching**\n",
    "5. **Vector space visualization**\n",
    "6. **Exported results**\n",
    "\n",
    "### üöÄ Next steps:\n",
    "\n",
    "1. **Train LLM on patterns:** \"Company in industry X historically needs skills Y\"\n",
    "2. **Predict for companies without postings:** Use learned patterns\n",
    "3. **Add weights:** Let users tune dimension importance\n",
    "4. **Build UI:** Interactive matching interface\n",
    "5. **LLM explanations:** Why these matches make sense\n",
    "\n",
    "### üí° Key insight achieved:\n",
    "\n",
    "**Postings bridge the gap!** They translate \"what companies are\" into \"what companies need\" - the same language candidates speak!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
