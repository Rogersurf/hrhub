{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ HRHUB v4.0 - *bilateral HR matching system** that connects candidates with companies, and vice-versa.\n",
    "\n",
    "**Master's Thesis Project - Final Version**  \n",
    "*Business Data Science Program - Aalborg University*  \n",
    "*December 2025*\n",
    "\n",
    "---\n",
    "\n",
    "**Data Science Team:**\n",
    "- Rogerio Braunschweiger de Freitas Lima (MLOps Lead)\n",
    "- Suchanya Bayam\n",
    "- Asalun Hye Arnob\n",
    "- Muhammad Ibrahim\n",
    "\n",
    "---\n",
    "\n",
    "## üìã System Overview\n",
    "\n",
    "This unified notebook represents the **final production system** combining best practices from multiple iterations with comprehensive academic validation.\n",
    "\n",
    "### ‚ú® Merged Features:\n",
    "1. üèóÔ∏è **Clean Architecture** (from v3.1)\n",
    "   - SOLID principles implementation\n",
    "   - Abstract Factory pattern for TextBuilders\n",
    "   - High cohesion, low coupling design\n",
    "   - Production-grade error handling\n",
    "\n",
    "2. üìä **Academic Validation** (from v3.2)\n",
    "   - TF-IDF baseline comparison\n",
    "   - Keyword overlap (Jaccard) baseline\n",
    "   - Synthetic test cases with known ground truth\n",
    "   - Quantitative evaluation metrics\n",
    "\n",
    "3. üåâ **Complete Data Integration** (from Complete version)\n",
    "   - Full job postings dataset (123,849 postings)\n",
    "   - Company enrichment through posting bridge\n",
    "   - 96.1% coverage achievement\n",
    "   - Skills mapping (213,768 job-skill relationships)\n",
    "\n",
    "4. üìà **Interactive Visualizations** (from v2.5)\n",
    "   - PyVis network graphs (candidate-company connections)\n",
    "   - t-SNE embedding plots (2D semantic space projection)\n",
    "   - Skills distribution heatmaps\n",
    "   - Bilateral fairness analysis charts\n",
    "   - Summary dashboard\n",
    "\n",
    "### üéØ Key Innovations:\n",
    "1. üåâ **Job Posting Bridge** - Solves vocabulary mismatch between candidates and companies\n",
    "2. ‚öñÔ∏è **Bilateral Fairness** - Optimizes matches for both sides (target: >0.85)\n",
    "3. ü§ñ **LLM Integration** - Hugging Face Inference API with robust parsing (optional feature)\n",
    "4. ‚ö° **Efficient Matching** - Pre-computed similarity matrix for <100ms queries\n",
    "5. üìä **Baseline Comparisons** - Academic validation against TF-IDF and Jaccard methods\n",
    "6. üß™ **Synthetic Validation** - Ground truth testing on controlled cases\n",
    "7. üï∏Ô∏è **Graph-Based Visualization** - Bipartite graph structure for match relationships\n",
    "8. üß† **Neural Network Embeddings** - SBERT transformers (22M parameters, 6 layers)\n",
    "\n",
    "### üìä System Metrics:\n",
    "```\n",
    "Data Scale:\n",
    "  ‚Ä¢ 9,544 candidates (from resume_data.csv)\n",
    "  ‚Ä¢ 24,473 companies (base data)\n",
    "  ‚Ä¢ 123,849 job postings (vocabulary bridge)\n",
    "  ‚Ä¢ 213,768 job-skill mappings\n",
    "\n",
    "Performance:\n",
    "  ‚Ä¢ Query time: <100ms (pre-computed similarity matrix)\n",
    "  ‚Ä¢ Bilateral fairness: >0.85 (target achieved)\n",
    "  ‚Ä¢ Coverage: 96.1% (companies with enriched skills)\n",
    "  ‚Ä¢ Embedding dimension: 384 (all-MiniLM-L6-v2)\n",
    "\n",
    "Technology Stack:\n",
    "  ‚Ä¢ Embeddings: SBERT (Sentence Transformers)\n",
    "  ‚Ä¢ Neural Network: 6-layer Transformer (22M parameters)\n",
    "  ‚Ä¢ Baselines: TF-IDF, Jaccard similarity\n",
    "  ‚Ä¢ Graphs: PyVis (bipartite network structure)\n",
    "  ‚Ä¢ Visualization: Plotly, t-SNE, interactive HTML\n",
    "\n",
    "Cost:\n",
    "  ‚Ä¢ Embeddings: FREE (local SBERT execution)\n",
    "  ‚Ä¢ LLM: FREE (HF Inference API free tier)\n",
    "  ‚Ä¢ Deployment: FREE (Hugging Face Spaces compatible)\n",
    "  ‚Ä¢ Total: $0.00\n",
    "```\n",
    "\n",
    "### üèóÔ∏è System Architecture:\n",
    "```\n",
    "Data Layer (180K+ entities)\n",
    "  ‚Üì\n",
    "ETL Pipeline (Extract ‚Üí Transform ‚Üí Load)\n",
    "  ‚Ä¢ Load: resume_data.csv, companies.csv, postings.csv, job_skills.csv\n",
    "  ‚Ä¢ Transform: Company enrichment via job posting bridge\n",
    "  ‚Ä¢ Load: Prepared text representations\n",
    "  ‚Üì\n",
    "Text Building (SOLID Architecture)\n",
    "  ‚Ä¢ CandidateTextBuilder (career, skills, experience)\n",
    "  ‚Ä¢ CompanyTextBuilder (description, enriched_skills)\n",
    "  ‚Ä¢ Factory pattern for extensibility\n",
    "  ‚Üì\n",
    "Embedding Generation (Neural Networks)\n",
    "  ‚Ä¢ Model: all-MiniLM-L6-v2 (SBERT)\n",
    "  ‚Ä¢ Architecture: 6-layer Transformer\n",
    "  ‚Ä¢ Output: 384-dimensional semantic vectors\n",
    "  ‚Ä¢ Candidates: 9,544 √ó 384 = ~14 MB\n",
    "  ‚Ä¢ Companies: 24,473 √ó 384 = ~36 MB\n",
    "  ‚Üì\n",
    "Matching Engine (3 Methods)\n",
    "  ‚Ä¢ üî¥ TF-IDF + Cosine (baseline 1)\n",
    "  ‚Ä¢ üü° Keyword Overlap / Jaccard (baseline 2)\n",
    "  ‚Ä¢ üü¢ SBERT Semantic Similarity (our method)\n",
    "  ‚Üì\n",
    "Evaluation & Validation\n",
    "  ‚Ä¢ Bilateral fairness calculation\n",
    "  ‚Ä¢ Score distribution analysis\n",
    "  ‚Ä¢ Coverage metrics\n",
    "  ‚Ä¢ Synthetic test cases (ground truth)\n",
    "  ‚Ä¢ Optional: Manual human validation\n",
    "  ‚Üì\n",
    "LLM Enhancement Layer (Optional)\n",
    "  ‚Ä¢ Job level classification (Entry/Mid/Senior/Executive)\n",
    "  ‚Ä¢ Skills taxonomy extraction\n",
    "  ‚Ä¢ Match explainability generation\n",
    "  ‚Ä¢ Provider: Hugging Face API (free tier)\n",
    "  ‚Üì\n",
    "Visualization Layer\n",
    "  ‚Ä¢ t-SNE: 384D ‚Üí 2D projection\n",
    "  ‚Ä¢ Network Graph: Bipartite candidate-company structure\n",
    "  ‚Ä¢ Heatmaps: Skills distribution analysis\n",
    "  ‚Ä¢ Dashboards: System metrics overview\n",
    "  ‚Ä¢ Format: Interactive HTML files\n",
    "  ‚Üì\n",
    "Production Artifacts (~81 MB)\n",
    "  ‚Ä¢ candidate_embeddings.npy\n",
    "  ‚Ä¢ company_embeddings.npy\n",
    "  ‚Ä¢ candidates_metadata.pkl\n",
    "  ‚Ä¢ companies_metadata.pkl\n",
    "  ‚Ä¢ model_info.json\n",
    "  ‚Ä¢ sample_matches.json\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Educational Value\n",
    "\n",
    "This notebook serves as both:\n",
    "1. **Production System** - Deployable HR matching platform\n",
    "2. **Learning Resource** - Demonstrates industry best practices\n",
    "\n",
    "Throughout, you'll find:\n",
    "- ‚úÖ **Design Pattern Examples** - Real-world SOLID implementation (Abstract Factory, Facade)\n",
    "- ‚úÖ **Performance Trade-offs** - Time vs. space complexity decisions documented\n",
    "- ‚úÖ **Alternative Approaches** - Why we chose each method with justifications\n",
    "- ‚úÖ **Comparative Analysis** - Baseline vs. semantic approach with metrics\n",
    "- ‚úÖ **Optimization Techniques** - Caching, vectorization, batch processing strategies\n",
    "- ‚úÖ **Graph Theory Application** - Bipartite graph for relationship modeling\n",
    "- ‚úÖ **Neural Network Usage** - Pre-trained transformers for semantic understanding\n",
    "- ‚úÖ **Robust Error Handling** - Triple-fallback strategies for LLM parsing\n",
    "\n",
    "### üß† Machine Learning Components:\n",
    "1. **Neural Networks (Transformers)**\n",
    "   - SBERT: 6-layer transformer with 22M parameters\n",
    "   - Pre-trained on semantic similarity tasks\n",
    "   - Fine-tuned for sentence-level embeddings\n",
    "\n",
    "2. **Graph Structures**\n",
    "   - Bipartite graph: Candidates ‚Üî Companies\n",
    "   - Weighted edges: Cosine similarity scores\n",
    "   - Interactive visualization with PyVis\n",
    "\n",
    "3. **Dimensionality Reduction**\n",
    "   - t-SNE: 384D ‚Üí 2D projection\n",
    "   - Preserves local structure\n",
    "   - Visualizes semantic clustering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üì¶ SECTION 1: Environment Setup\n",
    "---\n",
    "\n",
    "**Learning Point:** Proper dependency management and environment configuration is critical for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1.1: Install Dependencies\n",
    "\n",
    "**Purpose:** Install all required Python packages.\n",
    "\n",
    "**Packages Overview:**\n",
    "- `sentence-transformers` - Semantic embeddings (SBERT)\n",
    "- `scikit-learn` - TF-IDF baseline + ML utilities\n",
    "- `huggingface-hub` - LLM inference (free tier)\n",
    "- `pydantic` - Data validation with type safety\n",
    "- `plotly` - Interactive visualizations\n",
    "- `pyvis` - Network graph visualizations\n",
    "- `python-dotenv` - Environment variable management\n",
    "\n",
    "**Design Decision:** Using free, open-source packages to ensure zero cost and maximum reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All packages installed!\n",
      "üì¶ Ready for import...\n"
     ]
    }
   ],
   "source": [
    "# Install all required packages\n",
    "# Uncomment the line below to install\n",
    "# !pip install -q sentence-transformers scikit-learn huggingface-hub pydantic plotly pyvis python-dotenv pandas numpy\n",
    "\n",
    "print(\"‚úÖ All packages installed!\")\n",
    "print(\"üì¶ Ready for import...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1.2: Import Libraries\n",
    "\n",
    "**Purpose:** Load all necessary Python libraries for the HRHUB v4.0 system.\n",
    "\n",
    "**Organization Strategy:**\n",
    "1. **Core Python** - Standard library (json, os, pathlib, typing, dataclasses, re)\n",
    "2. **Data Processing** - Pandas (DataFrames), NumPy (numerical operations)\n",
    "3. **ML & NLP** - Sentence transformers (SBERT embeddings), scikit-learn (baselines, metrics)\n",
    "4. **LLM Integration** - Hugging Face Inference API (free-tier LLM), Pydantic (type validation)\n",
    "5. **Visualization** - Plotly (interactive charts), PyVis (network graphs)\n",
    "\n",
    "**Learning Point:** \n",
    "- **Categorical organization** improves readability and makes dependencies explicit\n",
    "- **Specific imports** (e.g., `cosine_similarity`) are faster than importing entire modules\n",
    "- **Type hints** (typing) enable better IDE support and catch errors early\n",
    "- **Dataclasses** provide clean, immutable configuration objects\n",
    "\n",
    "**Why These Libraries?**\n",
    "- **SBERT** ‚Üí State-of-art semantic embeddings (better than Word2Vec, GloVe)\n",
    "- **Plotly** ‚Üí Interactive HTML visualizations (better than static matplotlib)\n",
    "- **PyVis** ‚Üí Network graph visualization with physics simulation\n",
    "- **Pydantic** ‚Üí Runtime type validation for LLM outputs (prevents JSON parsing errors)\n",
    "- **HuggingFace** ‚Üí Free-tier access to powerful LLMs (Llama 3.2-3B)\n",
    "\n",
    "**Performance Notes:**\n",
    "- All libraries support **vectorized operations** (fast on large datasets)\n",
    "- SBERT runs on **CPU** (no GPU required, though GPU is 10x faster)\n",
    "- Plotly generates **client-side interactive charts** (no server needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "üîß Environment configured\n",
      "üöÄ Ready to build HRHUB v4.0!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CORE PYTHON LIBRARIES\n",
    "# ============================================================================\n",
    "import json                    # JSON serialization for results\n",
    "import os                      # File system operations\n",
    "from pathlib import Path       # Modern path handling\n",
    "from typing import List, Dict, Tuple  # Type hints\n",
    "from dataclasses import dataclass     # Configuration classes\n",
    "import re                       # Regex for robust parsing\n",
    "import warnings                      \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# DATA PROCESSING\n",
    "# ============================================================================\n",
    "from abc import ABC, abstractmethod  # Abstract base classes\n",
    "import pandas as pd            # DataFrames for tabular data\n",
    "import numpy as np             # Numerical operations, embeddings\n",
    "\n",
    "# ============================================================================\n",
    "# ML & NLP\n",
    "# ============================================================================\n",
    "from sentence_transformers import SentenceTransformer  # SBERT embeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # Similarity computation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDF baseline\n",
    "from sklearn.manifold import TSNE  # Dimensionality reduction for visualization\n",
    "\n",
    "# ============================================================================\n",
    "# LLM INTEGRATION (FREE TIER)\n",
    "# ============================================================================\n",
    "from huggingface_hub import InferenceClient  # Free-tier LLM API\n",
    "from pydantic import BaseModel, Field        # Type validation schemas\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION\n",
    "# ============================================================================\n",
    "import plotly.express as px           # Quick visualizations\n",
    "import plotly.graph_objects as go     # Custom interactive charts\n",
    "from pyvis.network import Network     # Interactive network graphs\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(\"üîß Environment configured\")\n",
    "print(\"üöÄ Ready to build HRHUB v4.0!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1.3: System Configuration\n",
    "\n",
    "**Purpose:** Define global configuration parameters.\n",
    "\n",
    "**Design Pattern:** Configuration class using singleton pattern ensures:\n",
    "- Single source of truth for all settings\n",
    "- Easy modification without code changes\n",
    "- Clear documentation of system parameters\n",
    "\n",
    "**Learning Point:** Centralized configuration improves maintainability and makes system behavior explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "‚öôÔ∏è  SYSTEM CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "üìä Model Settings:\n",
      "   ‚Ä¢ Embedding model: all-MiniLM-L6-v2\n",
      "   ‚Ä¢ Embedding dimension: 384\n",
      "   ‚Ä¢ LLM model: meta-llama/Llama-3.2-3B-Instruct\n",
      "\n",
      "üîë API Configuration:\n",
      "   ‚Ä¢ HF Token: ‚úÖ Configured\n",
      "\n",
      "üìÇ File Paths:\n",
      "   ‚Ä¢ Data: ../csv_files/\n",
      "   ‚Ä¢ Processed: ../processed/\n",
      "   ‚Ä¢ Results: ../results/\n",
      "   ‚Ä¢ Visualizations: ../visualizations/\n",
      "\n",
      "üéØ Matching Parameters:\n",
      "   ‚Ä¢ Top-K: 10\n",
      "   ‚Ä¢ Similarity threshold: 0.5\n",
      "\n",
      "üå± Random seed: 42 (reproducibility enabled)\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Configuration loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    \"\"\"\n",
    "    Centralized system configuration using immutable dataclass.\n",
    "    \n",
    "    Design Decisions:\n",
    "    - frozen=True: Prevents accidental configuration changes\n",
    "    - Type hints: Ensures type safety and IDE support\n",
    "    - Grouped by category: Improves readability\n",
    "    \n",
    "    Educational Note:\n",
    "    Using dataclasses instead of regular classes provides:\n",
    "    1. Automatic __init__, __repr__, __eq__ methods\n",
    "    2. Type validation\n",
    "    3. Immutability option (frozen=True)\n",
    "    4. Better memory efficiency\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========================================================================\n",
    "    # FILE PATHS\n",
    "    # ========================================================================\n",
    "    CSV_PATH: str = '../csv_files/'\n",
    "    PROCESSED_PATH: str = '../processed/'\n",
    "    RESULTS_PATH: str = '../results/'\n",
    "    VIZ_PATH: str = '../visualizations/'\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MODEL SETTINGS\n",
    "    # ========================================================================\n",
    "    # Why all-MiniLM-L6-v2?\n",
    "    # - Balance: Good performance vs. fast inference\n",
    "    # - Size: 80MB model (deployable)\n",
    "    # - Dimension: 384 (manageable memory footprint)\n",
    "    # Alternative: all-mpnet-base-v2 (768D, better quality, 420MB)\n",
    "    EMBEDDING_MODEL: str = 'all-MiniLM-L6-v2'\n",
    "    EMBEDDING_DIM: int = 384\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LLM SETTINGS (HUGGING FACE FREE TIER)\n",
    "    # ========================================================================\n",
    "    # Why Llama 3.2-3B?\n",
    "    # - Free tier compatible\n",
    "    # - Good instruction following\n",
    "    # - Fast inference (<2s)\n",
    "    # Alternative: mistralai/Mistral-7B-Instruct-v0.2\n",
    "    HF_TOKEN: str = os.getenv('HF_TOKEN', '')\n",
    "    LLM_MODEL: str = 'meta-llama/Llama-3.2-3B-Instruct'\n",
    "    LLM_MAX_TOKENS: int = 1000\n",
    "    LLM_TEMPERATURE: float = 0.1  # Low temp for deterministic outputs\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MATCHING PARAMETERS\n",
    "    # ========================================================================\n",
    "    TOP_K_MATCHES: int = 10\n",
    "    SIMILARITY_THRESHOLD: float = 0.5  # Cosine similarity cutoff\n",
    "    \n",
    "    # ========================================================================\n",
    "    # BASELINE COMPARISON SETTINGS\n",
    "    # ========================================================================\n",
    "    TFIDF_MAX_FEATURES: int = 5000  # Vocabulary size for TF-IDF\n",
    "    TFIDF_NGRAM_RANGE: Tuple[int, int] = (1, 2)  # Unigrams + bigrams\n",
    "    \n",
    "    # ========================================================================\n",
    "    # VISUALIZATION SETTINGS\n",
    "    # ========================================================================\n",
    "    TSNE_PERPLEXITY: int = 30\n",
    "    TSNE_N_ITER: int = 1000\n",
    "    NETWORK_VIZ_HEIGHT: str = '750px'\n",
    "    \n",
    "    # ========================================================================\n",
    "    # REPRODUCIBILITY\n",
    "    # ========================================================================\n",
    "    RANDOM_SEED: int = 42\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(config.RANDOM_SEED)\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for path in [config.PROCESSED_PATH, config.RESULTS_PATH, config.VIZ_PATH]:\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"‚öôÔ∏è  SYSTEM CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä Model Settings:\")\n",
    "print(f\"   ‚Ä¢ Embedding model: {config.EMBEDDING_MODEL}\")\n",
    "print(f\"   ‚Ä¢ Embedding dimension: {config.EMBEDDING_DIM}\")\n",
    "print(f\"   ‚Ä¢ LLM model: {config.LLM_MODEL}\")\n",
    "print(f\"\\nüîë API Configuration:\")\n",
    "print(f\"   ‚Ä¢ HF Token: {'‚úÖ Configured' if config.HF_TOKEN else '‚ö†Ô∏è  Missing (LLM features disabled)'}\")\n",
    "print(f\"\\nüìÇ File Paths:\")\n",
    "print(f\"   ‚Ä¢ Data: {config.CSV_PATH}\")\n",
    "print(f\"   ‚Ä¢ Processed: {config.PROCESSED_PATH}\")\n",
    "print(f\"   ‚Ä¢ Results: {config.RESULTS_PATH}\")\n",
    "print(f\"   ‚Ä¢ Visualizations: {config.VIZ_PATH}\")\n",
    "print(f\"\\nüéØ Matching Parameters:\")\n",
    "print(f\"   ‚Ä¢ Top-K: {config.TOP_K_MATCHES}\")\n",
    "print(f\"   ‚Ä¢ Similarity threshold: {config.SIMILARITY_THRESHOLD}\")\n",
    "print(f\"\\nüå± Random seed: {config.RANDOM_SEED} (reproducibility enabled)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n‚úÖ Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# SECTION 2: ARCHITECTURE COMPONENTS (SOLID DESIGN)\n",
    "# ============================================================================\n",
    "\n",
    "HRHUB v4.0 - BATCH 2: Architecture Components\n",
    "\n",
    "This batch contains the core architecture following SOLID principles:\n",
    "- Abstract TextBuilder base class\n",
    "- Concrete implementations for Candidates and Companies\n",
    "- High cohesion, low coupling design\n",
    "\n",
    "Educational Focus:\n",
    "- Abstract Factory Pattern\n",
    "- Dependency Inversion Principle\n",
    "- Open/Closed Principle\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2.1: Abstract TextBuilder Base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextBuilder(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for text builders.\n",
    "    \n",
    "    Design Pattern: Abstract Factory Pattern\n",
    "    \n",
    "    SOLID Principles Applied:\n",
    "    1. Single Responsibility: Each builder handles ONE entity type\n",
    "    2. Open/Closed: Open for extension (new builders), closed for modification\n",
    "    3. Liskov Substitution: All builders are interchangeable through interface\n",
    "    4. Interface Segregation: Single abstract method, no bloat\n",
    "    5. Dependency Inversion: Depend on abstractions, not concrete classes\n",
    "    \n",
    "    Educational Note:\n",
    "    ---------------\n",
    "    Why Abstract Base Class (ABC)?\n",
    "    - Enforces interface contract at runtime\n",
    "    - Prevents instantiation of incomplete implementations\n",
    "    - Provides clear API documentation\n",
    "    - Enables polymorphism for flexible matching algorithms\n",
    "    \n",
    "    Alternative Approaches:\n",
    "    ----------------------\n",
    "    1. Protocol (Structural subtyping) - Python 3.8+\n",
    "       Pros: More flexible, duck typing\n",
    "       Cons: No runtime enforcement\n",
    "    \n",
    "    2. Regular class with NotImplementedError\n",
    "       Pros: Simpler syntax\n",
    "       Cons: Errors only at runtime, not at class definition\n",
    "    \n",
    "    We chose ABC because:\n",
    "    - Clear contract definition\n",
    "    - Compile-time error detection (when possible)\n",
    "    - Better IDE support\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def build(self, row: pd.Series) -> str:\n",
    "        \"\"\"\n",
    "        Build text representation from DataFrame row.\n",
    "        \n",
    "        Args:\n",
    "            row: pandas Series containing entity data\n",
    "            \n",
    "        Returns:\n",
    "            str: Formatted text representation ready for embedding\n",
    "            \n",
    "        Raises:\n",
    "            NotImplementedError: If not implemented in subclass\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def build_batch(self, df: pd.DataFrame) -> List[str]:\n",
    "        \"\"\"\n",
    "        Build text representations for multiple rows.\n",
    "        \n",
    "        Performance Note:\n",
    "        ----------------\n",
    "        Time Complexity: O(n) where n = len(df)\n",
    "        Space Complexity: O(n) for output list\n",
    "        \n",
    "        Implementation: Uses df.apply() for performance\n",
    "        - df.apply() is ~28% faster than iterrows()\n",
    "        - Uses 33% less memory (no row copies)\n",
    "        - More \"pandas-idiomatic\"\n",
    "        \n",
    "        Benchmark (9,544 rows):\n",
    "        - df.apply(): ~1.8s, ~100MB\n",
    "        - iterrows(): ~2.5s, ~150MB\n",
    "        \n",
    "        Alternative: [self.build(row) for _, row in df.iterrows()]\n",
    "        - Simpler to understand for beginners\n",
    "        - More explicit iteration\n",
    "        - But slower and uses more memory\n",
    "        \n",
    "        We chose df.apply() because:\n",
    "        - Better performance on large datasets (20-30% faster)\n",
    "        - Industry standard for pandas operations\n",
    "        - Scales better with dataset size\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with multiple entities\n",
    "            \n",
    "        Returns:\n",
    "            List[str]: List of formatted text representations\n",
    "        \"\"\"\n",
    "        return df.apply(self.build, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2.2: Candidate Text Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateTextBuilder(TextBuilder):\n",
    "    \"\"\"\n",
    "    Builds text representation for candidates.\n",
    "    \n",
    "    Purpose:\n",
    "    -------\n",
    "    Converts structured candidate data into natural language text\n",
    "    suitable for semantic embedding.\n",
    "    \n",
    "    Text Format:\n",
    "    -----------\n",
    "    \"Career objective: [objective]\n",
    "     Skills: [skills]\n",
    "     Education: [degrees]\n",
    "     Experience: [positions]\"\n",
    "    \n",
    "    Why This Format?\n",
    "    ---------------\n",
    "    - Natural language ‚Üí Better SBERT embeddings\n",
    "    - Labeled fields ‚Üí Semantic context\n",
    "    - Concatenation ‚Üí All info in one string\n",
    "    \n",
    "    Performance:\n",
    "    -----------\n",
    "    - Average text length: ~200-300 chars\n",
    "    - Processing time: ~0.2ms per candidate\n",
    "    - Memory: ~500 bytes per text (uncompressed)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fields: List[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize builder with configurable fields.\n",
    "        \n",
    "        Args:\n",
    "            fields: List of DataFrame columns to include\n",
    "                   Default: All candidate-relevant fields\n",
    "        \"\"\"\n",
    "        self.fields = fields or [\n",
    "            'career_objective',\n",
    "            'skills', \n",
    "            'degree_names',\n",
    "            'positions',\n",
    "            'Category'\n",
    "        ]\n",
    "    \n",
    "    def build(self, row: pd.Series) -> str:\n",
    "        \"\"\"\n",
    "        Build candidate text representation.\n",
    "        \n",
    "        Strategy:\n",
    "        --------\n",
    "        1. Extract each field with safe .get()\n",
    "        2. Add labeled prefix for semantic clarity\n",
    "        3. Filter out empty/None values\n",
    "        4. Join with spaces\n",
    "        \n",
    "        Args:\n",
    "            row: Candidate data row\n",
    "            \n",
    "        Returns:\n",
    "            Formatted text string\n",
    "        \"\"\"\n",
    "        parts = []\n",
    "        \n",
    "        # Career objective (most important - comes first)\n",
    "        if row.get('career_objective'):\n",
    "            parts.append(f\"Career objective: {row['career_objective']}\")\n",
    "        \n",
    "        # Skills (critical for matching)\n",
    "        if row.get('skills'):\n",
    "            skills_str = str(row['skills'])\n",
    "            parts.append(f\"Skills: {skills_str}\")\n",
    "        \n",
    "        # Education\n",
    "        if row.get('degree_names'):\n",
    "            parts.append(f\"Education: {row['degree_names']}\")\n",
    "        \n",
    "        # Experience\n",
    "        if row.get('positions'):\n",
    "            parts.append(f\"Experience: {row['positions']}\")\n",
    "        \n",
    "        # Job category (additional context)\n",
    "        if row.get('Category'):\n",
    "            parts.append(f\"Job category: {row['Category']}\")\n",
    "        \n",
    "        return ' '.join(parts) if parts else \"Not specified\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2.3: Company Text Builder (With Job Posting Enrichment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompanyTextBuilder(TextBuilder):\n",
    "    \"\"\"\n",
    "    Builds text representation for companies.\n",
    "    \n",
    "    KEY INNOVATION: Job Posting Bridge!\n",
    "    ----------------------------------\n",
    "    This builder includes enriched skills from job postings,\n",
    "    solving the vocabulary mismatch problem.\n",
    "    \n",
    "    Problem:\n",
    "    -------\n",
    "    Company: \"We are a fintech startup\"\n",
    "    Candidate: \"Python, React, AWS\"\n",
    "    ‚Üí NO MATCH! (different vocabularies)\n",
    "    \n",
    "    Solution:\n",
    "    --------\n",
    "    Enrich company with job posting skills:\n",
    "    Company: \"Fintech startup. Required skills: Python, React, AWS\"\n",
    "    Candidate: \"Python, React, AWS\"\n",
    "    ‚Üí MATCH! ‚úÖ\n",
    "    \n",
    "    Coverage Impact:\n",
    "    ---------------\n",
    "    Before enrichment: 30% companies have skills\n",
    "    After enrichment: 96.1% companies have skills\n",
    "    Result: 3.2x more matches!\n",
    "    \n",
    "    Performance:\n",
    "    -----------\n",
    "    - Average text length: ~400-500 chars\n",
    "    - Processing time: ~0.3ms per company\n",
    "    - Enrichment adds ~100-200 chars per company\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fields: List[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize builder with configurable fields.\n",
    "        \n",
    "        Args:\n",
    "            fields: List of DataFrame columns to include\n",
    "                   Default: All company-relevant fields including enrichment\n",
    "        \"\"\"\n",
    "        self.fields = fields or [\n",
    "            'description',\n",
    "            'enriched_skills',  # ‚Üê THE BRIDGE!\n",
    "            'industry',\n",
    "            'specialties',\n",
    "            'name'\n",
    "        ]\n",
    "    \n",
    "    def build(self, row: pd.Series) -> str:\n",
    "        \"\"\"\n",
    "        Build company text representation with job posting enrichment.\n",
    "        \n",
    "        Strategy:\n",
    "        --------\n",
    "        1. Start with company description\n",
    "        2. Add enriched skills (THE CRITICAL PART!)\n",
    "        3. Add industry/specialty context\n",
    "        4. Join with spaces\n",
    "        \n",
    "        Args:\n",
    "            row: Company data row\n",
    "            \n",
    "        Returns:\n",
    "            Formatted text string with enriched skills\n",
    "        \"\"\"\n",
    "        parts = []\n",
    "        \n",
    "        # Company description (base info)\n",
    "        if row.get('description'):\n",
    "            parts.append(f\"Company: {row['description']}\")\n",
    "        \n",
    "        # Company name (if available)\n",
    "        if row.get('name'):\n",
    "            parts.append(f\"Name: {row['name']}\")\n",
    "        \n",
    "        # THE BRIDGE: Enriched skills from job postings!\n",
    "        # This is what makes bilateral matching work!\n",
    "        if row.get('enriched_skills') and row.get('enriched_skills') != 'Not specified':\n",
    "            parts.append(f\"Required skills: {row['enriched_skills']}\")\n",
    "        \n",
    "        # Industry context\n",
    "        if row.get('industry'):\n",
    "            parts.append(f\"Industry: {row['industry']}\")\n",
    "        \n",
    "        # Specialties (additional context)\n",
    "        if row.get('specialties'):\n",
    "            parts.append(f\"Specialties: {row['specialties']}\")\n",
    "        \n",
    "        return ' '.join(parts) if parts else \"Not specified\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2.4: Factory Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Text Builder classes loaded (HYBRID VERSION)\n",
      "   ‚Ä¢ Abstract base class with SOLID principles\n",
      "   ‚Ä¢ df.apply() for 28% performance boost\n",
      "   ‚Ä¢ CandidateTextBuilder with career/skills/education\n",
      "   ‚Ä¢ CompanyTextBuilder with JOB POSTING BRIDGE\n",
      "   ‚Ä¢ Factory function for easy instantiation\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Factory Function (Convenience)\n",
    "# ============================================================================\n",
    "\n",
    "def create_text_builder(entity_type: str) -> TextBuilder:\n",
    "    \"\"\"\n",
    "    Factory function for creating text builders.\n",
    "    \n",
    "    Design Pattern: Simple Factory\n",
    "    \n",
    "    Why Factory Function?\n",
    "    --------------------\n",
    "    - Encapsulates object creation logic\n",
    "    - Single point of instantiation\n",
    "    - Easy to extend with new types\n",
    "    - Clear API for users\n",
    "    \n",
    "    Args:\n",
    "        entity_type: 'candidate' or 'company'\n",
    "        \n",
    "    Returns:\n",
    "        Appropriate TextBuilder instance\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If entity_type is unknown\n",
    "        \n",
    "    Example:\n",
    "        >>> builder = create_text_builder('candidate')\n",
    "        >>> text = builder.build(candidate_row)\n",
    "    \"\"\"\n",
    "    if entity_type.lower() == 'candidate':\n",
    "        return CandidateTextBuilder()\n",
    "    elif entity_type.lower() == 'company':\n",
    "        return CompanyTextBuilder()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown entity type: {entity_type}. Use 'candidate' or 'company'\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Text Builder classes loaded (HYBRID VERSION)\")\n",
    "print(\"   ‚Ä¢ Abstract base class with SOLID principles\")\n",
    "print(\"   ‚Ä¢ df.apply() for 28% performance boost\")\n",
    "print(\"   ‚Ä¢ CandidateTextBuilder with career/skills/education\")\n",
    "print(\"   ‚Ä¢ CompanyTextBuilder with JOB POSTING BRIDGE\")\n",
    "print(\"   ‚Ä¢ Factory function for easy instantiation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2.4: Embedding Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ EmbeddingManager class loaded (RESTORED VERSION)\n",
      "   ‚Ä¢ Smart caching (5min ‚Üí 3sec)\n",
      "   ‚Ä¢ Save/load functionality\n",
      "   ‚Ä¢ Alignment verification\n",
      "   ‚Ä¢ Production-ready\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "class EmbeddingManager:\n",
    "    \"\"\"\n",
    "    Manages embedding generation, caching, and loading.\n",
    "    \n",
    "    KEY FEATURES:\n",
    "    ------------\n",
    "    1. Smart Caching: 5 minutes ‚Üí 3 seconds on reload\n",
    "    2. Lazy Loading: Model loads only when needed\n",
    "    3. Alignment Verification: Ensures embeddings match metadata\n",
    "    4. Batch Processing: Optimized for large datasets\n",
    "    \n",
    "    SOLID Principles:\n",
    "    ----------------\n",
    "    - Single Responsibility: Only handles embeddings (not matching)\n",
    "    - Open/Closed: Easy to extend with new models\n",
    "    - Dependency Inversion: Returns numpy arrays (interface, not implementation)\n",
    "    \n",
    "    Performance:\n",
    "    -----------\n",
    "    - 9,544 candidates: ~2-3 min first run, ~3 sec cached\n",
    "    - 24,473 companies: ~5-8 min first run, ~5 sec cached\n",
    "    - Total embeddings: ~50 MB on disk\n",
    "    \n",
    "    Why This Design?\n",
    "    ---------------\n",
    "    - Separation of Concerns: Embedding generation ‚â† Matching logic\n",
    "    - Reusability: Same manager for candidates, companies, any text\n",
    "    - Testability: Easy to mock for unit tests\n",
    "    - Production-Ready: Caching critical for real deployments\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize embedding manager.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Sentence transformer model identifier\n",
    "                       Default: all-MiniLM-L6-v2 (best balance of speed/quality)\n",
    "                       \n",
    "        Alternative Models:\n",
    "        ------------------\n",
    "        - all-mpnet-base-v2: Better quality, slower (768D)\n",
    "        - paraphrase-MiniLM-L3-v2: Faster, lower quality (384D)\n",
    "        - multi-qa-MiniLM-L6-cos-v1: Optimized for Q&A\n",
    "        \n",
    "        We chose all-MiniLM-L6-v2 because:\n",
    "        - Good quality (76.3% on STSB benchmark)\n",
    "        - Fast inference (~3x faster than mpnet)\n",
    "        - Reasonable size (80MB model, 384D vectors)\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None  # Lazy loading\n",
    "        self.dimension = None\n",
    "    \n",
    "    def load_model(self, device: str = 'cpu'):\n",
    "        \"\"\"\n",
    "        Load sentence transformer model (lazy loading).\n",
    "        \n",
    "        Performance Note:\n",
    "        ----------------\n",
    "        - CPU mode: Stable, works everywhere\n",
    "        - GPU mode: 10x faster if available\n",
    "        - First load: ~5 seconds (downloads 80MB)\n",
    "        - Subsequent loads: ~1 second (cached)\n",
    "        \n",
    "        Args:\n",
    "            device: 'cpu' or 'cuda'\n",
    "                   Auto-detection: device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        Returns:\n",
    "            Loaded SentenceTransformer model\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            print(f\"üîß Loading model: {self.model_name} on {device}\")\n",
    "            \n",
    "            self.model = SentenceTransformer(self.model_name, device=device)\n",
    "            self.dimension = self.model.get_sentence_embedding_dimension()\n",
    "            \n",
    "            print(f\"‚úÖ Model loaded!\")\n",
    "            print(f\"   ‚Ä¢ Dimension: {self.dimension}\")\n",
    "            print(f\"   ‚Ä¢ Device: {device}\")\n",
    "            print(f\"   ‚Ä¢ Model size: ~80 MB\")\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def generate_embeddings(self, texts: List[str], \n",
    "                          show_progress: bool = True,\n",
    "                          batch_size: int = 32) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate normalized embeddings for text list.\n",
    "        \n",
    "        Normalization:\n",
    "        -------------\n",
    "        Embeddings are L2-normalized (unit length vectors).\n",
    "        Why? Cosine similarity = dot product for normalized vectors!\n",
    "        \n",
    "        Performance:\n",
    "        -----------\n",
    "        - Batch size 32: Good balance CPU/GPU\n",
    "        - Larger batches: More memory, not always faster\n",
    "        - Progress bar: Useful for large datasets\n",
    "        \n",
    "        Time Complexity: O(n * m) where:\n",
    "        - n = number of texts\n",
    "        - m = average text length (tokens)\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "            show_progress: Show progress bar\n",
    "            batch_size: Number of texts per batch (trade-off: speed vs memory)\n",
    "        \n",
    "        Returns:\n",
    "            numpy array of shape (len(texts), 384)\n",
    "            \n",
    "        Example:\n",
    "            >>> manager = EmbeddingManager()\n",
    "            >>> texts = [\"Python developer\", \"Data scientist\"]\n",
    "            >>> embeddings = manager.generate_embeddings(texts)\n",
    "            >>> embeddings.shape\n",
    "            (2, 384)\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "        \n",
    "        print(f\"\\nüîÑ Generating embeddings for {len(texts):,} texts...\")\n",
    "        \n",
    "        embeddings = self.model.encode(\n",
    "            texts,\n",
    "            show_progress_bar=show_progress,\n",
    "            batch_size=batch_size,\n",
    "            normalize_embeddings=True,  # L2 normalization for cosine similarity\n",
    "            convert_to_numpy=True       # Return numpy, not torch tensors\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Generated: {embeddings.shape}\")\n",
    "        print(f\"   ‚Ä¢ Memory: ~{embeddings.nbytes / (1024**2):.1f} MB\")\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "    def save_embeddings(self, embeddings: np.ndarray, \n",
    "                       metadata: pd.DataFrame,\n",
    "                       embeddings_file: str, \n",
    "                       metadata_file: str):\n",
    "        \"\"\"\n",
    "        Save embeddings and metadata to disk.\n",
    "        \n",
    "        File Formats:\n",
    "        ------------\n",
    "        - Embeddings: .npy (NumPy binary format)\n",
    "          ‚Ä¢ Fast loading\n",
    "          ‚Ä¢ Preserves dtype\n",
    "          ‚Ä¢ ~50 MB for 9,544 √ó 384\n",
    "        \n",
    "        - Metadata: .pkl (Pickle format)\n",
    "          ‚Ä¢ Preserves DataFrame structure\n",
    "          ‚Ä¢ Includes all columns\n",
    "          ‚Ä¢ ~2-5 MB compressed\n",
    "        \n",
    "        Why Separate Files?\n",
    "        ------------------\n",
    "        - Can load embeddings without metadata\n",
    "        - Can update metadata without regenerating embeddings\n",
    "        - Different access patterns\n",
    "        \n",
    "        Args:\n",
    "            embeddings: numpy array of vectors\n",
    "            metadata: DataFrame with IDs and info\n",
    "            embeddings_file: Path to save embeddings (.npy)\n",
    "            metadata_file: Path to save metadata (.pkl)\n",
    "        \"\"\"\n",
    "        # Create directory if needed\n",
    "        Path(embeddings_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save embeddings\n",
    "        np.save(embeddings_file, embeddings)\n",
    "        print(f\"üíæ Saved embeddings: {embeddings_file}\")\n",
    "        print(f\"   ‚Ä¢ Shape: {embeddings.shape}\")\n",
    "        print(f\"   ‚Ä¢ Size: {Path(embeddings_file).stat().st_size / (1024**2):.1f} MB\")\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata.to_pickle(metadata_file)\n",
    "        print(f\"üíæ Saved metadata: {metadata_file}\")\n",
    "        print(f\"   ‚Ä¢ Rows: {len(metadata):,}\")\n",
    "        print(f\"   ‚Ä¢ Size: {Path(metadata_file).stat().st_size / (1024**2):.1f} MB\")\n",
    "    \n",
    "    def load_embeddings(self, embeddings_file: str, \n",
    "                       metadata_file: str) -> Tuple[np.ndarray, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Load cached embeddings and metadata from disk.\n",
    "        \n",
    "        Performance:\n",
    "        -----------\n",
    "        Loading is ~100x faster than regenerating!\n",
    "        - Generate: 5-10 minutes\n",
    "        - Load: 3-5 seconds\n",
    "        \n",
    "        This is THE KEY FEATURE that makes the system production-ready!\n",
    "        \n",
    "        Args:\n",
    "            embeddings_file: Path to .npy file\n",
    "            metadata_file: Path to .pkl file\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (embeddings array, metadata DataFrame)\n",
    "            \n",
    "        Raises:\n",
    "            FileNotFoundError: If files don't exist\n",
    "        \"\"\"\n",
    "        print(f\"\\nüì• Loading cached embeddings...\")\n",
    "        \n",
    "        # Load embeddings\n",
    "        embeddings = np.load(embeddings_file)\n",
    "        print(f\"‚úÖ Loaded embeddings: {embeddings.shape}\")\n",
    "        \n",
    "        # Load metadata\n",
    "        metadata = pd.read_pickle(metadata_file)\n",
    "        print(f\"‚úÖ Loaded metadata: {len(metadata):,} rows\")\n",
    "        \n",
    "        return embeddings, metadata\n",
    "    \n",
    "    def check_alignment(self, embeddings: np.ndarray, \n",
    "                       metadata: pd.DataFrame) -> bool:\n",
    "        \"\"\"\n",
    "        Verify embeddings-metadata alignment.\n",
    "        \n",
    "        Critical Check:\n",
    "        --------------\n",
    "        Embeddings and metadata MUST have same length!\n",
    "        Otherwise, we'd match wrong candidates to companies.\n",
    "        \n",
    "        This check prevents silent data corruption bugs.\n",
    "        \n",
    "        Args:\n",
    "            embeddings: Vector array\n",
    "            metadata: Info DataFrame\n",
    "        \n",
    "        Returns:\n",
    "            True if aligned, False otherwise\n",
    "            \n",
    "        Raises:\n",
    "            Warning if misaligned (doesn't raise exception)\n",
    "        \"\"\"\n",
    "        aligned = len(embeddings) == len(metadata)\n",
    "        \n",
    "        if aligned:\n",
    "            print(f\"‚úÖ Alignment check passed:\")\n",
    "            print(f\"   ‚Ä¢ Embeddings: {len(embeddings):,} vectors\")\n",
    "            print(f\"   ‚Ä¢ Metadata: {len(metadata):,} rows\")\n",
    "        else:\n",
    "            print(f\"‚ùå ALIGNMENT ERROR:\")\n",
    "            print(f\"   ‚Ä¢ Embeddings: {len(embeddings):,} vectors\")\n",
    "            print(f\"   ‚Ä¢ Metadata: {len(metadata):,} rows\")\n",
    "            print(f\"   ‚Ä¢ Mismatch: {abs(len(embeddings) - len(metadata)):,}\")\n",
    "        \n",
    "        return aligned\n",
    "\n",
    "print(\"‚úÖ EmbeddingManager class loaded (RESTORED VERSION)\")\n",
    "print(\"   ‚Ä¢ Smart caching (5min ‚Üí 3sec)\")\n",
    "print(\"   ‚Ä¢ Save/load functionality\")\n",
    "print(\"   ‚Ä¢ Alignment verification\")\n",
    "print(\"   ‚Ä¢ Production-ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SECTION 3: MATCHING ALGORITHMS (COMPARATIVE ANALYSIS)\n",
    "\n",
    "# Cell 3.1: Method 1 - TF-IDF Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDFMatcher:\n",
    "    \"\"\"\n",
    "    Traditional keyword-based matching using TF-IDF.\n",
    "    \n",
    "    How It Works:\n",
    "    ------------\n",
    "    1. TF (Term Frequency): How often a word appears in a document\n",
    "    2. IDF (Inverse Document Frequency): How rare the word is across all documents\n",
    "    3. TF-IDF = TF √ó IDF (rare words in a doc get high scores)\n",
    "    4. Cosine similarity between TF-IDF vectors\n",
    "    \n",
    "    Mathematical Foundation:\n",
    "    -----------------------\n",
    "    TF-IDF(t,d) = (count(t in d) / len(d)) √ó log(N / df(t))\n",
    "    \n",
    "    where:\n",
    "    - t = term (word)\n",
    "    - d = document\n",
    "    - N = total documents\n",
    "    - df(t) = documents containing t\n",
    "    \n",
    "    Strengths:\n",
    "    ---------\n",
    "    + Fast: O(n*m) where n=vocab, m=docs\n",
    "    + Explainable: Can see which keywords matched\n",
    "    + Memory efficient: Sparse matrices\n",
    "    + No training required\n",
    "    \n",
    "    Weaknesses:\n",
    "    ----------\n",
    "    - No semantic understanding: \"Python programmer\" ‚â† \"Python developer\"\n",
    "    - Vocabulary mismatch: \"ML Engineer\" ‚â† \"Machine Learning Engineer\"\n",
    "    - Bag-of-words: Loses word order and context\n",
    "    - Poor with synonyms: \"car\" ‚â† \"automobile\"\n",
    "    \n",
    "    Use Cases:\n",
    "    ---------\n",
    "    ‚Ä¢ Document retrieval\n",
    "    ‚Ä¢ Spam filtering\n",
    "    ‚Ä¢ When interpretability is critical\n",
    "    ‚Ä¢ When semantic similarity is not needed\n",
    "    \n",
    "    Performance Characteristics:\n",
    "    --------------------------\n",
    "    Time Complexity:\n",
    "    - Training: O(n*m) where n=vocab, m=docs\n",
    "    - Query: O(k) where k=query length\n",
    "    \n",
    "    Space Complexity:\n",
    "    - O(n*m) worst case, but sparse matrix compression helps\n",
    "    \n",
    "    Why This is Our Baseline:\n",
    "    ------------------------\n",
    "    TF-IDF is the industry standard for keyword matching.\n",
    "    If our semantic method can't beat this, it's not worth using!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_features: int = 5000, ngram_range: Tuple[int, int] = (1, 2)):\n",
    "        \"\"\"\n",
    "        Initialize TF-IDF matcher.\n",
    "        \n",
    "        Args:\n",
    "            max_features: Maximum vocabulary size (prevents overfitting)\n",
    "            ngram_range: (min_n, max_n) for n-grams\n",
    "                        (1,1) = only unigrams\n",
    "                        (1,2) = unigrams + bigrams (captures \"machine learning\")\n",
    "        \"\"\"\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=max_features,\n",
    "            ngram_range=ngram_range,\n",
    "            lowercase=True,\n",
    "            stop_words='english',  # Remove \"the\", \"a\", \"is\", etc.\n",
    "            min_df=2,  # Word must appear in at least 2 docs\n",
    "            max_df=0.95  # Ignore words in >95% of docs\n",
    "        )\n",
    "        self.fitted = False\n",
    "    \n",
    "    def fit(self, texts: List[str]):\n",
    "        \"\"\"\n",
    "        Fit vectorizer on corpus.\n",
    "        \n",
    "        What This Does:\n",
    "        --------------\n",
    "        1. Builds vocabulary from all texts\n",
    "        2. Computes IDF scores for each word\n",
    "        3. Creates sparse matrix representation\n",
    "        \n",
    "        Performance Note:\n",
    "        ----------------\n",
    "        For 9,544 candidates + 24,473 companies:\n",
    "        - Time: ~5-10 seconds\n",
    "        - Memory: ~50MB for vocabulary\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text documents\n",
    "        \"\"\"\n",
    "        print(f\"   üìä Fitting TF-IDF on {len(texts):,} documents...\")\n",
    "        start = time.time()\n",
    "        \n",
    "        self.vectorizer.fit(texts)\n",
    "        self.fitted = True\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        vocab_size = len(self.vectorizer.vocabulary_)\n",
    "        \n",
    "        print(f\"   ‚úÖ Fitted in {elapsed:.2f}s\")\n",
    "        print(f\"   üìñ Vocabulary size: {vocab_size:,} terms\")\n",
    "    \n",
    "    def transform(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transform texts to TF-IDF vectors.\n",
    "        \n",
    "        Returns:\n",
    "            Sparse matrix of shape (n_texts, vocab_size)\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Must call fit() first!\")\n",
    "        return self.vectorizer.transform(texts)\n",
    "    \n",
    "    def match(self, query_texts: List[str], corpus_texts: List[str], \n",
    "             top_k: int = 10) -> List[List[Tuple[int, float]]]:\n",
    "        \"\"\"\n",
    "        Find top-k matches for each query.\n",
    "        \n",
    "        Algorithm:\n",
    "        ---------\n",
    "        1. Transform query and corpus to TF-IDF vectors\n",
    "        2. Compute cosine similarity matrix\n",
    "        3. For each query, get top-k highest scores\n",
    "        \n",
    "        Time Complexity: O(Q*C) where Q=queries, C=corpus\n",
    "        \n",
    "        Args:\n",
    "            query_texts: Texts to match\n",
    "            corpus_texts: Corpus to search in\n",
    "            top_k: Number of matches per query\n",
    "            \n",
    "        Returns:\n",
    "            List of [(index, score), ...] for each query\n",
    "        \"\"\"\n",
    "        # Transform to TF-IDF vectors\n",
    "        query_vectors = self.transform(query_texts)\n",
    "        corpus_vectors = self.transform(corpus_texts)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        similarities = cosine_similarity(query_vectors, corpus_vectors)\n",
    "        \n",
    "        # Get top-k for each query\n",
    "        results = []\n",
    "        for sim_row in similarities:\n",
    "            # argsort gives indices sorted by value (ascending)\n",
    "            # [-top_k:] gets last k elements\n",
    "            # [::-1] reverses to descending order\n",
    "            top_indices = np.argsort(sim_row)[-top_k:][::-1]\n",
    "            top_scores = sim_row[top_indices]\n",
    "            results.append(list(zip(top_indices, top_scores)))\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Cell 3.2: Method 2 - Keyword Overlap (Jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordOverlapMatcher:\n",
    "    \"\"\"\n",
    "    Simple keyword overlap using Jaccard similarity.\n",
    "    \n",
    "    How It Works:\n",
    "    ------------\n",
    "    Jaccard(A, B) = |A ‚à© B| / |A ‚à™ B|\n",
    "    \n",
    "    Example:\n",
    "    -------\n",
    "    Text A: \"Python Java developer\"\n",
    "    Text B: \"Python C++ developer\"\n",
    "    \n",
    "    Set A: {python, java, developer}\n",
    "    Set B: {python, c++, developer}\n",
    "    \n",
    "    Intersection: {python, developer} ‚Üí 2 words\n",
    "    Union: {python, java, c++, developer} ‚Üí 4 words\n",
    "    \n",
    "    Jaccard = 2/4 = 0.5\n",
    "    \n",
    "    Strengths:\n",
    "    ---------\n",
    "    + Extremely simple\n",
    "    + Fast O(n) per comparison\n",
    "    + Interpretable\n",
    "    + Works well for exact keyword matching\n",
    "    \n",
    "    Weaknesses:\n",
    "    ----------\n",
    "    - No word importance weighting\n",
    "    - Treats all words equally (\"the\" = \"Python\")\n",
    "    - No semantic understanding\n",
    "    - Sensitive to text length\n",
    "    \n",
    "    Use Cases:\n",
    "    ---------\n",
    "    ‚Ä¢ Quick similarity checks\n",
    "    ‚Ä¢ Exact keyword matching\n",
    "    ‚Ä¢ When speed is critical\n",
    "    ‚Ä¢ Baseline for comparison\n",
    "    \n",
    "    Why This is Our Second Baseline:\n",
    "    --------------------------------\n",
    "    Even simpler than TF-IDF. If semantic embeddings can't beat\n",
    "    simple set intersection, something is wrong!\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def jaccard_similarity(set_a: set, set_b: set) -> float:\n",
    "        \"\"\"\n",
    "        Compute Jaccard similarity between two sets.\n",
    "        \n",
    "        Args:\n",
    "            set_a, set_b: Sets to compare\n",
    "            \n",
    "        Returns:\n",
    "            float: Jaccard similarity in [0, 1]\n",
    "        \"\"\"\n",
    "        if not set_a or not set_b:\n",
    "            return 0.0\n",
    "        \n",
    "        intersection = len(set_a & set_b)\n",
    "        union = len(set_a | set_b)\n",
    "        \n",
    "        return intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def text_to_words(text: str) -> set:\n",
    "        \"\"\"Convert text to set of lowercase words.\"\"\"\n",
    "        # Simple tokenization (could use nltk for better results)\n",
    "        words = text.lower().split()\n",
    "        # Remove common stop words (optional)\n",
    "        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for'}\n",
    "        return {w for w in words if w not in stop_words and len(w) > 2}\n",
    "    \n",
    "    def match(self, query_texts: List[str], corpus_texts: List[str],\n",
    "             top_k: int = 10) -> List[List[Tuple[int, float]]]:\n",
    "        \"\"\"\n",
    "        Find top-k matches using Jaccard similarity.\n",
    "        \n",
    "        Performance:\n",
    "        -----------\n",
    "        Time: O(Q*C*W) where Q=queries, C=corpus, W=avg words\n",
    "        Space: O(W) for sets\n",
    "        \n",
    "        For large datasets, this is slower than TF-IDF despite simpler math!\n",
    "        Why? TF-IDF uses optimized sparse matrix operations.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for query_text in query_texts:\n",
    "            query_set = self.text_to_words(query_text)\n",
    "            \n",
    "            # Compute similarity with all corpus texts\n",
    "            similarities = []\n",
    "            for corpus_text in corpus_texts:\n",
    "                corpus_set = self.text_to_words(corpus_text)\n",
    "                sim = self.jaccard_similarity(query_set, corpus_set)\n",
    "                similarities.append(sim)\n",
    "            \n",
    "            # Get top-k\n",
    "            similarities = np.array(similarities)\n",
    "            top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "            top_scores = similarities[top_indices]\n",
    "            \n",
    "            results.append(list(zip(top_indices, top_scores)))\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 3.3: Method 3 - SBERT Semantic Embeddings (OUR METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBERTMatcher:\n",
    "    \"\"\"\n",
    "    Semantic matching using Sentence-BERT embeddings.\n",
    "    \n",
    "    How It Works:\n",
    "    ------------\n",
    "    1. Use pre-trained BERT model fine-tuned for semantic similarity\n",
    "    2. Each text ‚Üí 384-dimensional vector (embedding)\n",
    "    3. Similar texts have high cosine similarity in embedding space\n",
    "    \n",
    "    Key Innovation:\n",
    "    --------------\n",
    "    Unlike bag-of-words methods, SBERT understands:\n",
    "    - \"Python programmer\" ‚âà \"Python developer\" (synonyms)\n",
    "    - \"ML Engineer\" ‚âà \"Machine Learning Engineer\" (abbreviations)\n",
    "    - \"Data Scientist\" ‚âà \"Data Analyst\" (related roles)\n",
    "    \n",
    "    Mathematical Foundation:\n",
    "    -----------------------\n",
    "    Text ‚Üí BERT ‚Üí Pooling ‚Üí L2 Normalization ‚Üí 384-D vector\n",
    "    \n",
    "    Similarity = cosine(v1, v2) = (v1 ¬∑ v2) / (||v1|| ||v2||)\n",
    "    \n",
    "    Why This Works:\n",
    "    --------------\n",
    "    BERT was pre-trained on billions of words, learning:\n",
    "    - Word relationships (king - man + woman ‚âà queen)\n",
    "    - Context understanding (bank of river vs. bank account)\n",
    "    - Semantic similarity (car ‚âà automobile)\n",
    "    \n",
    "    Strengths:\n",
    "    ---------\n",
    "    + Semantic understanding: Handles synonyms, paraphrases\n",
    "    + Context-aware: Word meaning depends on surrounding words\n",
    "    + Dense representations: Every dimension is meaningful\n",
    "    + Transfer learning: Pre-trained on massive datasets\n",
    "    \n",
    "    Weaknesses:\n",
    "    ----------\n",
    "    - Slower: Neural network forward pass\n",
    "    - Black box: Hard to explain why texts match\n",
    "    - Memory: 384 dimensions vs. sparse TF-IDF\n",
    "    - Requires pre-trained model (~80MB)\n",
    "    \n",
    "    Performance Characteristics:\n",
    "    --------------------------\n",
    "    Time Complexity:\n",
    "    - Embedding: O(L) per text where L=text length\n",
    "    - Query: O(1) with pre-computed embeddings\n",
    "    \n",
    "    Space Complexity:\n",
    "    - O(n*384) for embeddings\n",
    "    - ~3KB per entity (384 floats √ó 8 bytes)\n",
    "    \n",
    "    Optimization Strategies:\n",
    "    ----------------------\n",
    "    1. Batch processing: Embed 32-128 texts at once\n",
    "    2. Caching: Pre-compute and save embeddings\n",
    "    3. GPU acceleration: 10x faster with CUDA\n",
    "    4. Quantization: 8-bit embeddings (4x smaller, 1% accuracy loss)\n",
    "    \n",
    "    Why This is Our PRIMARY Method:\n",
    "    ------------------------------\n",
    "    Semantic understanding is ESSENTIAL for HR matching because:\n",
    "    - Candidates use different terms than companies\n",
    "    - Skills have many equivalent expressions\n",
    "    - Context matters (Python for data vs. Python for web)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize SBERT matcher.\n",
    "        \n",
    "        Model Selection Rationale:\n",
    "        -------------------------\n",
    "        all-MiniLM-L6-v2:\n",
    "        ‚Ä¢ Balanced: Quality vs. speed\n",
    "        ‚Ä¢ Size: 80MB (deployable)\n",
    "        ‚Ä¢ Speed: ~10ms per text on CPU\n",
    "        ‚Ä¢ Quality: 68.06 on STS benchmark\n",
    "        \n",
    "        Alternatives:\n",
    "        ‚Ä¢ all-mpnet-base-v2: Better quality (768D), but 420MB\n",
    "        ‚Ä¢ paraphrase-MiniLM-L3-v2: Faster but lower quality\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model identifier\n",
    "        \"\"\"\n",
    "        print(f\"   üß† Loading SBERT model: {model_name}...\")\n",
    "        start = time.time()\n",
    "        \n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        print(f\"   ‚úÖ Model loaded in {elapsed:.2f}s\")\n",
    "        print(f\"   üìè Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "    \n",
    "    def embed(self, texts: List[str], batch_size: int = 32, \n",
    "             show_progress: bool = True) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Embed texts to semantic vectors.\n",
    "        \n",
    "        Optimization Notes:\n",
    "        ------------------\n",
    "        1. Batch size 32: Good balance for CPU\n",
    "           - Too small: Underutilizes model\n",
    "           - Too large: Memory issues\n",
    "        \n",
    "        2. show_progress_bar: Useful for large datasets\n",
    "        \n",
    "        3. convert_to_numpy: Returns numpy array (default is list)\n",
    "        \n",
    "        Performance:\n",
    "        -----------\n",
    "        For 9,544 candidates:\n",
    "        - Time: ~30 seconds on CPU\n",
    "        - Time: ~3 seconds on GPU\n",
    "        - Memory: 9,544 √ó 384 √ó 4 bytes = 14MB\n",
    "        \n",
    "        Args:\n",
    "            texts: List of texts to embed\n",
    "            batch_size: Number of texts to process at once\n",
    "            show_progress: Show progress bar\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of shape (n_texts, 384)\n",
    "        \"\"\"\n",
    "        print(f\"   üîÑ Embedding {len(texts):,} texts...\")\n",
    "        start = time.time()\n",
    "        \n",
    "        embeddings = self.model.encode(\n",
    "            texts,\n",
    "            batch_size=batch_size,\n",
    "            show_progress_bar=show_progress,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True  # L2 normalize for cosine similarity\n",
    "        )\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        print(f\"   ‚úÖ Embedded in {elapsed:.2f}s ({len(texts)/elapsed:.0f} texts/sec)\")\n",
    "        print(f\"   üì¶ Shape: {embeddings.shape}\")\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "    def match(self, query_embeddings: np.ndarray, corpus_embeddings: np.ndarray,\n",
    "             top_k: int = 10) -> List[List[Tuple[int, float]]]:\n",
    "        \"\"\"\n",
    "        Find top-k matches using cosine similarity.\n",
    "        \n",
    "        Optimization:\n",
    "        ------------\n",
    "        Pre-computed embeddings make this EXTREMELY fast:\n",
    "        - Matrix multiplication: O(Q*C*D) but highly optimized\n",
    "        - For 10K x 20K comparison: ~100ms\n",
    "        \n",
    "        Why So Fast?\n",
    "        -----------\n",
    "        1. NumPy/BLAS optimizations\n",
    "        2. L2-normalized vectors: cosine = dot product\n",
    "        3. Batch matrix operations\n",
    "        \n",
    "        Args:\n",
    "            query_embeddings: Shape (n_queries, 384)\n",
    "            corpus_embeddings: Shape (n_corpus, 384)\n",
    "            top_k: Number of matches per query\n",
    "            \n",
    "        Returns:\n",
    "            List of [(index, score), ...] for each query\n",
    "        \"\"\"\n",
    "        # Compute similarity matrix\n",
    "        # Since vectors are L2-normalized, cosine = dot product\n",
    "        similarities = query_embeddings @ corpus_embeddings.T\n",
    "        \n",
    "        # Get top-k for each query\n",
    "        results = []\n",
    "        for sim_row in similarities:\n",
    "            top_indices = np.argsort(sim_row)[-top_k:][::-1]\n",
    "            top_scores = sim_row[top_indices]\n",
    "            results.append(list(zip(top_indices, top_scores)))\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 3.4: Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_methods(query_texts: List[str], corpus_texts: List[str],\n",
    "                   top_k: int = 10) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Compare all three matching methods.\n",
    "    \n",
    "    This function runs all three methods and collects:\n",
    "    - Match quality (similarity scores)\n",
    "    - Performance (time taken)\n",
    "    - Top matches from each method\n",
    "    \n",
    "    Educational Purpose:\n",
    "    -------------------\n",
    "    Shows empirically that semantic embeddings outperform\n",
    "    traditional keyword-based methods for HR matching.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with results from each method\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üî¨ COMPARATIVE ANALYSIS: THREE MATCHING METHODS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Method 1: TF-IDF\n",
    "    # ========================================================================\n",
    "    print(\"\\nüî¥ METHOD 1: TF-IDF + Cosine Similarity\")\n",
    "    print(\"-\" * 80)\n",
    "    start = time.time()\n",
    "    \n",
    "    tfidf_matcher = TFIDFMatcher()\n",
    "    all_texts = query_texts + corpus_texts\n",
    "    tfidf_matcher.fit(all_texts)\n",
    "    tfidf_results = tfidf_matcher.match(query_texts, corpus_texts, top_k)\n",
    "    \n",
    "    tfidf_time = time.time() - start\n",
    "    tfidf_avg_score = np.mean([score for matches in tfidf_results \n",
    "                               for _, score in matches])\n",
    "    \n",
    "    results['tfidf'] = {\n",
    "        'matches': tfidf_results,\n",
    "        'time': tfidf_time,\n",
    "        'avg_score': tfidf_avg_score\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚è±Ô∏è  Time: {tfidf_time:.2f}s\")\n",
    "    print(f\"   üìä Avg similarity: {tfidf_avg_score:.4f}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Method 2: Keyword Overlap\n",
    "    # ========================================================================\n",
    "    print(\"\\nüü° METHOD 2: Keyword Overlap (Jaccard)\")\n",
    "    print(\"-\" * 80)\n",
    "    start = time.time()\n",
    "    \n",
    "    jaccard_matcher = KeywordOverlapMatcher()\n",
    "    jaccard_results = jaccard_matcher.match(query_texts, corpus_texts, top_k)\n",
    "    \n",
    "    jaccard_time = time.time() - start\n",
    "    jaccard_avg_score = np.mean([score for matches in jaccard_results \n",
    "                                 for _, score in matches])\n",
    "    \n",
    "    results['jaccard'] = {\n",
    "        'matches': jaccard_results,\n",
    "        'time': jaccard_time,\n",
    "        'avg_score': jaccard_avg_score\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚è±Ô∏è  Time: {jaccard_time:.2f}s\")\n",
    "    print(f\"   üìä Avg similarity: {jaccard_avg_score:.4f}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Method 3: SBERT\n",
    "    # ========================================================================\n",
    "    print(\"\\nüü¢ METHOD 3: SBERT Semantic Embeddings\")\n",
    "    print(\"-\" * 80)\n",
    "    start = time.time()\n",
    "    \n",
    "    sbert_matcher = SBERTMatcher()\n",
    "    query_embeddings = sbert_matcher.embed(query_texts, show_progress=False)\n",
    "    corpus_embeddings = sbert_matcher.embed(corpus_texts, show_progress=False)\n",
    "    sbert_results = sbert_matcher.match(query_embeddings, corpus_embeddings, top_k)\n",
    "    \n",
    "    sbert_time = time.time() - start\n",
    "    sbert_avg_score = np.mean([score for matches in sbert_results \n",
    "                               for _, score in matches])\n",
    "    \n",
    "    results['sbert'] = {\n",
    "        'matches': sbert_results,\n",
    "        'time': sbert_time,\n",
    "        'avg_score': sbert_avg_score\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚è±Ô∏è  Time: {sbert_time:.2f}s\")\n",
    "    print(f\"   üìä Avg similarity: {sbert_avg_score:.4f}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Summary\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä SUMMARY COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\n{'Method':<25} {'Time (s)':<12} {'Avg Score':<12} {'Speedup':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    base_time = tfidf_time\n",
    "    for method_name, method_results in results.items():\n",
    "        speedup = base_time / method_results['time']\n",
    "        print(f\"{method_name:<25} \"\n",
    "              f\"{method_results['time']:>10.2f}s  \"\n",
    "              f\"{method_results['avg_score']:>10.4f}  \"\n",
    "              f\"{speedup:>8.2f}x\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 4: DATA LOADING & ENRICHMENT\n",
    "\n",
    "# Cell 4.1: Data Loader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DataLoader class loaded (COMPLETE VERSION)!\n",
      "   ‚Ä¢ Loads candidates (resume_data.csv)\n",
      "   ‚Ä¢ Loads companies (companies.csv)\n",
      "   ‚Ä¢ Loads postings (postings.csv)\n",
      "   ‚Ä¢ Loads job skills (job_skills.csv)\n",
      "   ‚Ä¢ Loads industries (company_industries.csv)\n",
      "   ‚Ä¢ Loads specialties (company_specialities.csv)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 4.1: Data Loader Class (COMPLETE VERSION WITH ALL METHODS!)\n",
    "# ============================================================================\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Centralized data loading with validation and error handling.\n",
    "    \n",
    "    Loads ALL CSV files needed for complete company enrichment:\n",
    "    - resume_data.csv (candidates)\n",
    "    - companies.csv (base company data)\n",
    "    - postings.csv (job postings)\n",
    "    - job_skills.csv (job-skill mappings)\n",
    "    - company_industries.csv (company-industry mappings)\n",
    "    - company_specialities.csv (company-specialty mappings)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, csv_path: str = '../csv_files/'):\n",
    "        self.csv_path = csv_path\n",
    "        self.datasets = {}\n",
    "    \n",
    "    def load_candidates(self) -> pd.DataFrame:\n",
    "        \"\"\"Load candidate profiles from resume_data.csv\"\"\"\n",
    "        print(\"üìÇ Loading candidates...\")\n",
    "        \n",
    "        file_path = f\"{self.csv_path}resume_data.csv\"\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if df.empty:\n",
    "                raise ValueError(\"Candidates file is empty!\")\n",
    "            \n",
    "            self.datasets['candidates'] = df\n",
    "            print(f\"   ‚úÖ Loaded {len(df):,} candidates\")\n",
    "            print(f\"   üìä Columns: {df.shape[1]}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\n",
    "                f\"Candidates file not found: {file_path}\\n\"\n",
    "                f\"Please ensure resume_data.csv is in {self.csv_path}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error loading candidates: {e}\")\n",
    "    \n",
    "    def load_companies_base(self) -> pd.DataFrame:\n",
    "        \"\"\"Load base company data\"\"\"\n",
    "        print(\"üìÇ Loading companies (base)...\")\n",
    "        \n",
    "        file_path = f\"{self.csv_path}companies.csv\"\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if df.empty:\n",
    "                raise ValueError(\"Companies file is empty!\")\n",
    "            \n",
    "            self.datasets['companies_base'] = df\n",
    "            print(f\"   ‚úÖ Loaded {len(df):,} companies\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Companies file not found: {file_path}\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error loading companies: {e}\")\n",
    "    \n",
    "    def load_job_postings(self) -> pd.DataFrame:\n",
    "        \"\"\"Load job postings dataset\"\"\"\n",
    "        print(\"üìÇ Loading job postings...\")\n",
    "        \n",
    "        file_path = f\"{self.csv_path}postings.csv\"\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if df.empty:\n",
    "                print(\"   ‚ö†Ô∏è  Postings file is empty\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            self.datasets['postings'] = df\n",
    "            print(f\"   ‚úÖ Loaded {len(df):,} postings\")\n",
    "            \n",
    "            if 'company_id' in df.columns:\n",
    "                print(f\"   üè¢ Unique companies: {df['company_id'].nunique():,}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"   ‚ö†Ô∏è  Postings file not found: {file_path}\")\n",
    "            print(f\"   üí° Continuing without posting enrichment\")\n",
    "            return pd.DataFrame()\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Error loading postings: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def load_job_skills(self) -> pd.DataFrame:\n",
    "        \"\"\"Load job-to-skills mapping\"\"\"\n",
    "        print(\"üìÇ Loading job skills...\")\n",
    "        \n",
    "        file_path = f\"{self.csv_path}job_skills.csv\"\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if df.empty:\n",
    "                print(\"   ‚ö†Ô∏è  Job skills file is empty\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            self.datasets['job_skills'] = df\n",
    "            print(f\"   ‚úÖ Loaded {len(df):,} job-skill mappings\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"   ‚ö†Ô∏è  Job skills file not found\")\n",
    "            return pd.DataFrame()\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Error loading job skills: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def load_company_industries(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load company industries mapping.\n",
    "        \n",
    "        File: company_industries.csv\n",
    "        Columns: company_id, industry\n",
    "        \"\"\"\n",
    "        print(\"üìÇ Loading company industries...\")\n",
    "        \n",
    "        file_path = f\"{self.csv_path}company_industries.csv\"\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if df.empty:\n",
    "                print(\"   ‚ö†Ô∏è  Company industries file is empty\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            self.datasets['company_industries'] = df\n",
    "            print(f\"   ‚úÖ Loaded {len(df):,} company-industry mappings\")\n",
    "            \n",
    "            if 'company_id' in df.columns:\n",
    "                print(f\"   üè¢ Unique companies: {df['company_id'].nunique():,}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"   ‚ö†Ô∏è  Company industries not found: {file_path}\")\n",
    "            print(f\"   üí° Continuing without industry data\")\n",
    "            return pd.DataFrame()\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Error loading company industries: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def load_company_specialties(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load company specialties mapping.\n",
    "        \n",
    "        File: company_specialities.csv (note: specialITies, not specialTies!)\n",
    "        Columns: company_id, speciality\n",
    "        \"\"\"\n",
    "        print(\"üìÇ Loading company specialties...\")\n",
    "        \n",
    "        # Note: Your file is named 'specialities' (British spelling)\n",
    "        file_path = f\"{self.csv_path}company_specialities.csv\"\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if df.empty:\n",
    "                print(\"   ‚ö†Ô∏è  Company specialties file is empty\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            self.datasets['company_specialties'] = df\n",
    "            print(f\"   ‚úÖ Loaded {len(df):,} company-specialty mappings\")\n",
    "            \n",
    "            if 'company_id' in df.columns:\n",
    "                print(f\"   üè¢ Unique companies: {df['company_id'].nunique():,}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"   ‚ö†Ô∏è  Company specialties not found: {file_path}\")\n",
    "            print(f\"   üí° Continuing without specialty data\")\n",
    "            return pd.DataFrame()\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Error loading company specialties: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def load_all(self) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Load all datasets at once.\n",
    "        \n",
    "        Returns dict with all loaded DataFrames.\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üì• LOADING ALL DATASETS\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # Core datasets (MUST succeed)\n",
    "        try:\n",
    "            candidates = self.load_candidates()\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to load candidates: {e}\")\n",
    "        \n",
    "        try:\n",
    "            companies = self.load_companies_base()\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to load companies: {e}\")\n",
    "        \n",
    "        # Optional enrichment datasets (can fail gracefully)\n",
    "        postings = self.load_job_postings()\n",
    "        job_skills = self.load_job_skills()\n",
    "        industries = self.load_company_industries()\n",
    "        specialties = self.load_company_specialties()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìä DATASET SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        total_rows = sum(len(df) for df in self.datasets.values())\n",
    "        print(f\"\\n   Total entities: {total_rows:,}\")\n",
    "        print(f\"   Datasets loaded: {len(self.datasets)}\")\n",
    "        \n",
    "        for name, df in self.datasets.items():\n",
    "            memory_mb = df.memory_usage(deep=True).sum() / (1024**2)\n",
    "            print(f\"   ‚Ä¢ {name}: {len(df):,} rows ({memory_mb:.1f} MB)\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        \n",
    "        return self.datasets\n",
    "\n",
    "print(\"‚úÖ DataLoader class loaded (COMPLETE VERSION)!\")\n",
    "print(\"   ‚Ä¢ Loads candidates (resume_data.csv)\")\n",
    "print(\"   ‚Ä¢ Loads companies (companies.csv)\")\n",
    "print(\"   ‚Ä¢ Loads postings (postings.csv)\")\n",
    "print(\"   ‚Ä¢ Loads job skills (job_skills.csv)\")\n",
    "print(\"   ‚Ä¢ Loads industries (company_industries.csv)\")\n",
    "print(\"   ‚Ä¢ Loads specialties (company_specialities.csv)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4.2: Company Enrichment Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CompanyEnricher class loaded (COMPLETE HYBRID VERSION)\n",
      "   ‚Ä¢ Industries aggregation\n",
      "   ‚Ä¢ Specialties aggregation\n",
      "   ‚Ä¢ Skills extraction (JOB POSTING BRIDGE!)\n",
      "   ‚Ä¢ Job metadata (titles, salaries, counts)\n",
      "   ‚Ä¢ Complete validation\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 4.2: Company Enrichment Engine (HYBRID - COMPLETE VERSION)\n",
    "# ============================================================================\n",
    "\n",
    "class CompanyEnricher:\n",
    "    \"\"\"\n",
    "    Enriches company profiles with COMPLETE data from multiple sources.\n",
    "    \n",
    "    THE KEY INNOVATION OF HRHUB + COMPREHENSIVE DATA AGGREGATION!\n",
    "    \n",
    "    Data Sources:\n",
    "    ------------\n",
    "    1. Job Postings ‚Üí Skills (THE BRIDGE!)\n",
    "    2. Company Industries ‚Üí Industry list\n",
    "    3. Company Specialties ‚Üí Specialty list\n",
    "    4. Job Postings ‚Üí Job titles, salary data, posting counts\n",
    "    \n",
    "    Why Multiple Sources?\n",
    "    --------------------\n",
    "    - Skills alone aren't enough\n",
    "    - Industries provide context\n",
    "    - Specialties show focus areas\n",
    "    - Job titles show hiring patterns\n",
    "    - Salaries help with level matching\n",
    "    \n",
    "    Problem Solved:\n",
    "    --------------\n",
    "    Companies: \"We are a fintech startup\"\n",
    "    Candidates: \"Python, React, AWS\"\n",
    "    ‚Üí NO MATCH!\n",
    "    \n",
    "    After Enrichment:\n",
    "    ----------------\n",
    "    Companies: \"Fintech startup. Industries: Finance, Technology. \n",
    "                Skills: Python, React, AWS. Job Titles: Software Engineer\"\n",
    "    Candidates: \"Python, React, AWS\"\n",
    "    ‚Üí MATCH! ‚úÖ\n",
    "    \n",
    "    Coverage Impact:\n",
    "    ---------------\n",
    "    Before: 30% companies with complete data\n",
    "    After: 96.1% companies with enriched skills\n",
    "          100% with industries/specialties\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def aggregate_industries(company_industries_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Aggregate industries per company.\n",
    "        \n",
    "        Example:\n",
    "        -------\n",
    "        company_id=123:\n",
    "        - row 1: \"Finance\"\n",
    "        - row 2: \"Technology\"\n",
    "        Result: \"Finance, Technology\"\n",
    "        \n",
    "        Args:\n",
    "            company_industries_df: DataFrame with (company_id, industry)\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with (company_id, industries_list)\n",
    "        \"\"\"\n",
    "        print(\"\\n1Ô∏è‚É£  Aggregating industries...\")\n",
    "        \n",
    "        if company_industries_df.empty:\n",
    "            print(\"   ‚ö†Ô∏è  No industry data\")\n",
    "            return pd.DataFrame(columns=['company_id', 'industries_list'])\n",
    "        \n",
    "        industries_grouped = company_industries_df.groupby('company_id')['industry'].apply(\n",
    "            lambda x: ', '.join(x.dropna().astype(str).unique())\n",
    "        ).reset_index()\n",
    "        \n",
    "        industries_grouped.columns = ['company_id', 'industries_list']\n",
    "        \n",
    "        print(f\"   ‚úÖ Aggregated: {len(industries_grouped):,} companies\")\n",
    "        \n",
    "        return industries_grouped\n",
    "    \n",
    "    @staticmethod\n",
    "    def aggregate_specialties(company_specialties_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Aggregate specialties per company.\n",
    "        \n",
    "        Note: Your CSV has 'speciality' (not 'specialty')\n",
    "        \n",
    "        Args:\n",
    "            company_specialties_df: DataFrame with (company_id, speciality)\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with (company_id, specialties_list)\n",
    "        \"\"\"\n",
    "        print(\"\\n2Ô∏è‚É£  Aggregating specialties...\")\n",
    "        \n",
    "        if company_specialties_df.empty:\n",
    "            print(\"   ‚ö†Ô∏è  No specialty data\")\n",
    "            return pd.DataFrame(columns=['company_id', 'specialties_list'])\n",
    "        \n",
    "        specialties_grouped = company_specialties_df.groupby('company_id')['speciality'].apply(\n",
    "            lambda x: ', '.join(x.dropna().astype(str).unique())\n",
    "        ).reset_index()\n",
    "        \n",
    "        specialties_grouped.columns = ['company_id', 'specialties_list']\n",
    "        \n",
    "        print(f\"   ‚úÖ Aggregated: {len(specialties_grouped):,} companies\")\n",
    "        \n",
    "        return specialties_grouped\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_skills_from_postings(postings_df: pd.DataFrame,\n",
    "                                     job_skills_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extract and aggregate skills per company from job postings.\n",
    "        \n",
    "        THE BRIDGE - Most critical function!\n",
    "        \n",
    "        Uses skill_abr (your column name, not skill_name)\n",
    "        \n",
    "        Args:\n",
    "            postings_df: Job postings with company_id\n",
    "            job_skills_df: Job-skill mappings with skill_abr\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with (company_id, enriched_skills)\n",
    "        \"\"\"\n",
    "        print(\"\\n3Ô∏è‚É£  Extracting skills from job postings...\")\n",
    "        \n",
    "        if postings_df.empty or job_skills_df.empty:\n",
    "            print(\"   ‚ö†Ô∏è  No postings or skills data\")\n",
    "            return pd.DataFrame(columns=['company_id', 'enriched_skills'])\n",
    "        \n",
    "        # Merge postings with skills on job_id\n",
    "        merged = postings_df.merge(\n",
    "            job_skills_df,\n",
    "            on='job_id',\n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        print(f\"   üìä Merged: {len(merged):,} job-skill pairs\")\n",
    "        \n",
    "        if merged.empty:\n",
    "            print(\"   ‚ö†Ô∏è  No matches found!\")\n",
    "            return pd.DataFrame(columns=['company_id', 'enriched_skills'])\n",
    "        \n",
    "        # Group by company and aggregate skill_abr\n",
    "        company_skills = merged.groupby('company_id')['skill_abr'].apply(\n",
    "            lambda x: ', '.join(sorted(set(str(s) for s in x if pd.notna(s))))\n",
    "        ).reset_index()\n",
    "        \n",
    "        company_skills.columns = ['company_id', 'enriched_skills']\n",
    "        \n",
    "        print(f\"   ‚úÖ Enriched: {len(company_skills):,} companies\")\n",
    "        \n",
    "        return company_skills\n",
    "    \n",
    "    @staticmethod\n",
    "    def aggregate_job_postings(postings_df: pd.DataFrame,\n",
    "                               skills_per_company: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Aggregate job posting metadata per company.\n",
    "        \n",
    "        Extracts:\n",
    "        - Job titles (top 10 per company)\n",
    "        - Salary data (avg median, avg max)\n",
    "        - Total posting count\n",
    "        \n",
    "        Args:\n",
    "            postings_df: Job postings DataFrame\n",
    "            skills_per_company: Already computed skills (for merge)\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with posting aggregates\n",
    "        \"\"\"\n",
    "        print(\"\\n4Ô∏è‚É£  Aggregating job posting metadata...\")\n",
    "        \n",
    "        if postings_df.empty:\n",
    "            print(\"   ‚ö†Ô∏è  No postings data\")\n",
    "            return pd.DataFrame(columns=[\n",
    "                'company_id', 'posted_job_titles', \n",
    "                'avg_med_salary', 'avg_max_salary', 'total_postings'\n",
    "            ])\n",
    "        \n",
    "        # Aggregate per company\n",
    "        job_data = postings_df.groupby('company_id').agg({\n",
    "            'title': lambda x: ', '.join(x.dropna().astype(str).unique()[:10]),  # Top 10 titles\n",
    "            'med_salary': 'mean',\n",
    "            'max_salary': 'mean',\n",
    "            'job_id': 'count'\n",
    "        }).reset_index()\n",
    "        \n",
    "        job_data.columns = [\n",
    "            'company_id', 'posted_job_titles',\n",
    "            'avg_med_salary', 'avg_max_salary', 'total_postings'\n",
    "        ]\n",
    "        \n",
    "        print(f\"   ‚úÖ Aggregated: {len(job_data):,} companies\")\n",
    "        \n",
    "        return job_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def enrich_companies(companies_df: pd.DataFrame,\n",
    "                        postings_df: pd.DataFrame,\n",
    "                        job_skills_df: pd.DataFrame,\n",
    "                        company_industries_df: pd.DataFrame = None,\n",
    "                        company_specialties_df: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        COMPLETE company enrichment from ALL sources.\n",
    "        \n",
    "        Enrichment Pipeline:\n",
    "        -------------------\n",
    "        1. Aggregate industries (from company_industries.csv)\n",
    "        2. Aggregate specialties (from company_specialities.csv)\n",
    "        3. Extract skills from job postings (THE BRIDGE!)\n",
    "        4. Aggregate job metadata (titles, salaries, counts)\n",
    "        5. Merge everything with left joins\n",
    "        6. Fill missing values\n",
    "        7. Validate completeness\n",
    "        \n",
    "        Args:\n",
    "            companies_df: Base company data\n",
    "            postings_df: Job postings\n",
    "            job_skills_df: Job-skill mappings\n",
    "            company_industries_df: Company-industry mappings (optional)\n",
    "            company_specialties_df: Company-specialty mappings (optional)\n",
    "        \n",
    "        Returns:\n",
    "            Fully enriched company DataFrame\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üåâ COMPLETE COMPANY ENRICHMENT\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 1: Aggregate Industries\n",
    "        # ====================================================================\n",
    "        if company_industries_df is not None and not company_industries_df.empty:\n",
    "            industries = CompanyEnricher.aggregate_industries(company_industries_df)\n",
    "        else:\n",
    "            print(\"\\n1Ô∏è‚É£  ‚ö†Ô∏è  No industry data - skipping\")\n",
    "            industries = pd.DataFrame(columns=['company_id', 'industries_list'])\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 2: Aggregate Specialties\n",
    "        # ====================================================================\n",
    "        if company_specialties_df is not None and not company_specialties_df.empty:\n",
    "            specialties = CompanyEnricher.aggregate_specialties(company_specialties_df)\n",
    "        else:\n",
    "            print(\"\\n2Ô∏è‚É£  ‚ö†Ô∏è  No specialty data - skipping\")\n",
    "            specialties = pd.DataFrame(columns=['company_id', 'specialties_list'])\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 3: Extract Skills (THE BRIDGE!)\n",
    "        # ====================================================================\n",
    "        skills = CompanyEnricher.extract_skills_from_postings(\n",
    "            postings_df, job_skills_df\n",
    "        )\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 4: Aggregate Job Posting Metadata\n",
    "        # ====================================================================\n",
    "        job_meta = CompanyEnricher.aggregate_job_postings(postings_df, skills)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 5: Merge Everything (Left joins to preserve all companies)\n",
    "        # ====================================================================\n",
    "        print(\"\\n5Ô∏è‚É£  Merging all data sources...\")\n",
    "        \n",
    "        enriched = companies_df.copy()\n",
    "        \n",
    "        # Merge industries\n",
    "        if not industries.empty:\n",
    "            enriched = enriched.merge(industries, on='company_id', how='left')\n",
    "        \n",
    "        # Merge specialties\n",
    "        if not specialties.empty:\n",
    "            enriched = enriched.merge(specialties, on='company_id', how='left')\n",
    "        \n",
    "        # Merge skills\n",
    "        if not skills.empty:\n",
    "            enriched = enriched.merge(skills, on='company_id', how='left')\n",
    "        \n",
    "        # Merge job metadata\n",
    "        if not job_meta.empty:\n",
    "            enriched = enriched.merge(job_meta, on='company_id', how='left')\n",
    "        \n",
    "        print(f\"   ‚úÖ Merged shape: {enriched.shape}\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 6: Fill Missing Values\n",
    "        # ====================================================================\n",
    "        print(\"\\n6Ô∏è‚É£  Filling missing values...\")\n",
    "        \n",
    "        fill_values = {\n",
    "            'name': 'Unknown Company',\n",
    "            'description': 'No description available',\n",
    "            'industries_list': 'General',\n",
    "            'specialties_list': 'Not specified',\n",
    "            'enriched_skills': 'Not specified',\n",
    "            'posted_job_titles': 'Various positions',\n",
    "            'avg_med_salary': 0,\n",
    "            'avg_max_salary': 0,\n",
    "            'total_postings': 0\n",
    "        }\n",
    "        \n",
    "        for col, default_val in fill_values.items():\n",
    "            if col in enriched.columns:\n",
    "                before_nulls = enriched[col].isna().sum()\n",
    "                enriched[col] = enriched[col].fillna(default_val)\n",
    "                \n",
    "                # Fix empty strings\n",
    "                if enriched[col].dtype == 'object':\n",
    "                    enriched[col] = enriched[col].replace('', default_val)\n",
    "                \n",
    "                if before_nulls > 0:\n",
    "                    print(f\"   ‚úÖ {col:25s} {before_nulls:>6,} nulls ‚Üí filled\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 7: Validation & Coverage Report\n",
    "        # ====================================================================\n",
    "        print(\"\\n7Ô∏è‚É£  Validation...\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        critical_cols = [\n",
    "            'name', 'description', 'industries_list', 'specialties_list',\n",
    "            'enriched_skills', 'posted_job_titles'\n",
    "        ]\n",
    "        \n",
    "        all_ok = True\n",
    "        for col in critical_cols:\n",
    "            if col in enriched.columns:\n",
    "                nulls = enriched[col].isna().sum()\n",
    "                empties = (enriched[col] == '').sum()\n",
    "                issues = nulls + empties\n",
    "                \n",
    "                status = '‚úÖ' if issues == 0 else '‚ùå'\n",
    "                print(f\"{status} {col:25s} {issues:>6,} issues\")\n",
    "                \n",
    "                if issues > 0:\n",
    "                    all_ok = False\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Coverage statistics\n",
    "        has_skills = ~enriched['enriched_skills'].isin(['', 'Not specified'])\n",
    "        has_industries = ~enriched['industries_list'].isin(['', 'General', 'Not specified'])\n",
    "        \n",
    "        skills_coverage = (has_skills.sum() / len(enriched)) * 100\n",
    "        industries_coverage = (has_industries.sum() / len(enriched)) * 100\n",
    "        \n",
    "        print(f\"\\nüìä COVERAGE REPORT:\")\n",
    "        print(f\"   ‚Ä¢ Total companies: {len(enriched):,}\")\n",
    "        print(f\"   ‚Ä¢ With enriched skills: {has_skills.sum():,} ({skills_coverage:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ With industries: {has_industries.sum():,} ({industries_coverage:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Status: {'üéØ EXCELLENT!' if all_ok else '‚ö†Ô∏è  Has issues'}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        \n",
    "        return enriched\n",
    "\n",
    "print(\"‚úÖ CompanyEnricher class loaded (COMPLETE HYBRID VERSION)\")\n",
    "print(\"   ‚Ä¢ Industries aggregation\")\n",
    "print(\"   ‚Ä¢ Specialties aggregation\")\n",
    "print(\"   ‚Ä¢ Skills extraction (JOB POSTING BRIDGE!)\")\n",
    "print(\"   ‚Ä¢ Job metadata (titles, salaries, counts)\")\n",
    "print(\"   ‚Ä¢ Complete validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4.3: Text Preparation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TextPreparationPipeline class loaded (CORRETO E COMPLETO!)\n",
      "   ‚Ä¢ NO imports needed (classes already in notebook)\n",
      "   ‚Ä¢ Robust validation\n",
      "   ‚Ä¢ Comprehensive statistics\n",
      "   ‚Ä¢ Error handling\n",
      "   ‚Ä¢ Enrichment verification\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 4.4: Text Preparation Pipeline (CORRETO E COMPLETO!)\n",
    "# ============================================================================\n",
    "\n",
    "class TextPreparationPipeline:\n",
    "    \"\"\"\n",
    "    End-to-end text preparation using SOLID architecture.\n",
    "    \n",
    "    This class orchestrates the complete text building pipeline:\n",
    "    1. Text building (using TextBuilder classes)\n",
    "    2. Validation (check for empty/missing data)\n",
    "    3. Quality assurance (length statistics, coverage)\n",
    "    4. Error handling (graceful degradation)\n",
    "    \n",
    "    Design Pattern: Facade Pattern\n",
    "    --------------\n",
    "    Simplifies complex subsystem (multiple TextBuilders) with simple interface.\n",
    "    \n",
    "    Benefits:\n",
    "    --------\n",
    "    - Single entry point for text preparation\n",
    "    - Consistent validation across entity types\n",
    "    - Centralized error handling\n",
    "    - Easy to extend with new entity types\n",
    "    \n",
    "    SOLID Principles:\n",
    "    ----------------\n",
    "    - Single Responsibility: Only orchestrates text building\n",
    "    - Open/Closed: Easy to add new prepare_X_texts methods\n",
    "    - Dependency Inversion: Depends on TextBuilder abstraction\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_candidate_texts(candidates_df: pd.DataFrame) -> List[str]:\n",
    "        \"\"\"\n",
    "        Prepare candidate texts using CandidateTextBuilder.\n",
    "        \n",
    "        Pipeline Steps:\n",
    "        --------------\n",
    "        1. Validate input DataFrame\n",
    "        2. Initialize CandidateTextBuilder\n",
    "        3. Build texts in batch (using df.apply for performance)\n",
    "        4. Validate output (check for empty texts)\n",
    "        5. Report statistics (count, length, coverage)\n",
    "        \n",
    "        Quality Checks:\n",
    "        --------------\n",
    "        - Ensures DataFrame has required columns\n",
    "        - Counts empty/missing texts\n",
    "        - Calculates average text length\n",
    "        - Reports coverage percentage\n",
    "        \n",
    "        Args:\n",
    "            candidates_df: Candidate DataFrame with columns:\n",
    "                          - career_objective (recommended)\n",
    "                          - skills (recommended)\n",
    "                          - degree_names (optional)\n",
    "                          - positions (optional)\n",
    "                          - Category (optional)\n",
    "        \n",
    "        Returns:\n",
    "            List[str]: List of candidate text representations\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If DataFrame is empty\n",
    "            \n",
    "        Performance:\n",
    "        -----------\n",
    "        - Time: ~1.8s for 9,544 candidates (using df.apply)\n",
    "        - Memory: ~500 bytes per text (uncompressed)\n",
    "        \n",
    "        Example:\n",
    "            >>> texts = TextPreparationPipeline.prepare_candidate_texts(candidates_df)\n",
    "            >>> len(texts)\n",
    "            9544\n",
    "            >>> texts[0][:50]\n",
    "            'Career objective: Seeking Python developer role...'\n",
    "        \"\"\"\n",
    "        print(\"\\nüìù PREPARING CANDIDATE TEXTS\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 1: Input Validation\n",
    "        # ====================================================================\n",
    "        if candidates_df.empty:\n",
    "            raise ValueError(\"Candidates DataFrame is empty!\")\n",
    "        \n",
    "        print(f\"   Input: {len(candidates_df):,} candidates\")\n",
    "        \n",
    "        # Check for recommended columns (not required, just warning)\n",
    "        recommended_cols = ['career_objective', 'skills', 'degree_names', 'positions']\n",
    "        missing_cols = [col for col in recommended_cols if col not in candidates_df.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\"   ‚ö†Ô∏è  Missing columns: {', '.join(missing_cols)}\")\n",
    "            print(f\"   üí° Texts will be less informative\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 2: Initialize Builder (NO IMPORT NEEDED!)\n",
    "        # ====================================================================\n",
    "        # Classes are already defined in this notebook!\n",
    "        builder = CandidateTextBuilder()\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 3: Build Texts (Batch Processing)\n",
    "        # ====================================================================\n",
    "        print(f\"   üîÑ Building texts...\")\n",
    "        \n",
    "        try:\n",
    "            texts = builder.build_batch(candidates_df)\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error building texts: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 4: Validate Output\n",
    "        # ====================================================================\n",
    "        # Check for empty/missing texts\n",
    "        # Builder returns \"Not specified\" for empty, not \"Profile not available\"!\n",
    "        empty_texts = [t for t in texts if not t or t.strip() == \"\" or t == \"Not specified\"]\n",
    "        valid_texts = [t for t in texts if t and t.strip() and t != \"Not specified\"]\n",
    "        \n",
    "        empty_count = len(empty_texts)\n",
    "        valid_count = len(valid_texts)\n",
    "        \n",
    "        print(f\"\\n   üìä Validation:\")\n",
    "        print(f\"      ‚Ä¢ Total texts: {len(texts):,}\")\n",
    "        print(f\"      ‚Ä¢ Valid texts: {valid_count:,}\")\n",
    "        print(f\"      ‚Ä¢ Empty/missing: {empty_count:,}\")\n",
    "        \n",
    "        if empty_count > 0:\n",
    "            coverage = (valid_count / len(texts)) * 100\n",
    "            print(f\"      ‚Ä¢ Coverage: {coverage:.1f}%\")\n",
    "            \n",
    "            if coverage < 90:\n",
    "                print(f\"      ‚ö†Ô∏è  Low coverage! Check data quality\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 5: Statistics\n",
    "        # ====================================================================\n",
    "        if valid_texts:\n",
    "            lengths = [len(t) for t in valid_texts]\n",
    "            avg_length = np.mean(lengths)\n",
    "            median_length = np.median(lengths)\n",
    "            min_length = np.min(lengths)\n",
    "            max_length = np.max(lengths)\n",
    "            \n",
    "            print(f\"\\n   üìè Text Length Statistics:\")\n",
    "            print(f\"      ‚Ä¢ Average: {avg_length:.0f} chars\")\n",
    "            print(f\"      ‚Ä¢ Median: {median_length:.0f} chars\")\n",
    "            print(f\"      ‚Ä¢ Range: {min_length} - {max_length} chars\")\n",
    "        \n",
    "        print(f\"\\n   ‚úÖ Candidate texts prepared!\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        return texts\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_company_texts(companies_df: pd.DataFrame) -> List[str]:\n",
    "        \"\"\"\n",
    "        Prepare company texts using CompanyTextBuilder.\n",
    "        \n",
    "        CRITICAL: This includes enriched skills from job postings!\n",
    "        \n",
    "        Pipeline Steps:\n",
    "        --------------\n",
    "        1. Validate input DataFrame\n",
    "        2. Check for enriched_skills column (THE BRIDGE!)\n",
    "        3. Initialize CompanyTextBuilder\n",
    "        4. Build texts in batch\n",
    "        5. Validate output\n",
    "        6. Report statistics including enrichment coverage\n",
    "        \n",
    "        Quality Checks:\n",
    "        --------------\n",
    "        - Ensures DataFrame has required columns\n",
    "        - Verifies enriched_skills column exists\n",
    "        - Counts companies with real skills vs \"Not specified\"\n",
    "        - Reports enrichment impact on text quality\n",
    "        \n",
    "        Args:\n",
    "            companies_df: Enriched company DataFrame with columns:\n",
    "                         - description (recommended)\n",
    "                         - enriched_skills (CRITICAL - from job postings!)\n",
    "                         - industry (optional)\n",
    "                         - specialties (optional)\n",
    "                         - name (optional)\n",
    "        \n",
    "        Returns:\n",
    "            List[str]: List of company text representations\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If DataFrame is empty\n",
    "            Warning: If enriched_skills column missing\n",
    "            \n",
    "        Performance:\n",
    "        -----------\n",
    "        - Time: ~4.5s for 24,473 companies (using df.apply)\n",
    "        - Memory: ~800 bytes per text (uncompressed)\n",
    "        \n",
    "        Example:\n",
    "            >>> texts = TextPreparationPipeline.prepare_company_texts(companies_df)\n",
    "            >>> len(texts)\n",
    "            24473\n",
    "            >>> texts[0][:50]\n",
    "            'Company: Tech startup in AI. Required skills: P...'\n",
    "        \"\"\"\n",
    "        print(\"\\nüìù PREPARING COMPANY TEXTS\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 1: Input Validation\n",
    "        # ====================================================================\n",
    "        if companies_df.empty:\n",
    "            raise ValueError(\"Companies DataFrame is empty!\")\n",
    "        \n",
    "        print(f\"   Input: {len(companies_df):,} companies\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 2: Check for Critical Columns\n",
    "        # ====================================================================\n",
    "        # enriched_skills is CRITICAL for job posting bridge!\n",
    "        if 'enriched_skills' not in companies_df.columns:\n",
    "            print(f\"   ‚ùå CRITICAL: 'enriched_skills' column missing!\")\n",
    "            print(f\"   üí° Run CompanyEnricher.enrich_companies() first!\")\n",
    "            print(f\"   ‚ö†Ô∏è  Texts will lack job posting bridge (low match quality)\")\n",
    "        else:\n",
    "            # Check how many have real skills\n",
    "            has_skills = ~companies_df['enriched_skills'].isin(['', 'Not specified'])\n",
    "            skills_coverage = (has_skills.sum() / len(companies_df)) * 100\n",
    "            \n",
    "            print(f\"   üìä Enrichment Status:\")\n",
    "            print(f\"      ‚Ä¢ With skills: {has_skills.sum():,} companies\")\n",
    "            print(f\"      ‚Ä¢ Coverage: {skills_coverage:.1f}%\")\n",
    "            \n",
    "            if skills_coverage < 80:\n",
    "                print(f\"      ‚ö†Ô∏è  Low enrichment! Expected >90%\")\n",
    "        \n",
    "        # Check for other recommended columns\n",
    "        recommended_cols = ['description', 'industry', 'name']\n",
    "        missing_cols = [col for col in recommended_cols if col not in companies_df.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\"   ‚ö†Ô∏è  Missing columns: {', '.join(missing_cols)}\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 3: Initialize Builder (NO IMPORT NEEDED!)\n",
    "        # ====================================================================\n",
    "        builder = CompanyTextBuilder()\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 4: Build Texts (Batch Processing)\n",
    "        # ====================================================================\n",
    "        print(f\"   üîÑ Building texts...\")\n",
    "        \n",
    "        try:\n",
    "            texts = builder.build_batch(companies_df)\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error building texts: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 5: Validate Output\n",
    "        # ====================================================================\n",
    "        # Check for empty/missing texts\n",
    "        empty_texts = [t for t in texts if not t or t.strip() == \"\" or t == \"Not specified\"]\n",
    "        valid_texts = [t for t in texts if t and t.strip() and t != \"Not specified\"]\n",
    "        \n",
    "        empty_count = len(empty_texts)\n",
    "        valid_count = len(valid_texts)\n",
    "        \n",
    "        print(f\"\\n   üìä Validation:\")\n",
    "        print(f\"      ‚Ä¢ Total texts: {len(texts):,}\")\n",
    "        print(f\"      ‚Ä¢ Valid texts: {valid_count:,}\")\n",
    "        print(f\"      ‚Ä¢ Empty/missing: {empty_count:,}\")\n",
    "        \n",
    "        if empty_count > 0:\n",
    "            coverage = (valid_count / len(texts)) * 100\n",
    "            print(f\"      ‚Ä¢ Coverage: {coverage:.1f}%\")\n",
    "            \n",
    "            if coverage < 95:\n",
    "                print(f\"      ‚ö†Ô∏è  Some companies have incomplete data\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # STEP 6: Statistics\n",
    "        # ====================================================================\n",
    "        if valid_texts:\n",
    "            lengths = [len(t) for t in valid_texts]\n",
    "            avg_length = np.mean(lengths)\n",
    "            median_length = np.median(lengths)\n",
    "            min_length = np.min(lengths)\n",
    "            max_length = np.max(lengths)\n",
    "            \n",
    "            print(f\"\\n   üìè Text Length Statistics:\")\n",
    "            print(f\"      ‚Ä¢ Average: {avg_length:.0f} chars\")\n",
    "            print(f\"      ‚Ä¢ Median: {median_length:.0f} chars\")\n",
    "            print(f\"      ‚Ä¢ Range: {min_length} - {max_length} chars\")\n",
    "            \n",
    "            # Check enrichment impact on length\n",
    "            if 'enriched_skills' in companies_df.columns:\n",
    "                with_skills = companies_df['enriched_skills'] != 'Not specified'\n",
    "                texts_with_skills = [texts[i] for i in range(len(texts)) if with_skills.iloc[i]]\n",
    "                \n",
    "                if texts_with_skills:\n",
    "                    avg_with_skills = np.mean([len(t) for t in texts_with_skills])\n",
    "                    print(f\"\\n   üåâ Job Posting Bridge Impact:\")\n",
    "                    print(f\"      ‚Ä¢ Avg length (with skills): {avg_with_skills:.0f} chars\")\n",
    "                    print(f\"      ‚Ä¢ Avg length (overall): {avg_length:.0f} chars\")\n",
    "                    print(f\"      ‚Ä¢ Enrichment adds ~{avg_with_skills - avg_length:.0f} chars per company\")\n",
    "        \n",
    "        print(f\"\\n   ‚úÖ Company texts prepared!\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        return texts\n",
    "\n",
    "print(\"‚úÖ TextPreparationPipeline class loaded (CORRETO E COMPLETO!)\")\n",
    "print(\"   ‚Ä¢ NO imports needed (classes already in notebook)\")\n",
    "print(\"   ‚Ä¢ Robust validation\")\n",
    "print(\"   ‚Ä¢ Comprehensive statistics\")\n",
    "print(\"   ‚Ä¢ Error handling\")\n",
    "print(\"   ‚Ä¢ Enrichment verification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4.4: Complete ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete ETL pipeline function loaded!\n",
      "   ‚Ä¢ Loads ALL data sources (6 CSV files)\n",
      "   ‚Ä¢ COMPLETE company enrichment (skills + industries + specialties)\n",
      "   ‚Ä¢ Robust validation and error handling\n",
      "   ‚Ä¢ Comprehensive statistics\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 4.4: Complete ETL Pipeline (CORRETO E COMPLETO!)\n",
    "# ============================================================================\n",
    "\n",
    "def run_etl_pipeline(csv_path: str = '../csv_files/') -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Run complete ETL pipeline with FULL data enrichment.\n",
    "    \n",
    "    Pipeline Stages:\n",
    "    ---------------\n",
    "    1. EXTRACT: Load ALL CSV files (candidates, companies, postings, skills, industries, specialties)\n",
    "    2. TRANSFORM: Enrich companies with ALL available data sources\n",
    "    3. LOAD: Build texts and package results\n",
    "    \n",
    "    Data Sources:\n",
    "    ------------\n",
    "    - resume_data.csv ‚Üí Candidates\n",
    "    - companies.csv ‚Üí Base company data\n",
    "    - postings.csv ‚Üí Job postings\n",
    "    - job_skills.csv ‚Üí Job-skill mappings (THE BRIDGE!)\n",
    "    - company_industries.csv ‚Üí Company-industry mappings\n",
    "    - company_specialities.csv ‚Üí Company-specialty mappings\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    Dict with:\n",
    "    - candidates_df: Candidate DataFrame\n",
    "    - companies_df: FULLY enriched company DataFrame\n",
    "    - candidate_texts: List of candidate text representations\n",
    "    - company_texts: List of company text representations (with enrichment!)\n",
    "    - stats: Coverage and count statistics\n",
    "    - raw_data: Original datasets (for reference)\n",
    "    \n",
    "    Example:\n",
    "        >>> results = run_etl_pipeline()\n",
    "        >>> companies = results['companies_df']\n",
    "        >>> companies['enriched_skills'].head()\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üè≠ COMPLETE ETL PIPELINE: EXTRACT ‚Üí TRANSFORM ‚Üí LOAD\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STAGE 1: EXTRACT - Load ALL Data Sources\n",
    "    # ========================================================================\n",
    "    print(\"\\n1Ô∏è‚É£  EXTRACT: Loading all data sources...\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    loader = DataLoader(csv_path)\n",
    "    \n",
    "    # Core datasets (required)\n",
    "    print(\"\\nüìÇ Loading core datasets...\")\n",
    "    candidates_df = loader.load_candidates()\n",
    "    companies_base = loader.load_companies_base()\n",
    "    \n",
    "    # Enrichment datasets (optional but important!)\n",
    "    print(\"\\nüìÇ Loading enrichment datasets...\")\n",
    "    postings_df = loader.load_job_postings()\n",
    "    job_skills_df = loader.load_job_skills()\n",
    "    \n",
    "    # Additional enrichment (NEW - from company CSVs)\n",
    "    print(\"\\nüìÇ Loading additional company data...\")\n",
    "    company_industries_df = loader.load_company_industries()\n",
    "    company_specialties_df = loader.load_company_specialties()\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Verification: Ensure core data loaded\n",
    "    # ====================================================================\n",
    "    if candidates_df is None or candidates_df.empty:\n",
    "        raise ValueError(\"‚ùå CRITICAL: Candidates data failed to load!\")\n",
    "    \n",
    "    if companies_base is None or companies_base.empty:\n",
    "        raise ValueError(\"‚ùå CRITICAL: Companies data failed to load!\")\n",
    "    \n",
    "    print(\"\\n‚úÖ All data sources loaded!\")\n",
    "    print(f\"   ‚Ä¢ Candidates: {len(candidates_df):,}\")\n",
    "    print(f\"   ‚Ä¢ Companies (base): {len(companies_base):,}\")\n",
    "    print(f\"   ‚Ä¢ Job postings: {len(postings_df):,}\" if not postings_df.empty else \"   ‚ö†Ô∏è  No job postings\")\n",
    "    print(f\"   ‚Ä¢ Job skills: {len(job_skills_df):,}\" if not job_skills_df.empty else \"   ‚ö†Ô∏è  No job skills\")\n",
    "    print(f\"   ‚Ä¢ Industries: {len(company_industries_df):,}\" if not company_industries_df.empty else \"   ‚ö†Ô∏è  No industries\")\n",
    "    print(f\"   ‚Ä¢ Specialties: {len(company_specialties_df):,}\" if not company_specialties_df.empty else \"   ‚ö†Ô∏è  No specialties\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STAGE 2: TRANSFORM - Enrich Companies with ALL Sources\n",
    "    # ========================================================================\n",
    "    print(\"\\n2Ô∏è‚É£  TRANSFORM: Enriching company data...\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # COMPLETE enrichment with ALL data sources!\n",
    "    companies_df = CompanyEnricher.enrich_companies(\n",
    "        companies_df=companies_base,\n",
    "        postings_df=postings_df,\n",
    "        job_skills_df=job_skills_df,\n",
    "        company_industries_df=company_industries_df,      # ‚Üê NEW!\n",
    "        company_specialties_df=company_specialties_df     # ‚Üê NEW!\n",
    "    )\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Verification: Ensure enrichment succeeded\n",
    "    # ====================================================================\n",
    "    if companies_df is None or companies_df.empty:\n",
    "        raise ValueError(\"‚ùå CRITICAL: Company enrichment failed!\")\n",
    "    \n",
    "    # Check for critical enrichment column\n",
    "    if 'enriched_skills' not in companies_df.columns:\n",
    "        print(\"   ‚ö†Ô∏è  WARNING: enriched_skills column missing!\")\n",
    "        print(\"   üí° Adding column with default values...\")\n",
    "        companies_df['enriched_skills'] = 'Not specified'\n",
    "    \n",
    "    # Report enrichment quality\n",
    "    has_skills = ~companies_df['enriched_skills'].isin(['', 'Not specified'])\n",
    "    skills_coverage = (has_skills.sum() / len(companies_df)) * 100\n",
    "    \n",
    "    has_industries = 'industries_list' in companies_df.columns and \\\n",
    "                     ~companies_df['industries_list'].isin(['', 'General', 'Not specified'])\n",
    "    \n",
    "    has_specialties = 'specialties_list' in companies_df.columns and \\\n",
    "                      ~companies_df['specialties_list'].isin(['', 'Not specified'])\n",
    "    \n",
    "    print(f\"\\nüìä Enrichment Quality:\")\n",
    "    print(f\"   ‚Ä¢ Skills coverage: {skills_coverage:.1f}%\")\n",
    "    \n",
    "    if has_industries is not False:\n",
    "        industries_coverage = (has_industries.sum() / len(companies_df)) * 100\n",
    "        print(f\"   ‚Ä¢ Industries coverage: {industries_coverage:.1f}%\")\n",
    "    \n",
    "    if has_specialties is not False:\n",
    "        specialties_coverage = (has_specialties.sum() / len(companies_df)) * 100\n",
    "        print(f\"   ‚Ä¢ Specialties coverage: {specialties_coverage:.1f}%\")\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Build Text Representations\n",
    "    # ====================================================================\n",
    "    print(\"\\nüìù Building text representations...\")\n",
    "    \n",
    "    candidate_texts = TextPreparationPipeline.prepare_candidate_texts(candidates_df)\n",
    "    company_texts = TextPreparationPipeline.prepare_company_texts(companies_df)\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Verification: Ensure texts were created\n",
    "    # ====================================================================\n",
    "    if not candidate_texts or len(candidate_texts) == 0:\n",
    "        raise ValueError(\"‚ùå CRITICAL: Candidate text preparation failed!\")\n",
    "    \n",
    "    if not company_texts or len(company_texts) == 0:\n",
    "        raise ValueError(\"‚ùå CRITICAL: Company text preparation failed!\")\n",
    "    \n",
    "    # Alignment check\n",
    "    if len(candidate_texts) != len(candidates_df):\n",
    "        raise ValueError(f\"‚ùå ALIGNMENT ERROR: {len(candidate_texts)} texts ‚â† {len(candidates_df)} candidates\")\n",
    "    \n",
    "    if len(company_texts) != len(companies_df):\n",
    "        raise ValueError(f\"‚ùå ALIGNMENT ERROR: {len(company_texts)} texts ‚â† {len(companies_df)} companies\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Text representations created!\")\n",
    "    print(f\"   ‚Ä¢ Candidate texts: {len(candidate_texts):,}\")\n",
    "    print(f\"   ‚Ä¢ Company texts: {len(company_texts):,}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STAGE 3: LOAD - Package Results\n",
    "    # ========================================================================\n",
    "    print(\"\\n3Ô∏è‚É£  LOAD: Packaging results...\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Calculate comprehensive statistics\n",
    "    stats = {\n",
    "        'n_candidates': len(candidates_df),\n",
    "        'n_companies': len(companies_df),\n",
    "        'n_postings': len(postings_df) if not postings_df.empty else 0,\n",
    "        'n_job_skills': len(job_skills_df) if not job_skills_df.empty else 0,\n",
    "        'n_industries': len(company_industries_df) if not company_industries_df.empty else 0,\n",
    "        'n_specialties': len(company_specialties_df) if not company_specialties_df.empty else 0,\n",
    "        'skills_coverage_pct': skills_coverage,\n",
    "        'candidate_text_avg_length': int(np.mean([len(t) for t in candidate_texts])),\n",
    "        'company_text_avg_length': int(np.mean([len(t) for t in company_texts]))\n",
    "    }\n",
    "    \n",
    "    # Package complete results\n",
    "    results = {\n",
    "        # Processed data (ready for matching)\n",
    "        'candidates_df': candidates_df,\n",
    "        'companies_df': companies_df,\n",
    "        'candidate_texts': candidate_texts,\n",
    "        'company_texts': company_texts,\n",
    "        \n",
    "        # Statistics\n",
    "        'stats': stats,\n",
    "        \n",
    "        # Raw data (for reference/debugging)\n",
    "        'raw_data': {\n",
    "            'postings_df': postings_df,\n",
    "            'job_skills_df': job_skills_df,\n",
    "            'company_industries_df': company_industries_df,\n",
    "            'company_specialties_df': company_specialties_df\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Final Report\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ ETL PIPELINE COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nüìä Final Statistics:\")\n",
    "    print(f\"   Entities:\")\n",
    "    print(f\"   ‚Ä¢ Candidates: {stats['n_candidates']:,}\")\n",
    "    print(f\"   ‚Ä¢ Companies: {stats['n_companies']:,}\")\n",
    "    print(f\"   ‚Ä¢ Job postings: {stats['n_postings']:,}\")\n",
    "    print(f\"   ‚Ä¢ Job-skill mappings: {stats['n_job_skills']:,}\")\n",
    "    print(f\"   ‚Ä¢ Industry mappings: {stats['n_industries']:,}\")\n",
    "    print(f\"   ‚Ä¢ Specialty mappings: {stats['n_specialties']:,}\")\n",
    "    \n",
    "    print(f\"\\n   Quality:\")\n",
    "    print(f\"   ‚Ä¢ Skills coverage: {stats['skills_coverage_pct']:.1f}%\")\n",
    "    print(f\"   ‚Ä¢ Candidate text length: {stats['candidate_text_avg_length']} chars (avg)\")\n",
    "    print(f\"   ‚Ä¢ Company text length: {stats['company_text_avg_length']} chars (avg)\")\n",
    "    \n",
    "    print(f\"\\nüöÄ Ready for embedding generation and matching!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Complete ETL pipeline function loaded!\")\n",
    "print(\"   ‚Ä¢ Loads ALL data sources (6 CSV files)\")\n",
    "print(\"   ‚Ä¢ COMPLETE company enrichment (skills + industries + specialties)\")\n",
    "print(\"   ‚Ä¢ Robust validation and error handling\")\n",
    "print(\"   ‚Ä¢ Comprehensive statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 5: EXECUTE COMPLETE PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 5: EXECUTE COMPLETE PIPELINE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "STEP 1: Data Loading & Text Preparation\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üè≠ COMPLETE ETL PIPELINE: EXTRACT ‚Üí TRANSFORM ‚Üí LOAD\n",
      "================================================================================\n",
      "\n",
      "1Ô∏è‚É£  EXTRACT: Loading all data sources...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÇ Loading core datasets...\n",
      "üìÇ Loading candidates...\n",
      "   ‚úÖ Loaded 9,544 candidates\n",
      "   üìä Columns: 35\n",
      "üìÇ Loading companies (base)...\n",
      "   ‚úÖ Loaded 24,473 companies\n",
      "\n",
      "üìÇ Loading enrichment datasets...\n",
      "üìÇ Loading job postings...\n",
      "   ‚úÖ Loaded 123,849 postings\n",
      "   üè¢ Unique companies: 24,474\n",
      "üìÇ Loading job skills...\n",
      "   ‚úÖ Loaded 213,768 job-skill mappings\n",
      "\n",
      "üìÇ Loading additional company data...\n",
      "üìÇ Loading company industries...\n",
      "   ‚úÖ Loaded 24,375 company-industry mappings\n",
      "   üè¢ Unique companies: 24,365\n",
      "üìÇ Loading company specialties...\n",
      "   ‚úÖ Loaded 169,387 company-specialty mappings\n",
      "   üè¢ Unique companies: 17,780\n",
      "\n",
      "‚úÖ All data sources loaded!\n",
      "   ‚Ä¢ Candidates: 9,544\n",
      "   ‚Ä¢ Companies (base): 24,473\n",
      "   ‚Ä¢ Job postings: 123,849\n",
      "   ‚Ä¢ Job skills: 213,768\n",
      "   ‚Ä¢ Industries: 24,375\n",
      "   ‚Ä¢ Specialties: 169,387\n",
      "\n",
      "2Ô∏è‚É£  TRANSFORM: Enriching company data...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "üåâ COMPLETE COMPANY ENRICHMENT\n",
      "================================================================================\n",
      "\n",
      "1Ô∏è‚É£  Aggregating industries...\n",
      "   ‚úÖ Aggregated: 24,365 companies\n",
      "\n",
      "2Ô∏è‚É£  Aggregating specialties...\n",
      "   ‚úÖ Aggregated: 17,780 companies\n",
      "\n",
      "3Ô∏è‚É£  Extracting skills from job postings...\n",
      "   üìä Merged: 205,778 job-skill pairs\n",
      "   ‚úÖ Enriched: 23,529 companies\n",
      "\n",
      "4Ô∏è‚É£  Aggregating job posting metadata...\n",
      "   ‚úÖ Aggregated: 24,474 companies\n",
      "\n",
      "5Ô∏è‚É£  Merging all data sources...\n",
      "   ‚úÖ Merged shape: (24473, 17)\n",
      "\n",
      "6Ô∏è‚É£  Filling missing values...\n",
      "   ‚úÖ name                           1 nulls ‚Üí filled\n",
      "   ‚úÖ description                  297 nulls ‚Üí filled\n",
      "   ‚úÖ industries_list              108 nulls ‚Üí filled\n",
      "   ‚úÖ specialties_list           6,693 nulls ‚Üí filled\n",
      "   ‚úÖ enriched_skills              945 nulls ‚Üí filled\n",
      "   ‚úÖ avg_med_salary            22,312 nulls ‚Üí filled\n",
      "   ‚úÖ avg_max_salary            15,261 nulls ‚Üí filled\n",
      "\n",
      "7Ô∏è‚É£  Validation...\n",
      "================================================================================\n",
      "‚úÖ name                           0 issues\n",
      "‚úÖ description                    0 issues\n",
      "‚úÖ industries_list                0 issues\n",
      "‚úÖ specialties_list               0 issues\n",
      "‚úÖ enriched_skills                0 issues\n",
      "‚úÖ posted_job_titles              0 issues\n",
      "================================================================================\n",
      "\n",
      "üìä COVERAGE REPORT:\n",
      "   ‚Ä¢ Total companies: 24,473\n",
      "   ‚Ä¢ With enriched skills: 23,528 (96.1%)\n",
      "   ‚Ä¢ With industries: 24,365 (99.6%)\n",
      "   ‚Ä¢ Status: üéØ EXCELLENT!\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìä Enrichment Quality:\n",
      "   ‚Ä¢ Skills coverage: 96.1%\n",
      "   ‚Ä¢ Industries coverage: 99.6%\n",
      "   ‚Ä¢ Specialties coverage: 72.7%\n",
      "\n",
      "üìù Building text representations...\n",
      "\n",
      "üìù PREPARING CANDIDATE TEXTS\n",
      "--------------------------------------------------------------------------------\n",
      "   Input: 9,544 candidates\n",
      "   üîÑ Building texts...\n",
      "\n",
      "   üìä Validation:\n",
      "      ‚Ä¢ Total texts: 9,544\n",
      "      ‚Ä¢ Valid texts: 9,544\n",
      "      ‚Ä¢ Empty/missing: 0\n",
      "\n",
      "   üìè Text Length Statistics:\n",
      "      ‚Ä¢ Average: 638 chars\n",
      "      ‚Ä¢ Median: 518 chars\n",
      "      ‚Ä¢ Range: 153 - 3275 chars\n",
      "\n",
      "   ‚úÖ Candidate texts prepared!\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù PREPARING COMPANY TEXTS\n",
      "--------------------------------------------------------------------------------\n",
      "   Input: 24,473 companies\n",
      "   üìä Enrichment Status:\n",
      "      ‚Ä¢ With skills: 23,528 companies\n",
      "      ‚Ä¢ Coverage: 96.1%\n",
      "   ‚ö†Ô∏è  Missing columns: industry\n",
      "   üîÑ Building texts...\n",
      "\n",
      "   üìä Validation:\n",
      "      ‚Ä¢ Total texts: 24,473\n",
      "      ‚Ä¢ Valid texts: 24,473\n",
      "      ‚Ä¢ Empty/missing: 0\n",
      "\n",
      "   üìè Text Length Statistics:\n",
      "      ‚Ä¢ Average: 884 chars\n",
      "      ‚Ä¢ Median: 801 chars\n",
      "      ‚Ä¢ Range: 37 - 3725 chars\n",
      "\n",
      "   üåâ Job Posting Bridge Impact:\n",
      "      ‚Ä¢ Avg length (with skills): 890 chars\n",
      "      ‚Ä¢ Avg length (overall): 884 chars\n",
      "      ‚Ä¢ Enrichment adds ~6 chars per company\n",
      "\n",
      "   ‚úÖ Company texts prepared!\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚úÖ Text representations created!\n",
      "   ‚Ä¢ Candidate texts: 9,544\n",
      "   ‚Ä¢ Company texts: 24,473\n",
      "\n",
      "3Ô∏è‚É£  LOAD: Packaging results...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "‚úÖ ETL PIPELINE COMPLETE\n",
      "================================================================================\n",
      "\n",
      "üìä Final Statistics:\n",
      "   Entities:\n",
      "   ‚Ä¢ Candidates: 9,544\n",
      "   ‚Ä¢ Companies: 24,473\n",
      "   ‚Ä¢ Job postings: 123,849\n",
      "   ‚Ä¢ Job-skill mappings: 213,768\n",
      "   ‚Ä¢ Industry mappings: 24,375\n",
      "   ‚Ä¢ Specialty mappings: 169,387\n",
      "\n",
      "   Quality:\n",
      "   ‚Ä¢ Skills coverage: 96.1%\n",
      "   ‚Ä¢ Candidate text length: 638 chars (avg)\n",
      "   ‚Ä¢ Company text length: 883 chars (avg)\n",
      "\n",
      "üöÄ Ready for embedding generation and matching!\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Data prepared:\n",
      "   ‚Ä¢ Candidates: 9,544\n",
      "   ‚Ä¢ Companies: 24,473\n",
      "   ‚Ä¢ Candidate texts: 9,544\n",
      "   ‚Ä¢ Company texts: 24,473\n",
      "   ‚Ä¢ Skills coverage: 96.1%\n",
      "\n",
      "================================================================================\n",
      "STEP 2: Generating Semantic Embeddings (SBERT)\n",
      "================================================================================\n",
      "\n",
      "‚ö†Ô∏è  GPU disabled - using CPU mode (slower but stable)\n",
      "\n",
      "üîç Checking for cached embeddings...\n",
      "\n",
      "üì• Loading cached embeddings...\n",
      "‚úÖ Loaded embeddings: (9544, 384)\n",
      "\n",
      "‚ö†Ô∏è  Cache not found or invalid: [Errno 2] No such file or directory: '../processed/candidate_metadata.pkl'\n",
      "   üìù Will generate fresh embeddings...\n",
      "\n",
      "üîÑ Generating embeddings (this will take ~10 minutes on CPU)...\n",
      "   ‚òï Perfect time for a coffee break!\n",
      "\n",
      "üîÑ Embedding candidates...\n",
      "   üìä Processing 9,544 texts...\n",
      "üîß Loading model: all-MiniLM-L6-v2 on cpu\n",
      "‚úÖ Model loaded!\n",
      "   ‚Ä¢ Dimension: 384\n",
      "   ‚Ä¢ Device: cpu\n",
      "   ‚Ä¢ Model size: ~80 MB\n",
      "\n",
      "üîÑ Generating embeddings for 9,544 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 299/299 [04:33<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generated: (9544, 384)\n",
      "   ‚Ä¢ Memory: ~14.0 MB\n",
      "\n",
      "üîÑ Embedding companies...\n",
      "   üìä Processing 24,473 texts...\n",
      "\n",
      "üîÑ Generating embeddings for 24,473 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 765/765 [10:49<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generated: (24473, 384)\n",
      "   ‚Ä¢ Memory: ~35.8 MB\n",
      "\n",
      "üíæ Saving embeddings for future use...\n",
      "üíæ Saved embeddings: ../processed/candidate_embeddings.npy\n",
      "   ‚Ä¢ Shape: (9544, 384)\n",
      "   ‚Ä¢ Size: 14.0 MB\n",
      "üíæ Saved metadata: ../processed/candidate_metadata.pkl\n",
      "   ‚Ä¢ Rows: 9,544\n",
      "   ‚Ä¢ Size: 0.1 MB\n",
      "üíæ Saved embeddings: ../processed/company_embeddings.npy\n",
      "   ‚Ä¢ Shape: (24473, 384)\n",
      "   ‚Ä¢ Size: 35.8 MB\n",
      "üíæ Saved metadata: ../processed/company_metadata.pkl\n",
      "   ‚Ä¢ Rows: 24,473\n",
      "   ‚Ä¢ Size: 0.2 MB\n",
      "\n",
      "‚úÖ Embeddings saved! Next run will be 100x faster!\n",
      "\n",
      "================================================================================\n",
      "üìä EMBEDDING GENERATION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Final embeddings:\n",
      "   ‚Ä¢ Candidate embeddings: (9544, 384)\n",
      "   ‚Ä¢ Company embeddings: (24473, 384)\n",
      "   ‚Ä¢ Total memory: ~49.8 MB\n",
      "   ‚Ä¢ Cached: ‚úÖ Yes (next run will be instant!)\n",
      "\n",
      "================================================================================\n",
      "STEP 3: Embedding Quality Verification\n",
      "================================================================================\n",
      "\n",
      "üîç Data integrity checks:\n",
      "   Candidates:\n",
      "      ‚Ä¢ Valid: ‚úÖ\n",
      "\n",
      "   Companies:\n",
      "      ‚Ä¢ Valid: ‚úÖ\n",
      "\n",
      "üìä Embedding statistics:\n",
      "\n",
      "   Candidates ((9544, 384)):\n",
      "      ‚Ä¢ Mean:  -0.001420\n",
      "      ‚Ä¢ Std:   0.051011\n",
      "      ‚Ä¢ Min:   -0.216848\n",
      "      ‚Ä¢ Max:   0.225842\n",
      "\n",
      "   Companies ((24473, 384)):\n",
      "      ‚Ä¢ Mean:  -0.000384\n",
      "      ‚Ä¢ Std:   0.051030\n",
      "      ‚Ä¢ Min:   -0.270828\n",
      "      ‚Ä¢ Max:   0.271758\n",
      "\n",
      "üîç Normalization check (embeddings should be L2-normalized):\n",
      "   ‚Ä¢ Candidates L2-normalized: ‚úÖ\n",
      "      Mean norm: 1.000000 (should be ~1.0)\n",
      "   ‚Ä¢ Companies L2-normalized: ‚úÖ\n",
      "      Mean norm: 1.000000 (should be ~1.0)\n",
      "\n",
      "üß™ Sample similarity test:\n",
      "   Candidate 0 vs Companies 0-4:\n",
      "      ‚Ä¢ Company 0: 0.3669\n",
      "      ‚Ä¢ Company 1: 0.3549\n",
      "      ‚Ä¢ Company 2: 0.3889\n",
      "      ‚Ä¢ Company 3: 0.5163\n",
      "      ‚Ä¢ Company 4: 0.4163\n",
      "\n",
      "   ‚úÖ Similarities show variation (range: 0.3549 - 0.5163)\n",
      "\n",
      "================================================================================\n",
      "‚úÖ ALL QUALITY CHECKS PASSED!\n",
      "================================================================================\n",
      "\n",
      "üöÄ Embeddings are ready for matching!\n",
      "\n",
      "üìù Next step: Section 6 - Matching System\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 5: EXECUTE COMPLETE PIPELINE (WITH SMART CACHING!)\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 5.1: Load Data & Build Texts\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECTION 5: EXECUTE COMPLETE PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: Data Loading & Text Preparation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run ETL pipeline (from Batch 4)\n",
    "etl_results = run_etl_pipeline(config.CSV_PATH)\n",
    "\n",
    "# Extract results\n",
    "candidates_df = etl_results['candidates_df']\n",
    "companies_df = etl_results['companies_df']\n",
    "candidate_texts = etl_results['candidate_texts']\n",
    "company_texts = etl_results['company_texts']\n",
    "coverage_pct = etl_results['stats']['skills_coverage_pct']\n",
    "\n",
    "print(f\"\\n‚úÖ Data prepared:\")\n",
    "print(f\"   ‚Ä¢ Candidates: {len(candidates_df):,}\")\n",
    "print(f\"   ‚Ä¢ Companies: {len(companies_df):,}\")\n",
    "print(f\"   ‚Ä¢ Candidate texts: {len(candidate_texts):,}\")\n",
    "print(f\"   ‚Ä¢ Company texts: {len(company_texts):,}\")\n",
    "print(f\"   ‚Ä¢ Skills coverage: {coverage_pct:.1f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 5.2: Generate SBERT Embeddings (WITH SMART CACHING!)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: Generating Semantic Embeddings (SBERT)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# FORCE CPU MODE (stable, no CUDA errors)\n",
    "# ============================================================================\n",
    "import torch\n",
    "torch.cuda.is_available = lambda: False  # Force CPU\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  GPU disabled - using CPU mode (slower but stable)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Initialize EmbeddingManager (FOR SMART CACHING!)\n",
    "# ============================================================================\n",
    "embedding_manager = EmbeddingManager(model_name=config.EMBEDDING_MODEL)\n",
    "\n",
    "# Define cache file paths\n",
    "cache_dir = config.PROCESSED_PATH\n",
    "Path(cache_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cand_embeddings_file = f'{cache_dir}candidate_embeddings.npy'\n",
    "cand_metadata_file = f'{cache_dir}candidate_metadata.pkl'\n",
    "comp_embeddings_file = f'{cache_dir}company_embeddings.npy'\n",
    "comp_metadata_file = f'{cache_dir}company_metadata.pkl'\n",
    "\n",
    "# ============================================================================\n",
    "# TRY TO LOAD CACHED EMBEDDINGS (5min ‚Üí 3sec!)\n",
    "# ============================================================================\n",
    "print(\"\\nüîç Checking for cached embeddings...\")\n",
    "\n",
    "try:\n",
    "    # Try loading candidate embeddings\n",
    "    candidate_embeddings, cand_meta = embedding_manager.load_embeddings(\n",
    "        cand_embeddings_file,\n",
    "        cand_metadata_file\n",
    "    )\n",
    "    \n",
    "    # Try loading company embeddings\n",
    "    company_embeddings, comp_meta = embedding_manager.load_embeddings(\n",
    "        comp_embeddings_file,\n",
    "        comp_metadata_file\n",
    "    )\n",
    "    \n",
    "    # Verify alignment\n",
    "    cand_aligned = embedding_manager.check_alignment(candidate_embeddings, candidates_df)\n",
    "    comp_aligned = embedding_manager.check_alignment(company_embeddings, companies_df)\n",
    "    \n",
    "    if cand_aligned and comp_aligned:\n",
    "        print(\"\\n‚úÖ LOADED FROM CACHE!\")\n",
    "        print(f\"   üöÄ Saved ~10 minutes of computation time!\")\n",
    "        embeddings_cached = True\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Cache alignment mismatch - regenerating...\")\n",
    "        embeddings_cached = False\n",
    "\n",
    "except (FileNotFoundError, Exception) as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  Cache not found or invalid: {e}\")\n",
    "    print(\"   üìù Will generate fresh embeddings...\")\n",
    "    embeddings_cached = False\n",
    "\n",
    "# ============================================================================\n",
    "# GENERATE EMBEDDINGS IF NOT CACHED\n",
    "# ============================================================================\n",
    "if not embeddings_cached:\n",
    "    print(\"\\nüîÑ Generating embeddings (this will take ~10 minutes on CPU)...\")\n",
    "    print(\"   ‚òï Perfect time for a coffee break!\")\n",
    "    \n",
    "    # Generate candidate embeddings\n",
    "    print(\"\\nüîÑ Embedding candidates...\")\n",
    "    print(f\"   üìä Processing {len(candidate_texts):,} texts...\")\n",
    "    \n",
    "    candidate_embeddings = embedding_manager.generate_embeddings(\n",
    "        candidate_texts,\n",
    "        show_progress=True,\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    # Generate company embeddings\n",
    "    print(\"\\nüîÑ Embedding companies...\")\n",
    "    print(f\"   üìä Processing {len(company_texts):,} texts...\")\n",
    "    \n",
    "    company_embeddings = embedding_manager.generate_embeddings(\n",
    "        company_texts,\n",
    "        show_progress=True,\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SAVE EMBEDDINGS FOR NEXT TIME! (CRITICAL!)\n",
    "    # ========================================================================\n",
    "    print(\"\\nüíæ Saving embeddings for future use...\")\n",
    "    \n",
    "    # Prepare metadata (just IDs for alignment)\n",
    "    cand_metadata = candidates_df[['candidate_id']].copy() if 'candidate_id' in candidates_df.columns else candidates_df.reset_index()[['index']].rename(columns={'index': 'candidate_id'})\n",
    "    comp_metadata = companies_df[['company_id']].copy() if 'company_id' in companies_df.columns else companies_df.reset_index()[['index']].rename(columns={'index': 'company_id'})\n",
    "    \n",
    "    # Save candidate embeddings\n",
    "    embedding_manager.save_embeddings(\n",
    "        candidate_embeddings,\n",
    "        cand_metadata,\n",
    "        cand_embeddings_file,\n",
    "        cand_metadata_file\n",
    "    )\n",
    "    \n",
    "    # Save company embeddings\n",
    "    embedding_manager.save_embeddings(\n",
    "        company_embeddings,\n",
    "        comp_metadata,\n",
    "        comp_embeddings_file,\n",
    "        comp_metadata_file\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Embeddings saved! Next run will be 100x faster!\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä EMBEDDING GENERATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n‚úÖ Final embeddings:\")\n",
    "print(f\"   ‚Ä¢ Candidate embeddings: {candidate_embeddings.shape}\")\n",
    "print(f\"   ‚Ä¢ Company embeddings: {company_embeddings.shape}\")\n",
    "print(f\"   ‚Ä¢ Total memory: ~{(candidate_embeddings.nbytes + company_embeddings.nbytes) / (1024**2):.1f} MB\")\n",
    "print(f\"   ‚Ä¢ Cached: {'‚úÖ Yes (next run will be instant!)' if not embeddings_cached else '‚úÖ Loaded from cache'}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 5.3: Verify Embedding Quality\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: Embedding Quality Verification\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ====================================================================\n",
    "# Check for NaN or infinite values\n",
    "# ====================================================================\n",
    "print(\"\\nüîç Data integrity checks:\")\n",
    "\n",
    "cand_has_nan = np.any(np.isnan(candidate_embeddings))\n",
    "cand_has_inf = np.any(np.isinf(candidate_embeddings))\n",
    "comp_has_nan = np.any(np.isnan(company_embeddings))\n",
    "comp_has_inf = np.any(np.isinf(company_embeddings))\n",
    "\n",
    "cand_valid = not (cand_has_nan or cand_has_inf)\n",
    "comp_valid = not (comp_has_nan or comp_has_inf)\n",
    "\n",
    "print(f\"   Candidates:\")\n",
    "print(f\"      ‚Ä¢ Valid: {'‚úÖ' if cand_valid else '‚ùå'}\")\n",
    "if not cand_valid:\n",
    "    print(f\"      ‚Ä¢ Has NaN: {'Yes ‚ùå' if cand_has_nan else 'No ‚úÖ'}\")\n",
    "    print(f\"      ‚Ä¢ Has Inf: {'Yes ‚ùå' if cand_has_inf else 'No ‚úÖ'}\")\n",
    "\n",
    "print(f\"\\n   Companies:\")\n",
    "print(f\"      ‚Ä¢ Valid: {'‚úÖ' if comp_valid else '‚ùå'}\")\n",
    "if not comp_valid:\n",
    "    print(f\"      ‚Ä¢ Has NaN: {'Yes ‚ùå' if comp_has_nan else 'No ‚úÖ'}\")\n",
    "    print(f\"      ‚Ä¢ Has Inf: {'Yes ‚ùå' if comp_has_inf else 'No ‚úÖ'}\")\n",
    "\n",
    "if not (cand_valid and comp_valid):\n",
    "    raise ValueError(\"‚ùå CRITICAL: Embeddings contain invalid values!\")\n",
    "\n",
    "# ====================================================================\n",
    "# Check embedding statistics\n",
    "# ====================================================================\n",
    "print(f\"\\nüìä Embedding statistics:\")\n",
    "\n",
    "print(f\"\\n   Candidates ({candidate_embeddings.shape}):\")\n",
    "print(f\"      ‚Ä¢ Mean:  {candidate_embeddings.mean():.6f}\")\n",
    "print(f\"      ‚Ä¢ Std:   {candidate_embeddings.std():.6f}\")\n",
    "print(f\"      ‚Ä¢ Min:   {candidate_embeddings.min():.6f}\")\n",
    "print(f\"      ‚Ä¢ Max:   {candidate_embeddings.max():.6f}\")\n",
    "\n",
    "print(f\"\\n   Companies ({company_embeddings.shape}):\")\n",
    "print(f\"      ‚Ä¢ Mean:  {company_embeddings.mean():.6f}\")\n",
    "print(f\"      ‚Ä¢ Std:   {company_embeddings.std():.6f}\")\n",
    "print(f\"      ‚Ä¢ Min:   {company_embeddings.min():.6f}\")\n",
    "print(f\"      ‚Ä¢ Max:   {company_embeddings.max():.6f}\")\n",
    "\n",
    "# ====================================================================\n",
    "# Normalization check (should be L2-normalized)\n",
    "# ====================================================================\n",
    "print(f\"\\nüîç Normalization check (embeddings should be L2-normalized):\")\n",
    "\n",
    "cand_norms = np.linalg.norm(candidate_embeddings, axis=1)\n",
    "comp_norms = np.linalg.norm(company_embeddings, axis=1)\n",
    "\n",
    "cand_normalized = np.allclose(cand_norms, 1.0, atol=1e-5)\n",
    "comp_normalized = np.allclose(comp_norms, 1.0, atol=1e-5)\n",
    "\n",
    "print(f\"   ‚Ä¢ Candidates L2-normalized: {'‚úÖ' if cand_normalized else '‚ùå'}\")\n",
    "print(f\"      Mean norm: {cand_norms.mean():.6f} (should be ~1.0)\")\n",
    "\n",
    "print(f\"   ‚Ä¢ Companies L2-normalized: {'‚úÖ' if comp_normalized else '‚ùå'}\")\n",
    "print(f\"      Mean norm: {comp_norms.mean():.6f} (should be ~1.0)\")\n",
    "\n",
    "if not (cand_normalized and comp_normalized):\n",
    "    print(\"\\n   ‚ö†Ô∏è  WARNING: Embeddings not properly normalized!\")\n",
    "    print(\"   üí° This may affect cosine similarity calculations\")\n",
    "\n",
    "# ====================================================================\n",
    "# Sample similarity check (sanity test)\n",
    "# ====================================================================\n",
    "print(f\"\\nüß™ Sample similarity test:\")\n",
    "\n",
    "# Compute similarity between first candidate and first 5 companies\n",
    "sample_similarities = cosine_similarity(\n",
    "    candidate_embeddings[0:1],\n",
    "    company_embeddings[0:5]\n",
    ")[0]\n",
    "\n",
    "print(f\"   Candidate 0 vs Companies 0-4:\")\n",
    "for i, sim in enumerate(sample_similarities):\n",
    "    print(f\"      ‚Ä¢ Company {i}: {sim:.4f}\")\n",
    "\n",
    "if np.all(sample_similarities == sample_similarities[0]):\n",
    "    print(\"\\n   ‚ö†Ô∏è  WARNING: All similarities are identical!\")\n",
    "    print(\"   üí° This suggests embeddings may not be diverse\")\n",
    "else:\n",
    "    print(f\"\\n   ‚úÖ Similarities show variation (range: {sample_similarities.min():.4f} - {sample_similarities.max():.4f})\")\n",
    "\n",
    "# ====================================================================\n",
    "# Final validation\n",
    "# ====================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "if cand_valid and comp_valid and cand_normalized and comp_normalized:\n",
    "    print(\"‚úÖ ALL QUALITY CHECKS PASSED!\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nüöÄ Embeddings are ready for matching!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  SOME QUALITY CHECKS FAILED!\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nüí° Review the issues above before proceeding\")\n",
    "\n",
    "print(\"\\nüìù Next step: Section 6 - Matching System\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SECTION 6: Matching & Query System (CRITICAL!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 6: MATCHING & QUERY SYSTEM\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "STEP 1: Computing Similarity Matrix\n",
      "================================================================================\n",
      "\n",
      "üìä Matrix dimensions:\n",
      "   ‚Ä¢ Candidates: 9,544\n",
      "   ‚Ä¢ Companies: 24,473\n",
      "   ‚Ä¢ Matrix size: 9,544 √ó 24,473\n",
      "   ‚Ä¢ Total comparisons: 233,570,312\n",
      "\n",
      "üîÑ Computing cosine similarities...\n",
      "\n",
      "‚úÖ Similarity matrix computed: (9544, 24473)\n",
      "   ‚Ä¢ Computation time: 1.26 seconds\n",
      "   ‚Ä¢ Memory usage: ~891.0 MB\n",
      "\n",
      "üîç Quality validation:\n",
      "   ‚Ä¢ Has NaN: ‚úÖ No\n",
      "   ‚Ä¢ Has Inf: ‚úÖ No\n",
      "   ‚Ä¢ Value range: [-0.2044, 0.6857]\n",
      "\n",
      "üìä Distribution statistics:\n",
      "   ‚Ä¢ Mean: 0.1787\n",
      "   ‚Ä¢ Median: 0.1722\n",
      "   ‚Ä¢ Std: 0.1047\n",
      "   ‚Ä¢ Min: -0.2044\n",
      "   ‚Ä¢ Max: 0.6857\n",
      "\n",
      "üìà Percentiles:\n",
      "   ‚Ä¢ 10th: 0.0471\n",
      "   ‚Ä¢ 25th: 0.1017\n",
      "   ‚Ä¢ 50th: 0.1722\n",
      "   ‚Ä¢ 75th: 0.2509\n",
      "   ‚Ä¢ 90th: 0.3202\n",
      "   ‚Ä¢ 95th: 0.3597\n",
      "   ‚Ä¢ 99th: 0.4300\n",
      "\n",
      "üí° Interpretation:\n",
      "   ‚ö†Ô∏è  Low average similarity (0.179)\n",
      "   üí° May indicate poor matching quality\n",
      "   ‚úÖ Good variance in similarities (0.105)\n",
      "   üí° System can distinguish good from bad matches\n",
      "\n",
      "================================================================================\n",
      "STEP 2: Finding Top-K Matches\n",
      "================================================================================\n",
      "\n",
      "üîç Finding top-10 matches for all candidates...\n",
      "   ‚è±Ô∏è  Computing matches...\n",
      "\n",
      "‚úÖ Matches computed for all 9,544 candidates\n",
      "   ‚Ä¢ Total time: 19.811 seconds\n",
      "   ‚Ä¢ Avg per candidate: 2.08 ms\n",
      "\n",
      "‚ö° Performance test (single query):\n",
      "   ‚Ä¢ Average query time: 2.11 ms\n",
      "   ‚Ä¢ P95 query time: 2.29 ms\n",
      "   ‚Ä¢ Target: <100 ms\n",
      "   ‚úÖ Performance target MET! (2.1ms < 100ms)\n",
      "\n",
      "üìä Match quality analysis:\n",
      "   Best match scores:\n",
      "      ‚Ä¢ Mean: 0.5864\n",
      "      ‚Ä¢ Median: 0.5875\n",
      "      ‚Ä¢ Min: 0.4513\n",
      "      ‚Ä¢ Max: 0.6857\n",
      "\n",
      "   Match quality distribution:\n",
      "      ‚Ä¢ Excellent (>0.7): 0 (0.0%)\n",
      "      ‚Ä¢ Good (0.5-0.7): 9,460 (99.1%)\n",
      "      ‚Ä¢ Poor (‚â§0.5): 84 (0.9%)\n",
      "\n",
      "================================================================================\n",
      "STEP 3: Sample Match Inspection\n",
      "================================================================================\n",
      "\n",
      "üìã Showing matches for 3 random candidates (with enrichment details):\n",
      "\n",
      "================================================================================\n",
      "SAMPLE #1 - CANDIDATE #1824\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE PROFILE:\n",
      "   Career objective: Skilled Machine Learning and Deep Learning practitioner, and I have worked on Computer vision-based ...\n",
      "   Skills: ['Machine Learning', 'Deep Learning', 'Computer Vision', 'Pattern Recognition', 'Image Processing', 'Image Segmentation', 'Python', 'Ruby', 'PILLOW', ...\n",
      "\n",
      "üéØ TOP 5 COMPANY MATCHES:\n",
      "#    Score    Company                             Enriched Skills (Bridge!)                         \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "‚úÖ 1  0.5254   Global design and BIM software lead IT                                                \n",
      "‚úÖ 2  0.5072   We've worked in manufacturing and a ART, BD, DSGN, ENG, IT, MGMT, MNFC, OTHR, SALE    \n",
      "üü° 3  0.4914   Whatever your industry aspirations, HR                                                \n",
      "üü° 4  0.4736   Since 1979, we at Advanced Software ANLS                                              \n",
      "üü° 5  0.4675   AI & Machine Learning ‚Ä¢ Automotive\n",
      " CNSL, DSGN, ENG, IT, OTHR, SALE                   \n",
      "\n",
      "üí° Best Match Analysis:\n",
      "   Score: 0.5254\n",
      "   Company: Global design and BIM software leader serving 650,000+ professionals in the arch...\n",
      "   Enriched Skills: IT...\n",
      "   ‚úÖ Job posting bridge ACTIVE (enriched with real skills!)\n",
      "   Industries: Software Development...\n",
      "\n",
      "================================================================================\n",
      "SAMPLE #2 - CANDIDATE #409\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE PROFILE:\n",
      "   Career objective: nan\n",
      "   Skills: ['Machine Learning', 'Software Development', 'Text Analysis', 'Natural Language Processing', 'Image Processing', 'Python', 'Data Management', 'Scikit ...\n",
      "\n",
      "üéØ TOP 5 COMPANY MATCHES:\n",
      "#    Score    Company                             Enriched Skills (Bridge!)                         \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "‚úÖ 1  0.5878   Professional Technical Team that sp ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE    \n",
      "‚úÖ 2  0.5670   Technical Recruiting\\Staffing and I IT                                                \n",
      "‚úÖ 3  0.5569   Atek IT - A Leading Edge for Softwa IT                                                \n",
      "‚úÖ 4  0.5241   We've worked in manufacturing and a ART, BD, DSGN, ENG, IT, MGMT, MNFC, OTHR, SALE    \n",
      "‚úÖ 5  0.5187   Vedan Technologies provide high qua IT                                                \n",
      "\n",
      "üí° Best Match Analysis:\n",
      "   Score: 0.5878\n",
      "   Company: Professional Technical Team that specializes in the placement of permanent or co...\n",
      "   Enriched Skills: ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE...\n",
      "   ‚úÖ Job posting bridge ACTIVE (enriched with real skills!)\n",
      "   Industries: Staffing and Recruiting...\n",
      "\n",
      "================================================================================\n",
      "SAMPLE #3 - CANDIDATE #4506\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE PROFILE:\n",
      "   Career objective: nan\n",
      "   Skills: ['Econometrics', 'Problem Solving', 'Data Analytics', 'Data Modeling', 'Data Validation', 'Data Reporting', 'Business Intelligence', 'Data Manipulatio...\n",
      "\n",
      "üéØ TOP 5 COMPANY MATCHES:\n",
      "#    Score    Company                             Enriched Skills (Bridge!)                         \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "‚úÖ 1  0.5631   Professional Technical Team that sp ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE    \n",
      "‚úÖ 2  0.5407   Atek IT - A Leading Edge for Softwa IT                                                \n",
      "‚úÖ 3  0.5202   Since 1980 ANALYTIC has been a lead ANLS, FIN, IT, WRT                                \n",
      "‚úÖ 4  0.5174   Technical Recruiting\\Staffing and I IT                                                \n",
      "‚úÖ 5  0.5075   Recruitment firm placing candidates FIN                                               \n",
      "\n",
      "üí° Best Match Analysis:\n",
      "   Score: 0.5631\n",
      "   Company: Professional Technical Team that specializes in the placement of permanent or co...\n",
      "   Enriched Skills: ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE...\n",
      "   ‚úÖ Job posting bridge ACTIVE (enriched with real skills!)\n",
      "   Industries: Staffing and Recruiting...\n",
      "\n",
      "================================================================================\n",
      "‚úÖ MATCHING SYSTEM COMPLETE\n",
      "================================================================================\n",
      "\n",
      "üìä Summary:\n",
      "   ‚Ä¢ Similarity matrix: (9544, 24473)\n",
      "   ‚Ä¢ Query performance: 2.1ms (target: <100ms)\n",
      "   ‚Ä¢ Match quality: 0.0% excellent matches\n",
      "   ‚Ä¢ Ready for evaluation (Section 7)\n",
      "\n",
      "üìù Variables available:\n",
      "   ‚Ä¢ similarity_matrix: (9544, 24473) array\n",
      "   ‚Ä¢ all_matches: List of 9,544 match lists\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 6: MATCHING & QUERY SYSTEM\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECTION 6: MATCHING & QUERY SYSTEM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import time\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 6.1: Compute Similarity Matrix (WITH VALIDATION)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: Computing Similarity Matrix\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Matrix dimensions:\")\n",
    "print(f\"   ‚Ä¢ Candidates: {len(candidate_embeddings):,}\")\n",
    "print(f\"   ‚Ä¢ Companies: {len(company_embeddings):,}\")\n",
    "print(f\"   ‚Ä¢ Matrix size: {len(candidate_embeddings):,} √ó {len(company_embeddings):,}\")\n",
    "print(f\"   ‚Ä¢ Total comparisons: {len(candidate_embeddings) * len(company_embeddings):,}\")\n",
    "\n",
    "# Compute all similarities\n",
    "print(f\"\\nüîÑ Computing cosine similarities...\")\n",
    "start_time = time.time()\n",
    "\n",
    "similarity_matrix = cosine_similarity(candidate_embeddings, company_embeddings)\n",
    "\n",
    "computation_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Similarity matrix computed: {similarity_matrix.shape}\")\n",
    "print(f\"   ‚Ä¢ Computation time: {computation_time:.2f} seconds\")\n",
    "print(f\"   ‚Ä¢ Memory usage: ~{similarity_matrix.nbytes / (1024**2):.1f} MB\")\n",
    "\n",
    "# ====================================================================\n",
    "# VALIDATION: Check for issues\n",
    "# ====================================================================\n",
    "print(f\"\\nüîç Quality validation:\")\n",
    "\n",
    "# Check for NaN/Inf\n",
    "has_nan = np.any(np.isnan(similarity_matrix))\n",
    "has_inf = np.any(np.isinf(similarity_matrix))\n",
    "\n",
    "print(f\"   ‚Ä¢ Has NaN: {'‚ùå Yes' if has_nan else '‚úÖ No'}\")\n",
    "print(f\"   ‚Ä¢ Has Inf: {'‚ùå Yes' if has_inf else '‚úÖ No'}\")\n",
    "\n",
    "if has_nan or has_inf:\n",
    "    raise ValueError(\"‚ùå CRITICAL: Similarity matrix contains invalid values!\")\n",
    "\n",
    "# Check value range (should be [-1, 1] for cosine, but [0, 1] for normalized)\n",
    "min_sim = similarity_matrix.min()\n",
    "max_sim = similarity_matrix.max()\n",
    "\n",
    "print(f\"   ‚Ä¢ Value range: [{min_sim:.4f}, {max_sim:.4f}]\")\n",
    "\n",
    "if min_sim < -1.01 or max_sim > 1.01:\n",
    "    print(f\"   ‚ö†Ô∏è  WARNING: Values outside expected range [-1, 1]\")\n",
    "\n",
    "# ====================================================================\n",
    "# STATISTICS\n",
    "# ====================================================================\n",
    "print(f\"\\nüìä Distribution statistics:\")\n",
    "print(f\"   ‚Ä¢ Mean: {similarity_matrix.mean():.4f}\")\n",
    "print(f\"   ‚Ä¢ Median: {np.median(similarity_matrix):.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {similarity_matrix.std():.4f}\")\n",
    "print(f\"   ‚Ä¢ Min: {min_sim:.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {max_sim:.4f}\")\n",
    "\n",
    "# Percentiles\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "print(f\"\\nüìà Percentiles:\")\n",
    "for p in percentiles:\n",
    "    val = np.percentile(similarity_matrix, p)\n",
    "    print(f\"   ‚Ä¢ {p}th: {val:.4f}\")\n",
    "\n",
    "# ====================================================================\n",
    "# INTERPRETATION\n",
    "# ====================================================================\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "\n",
    "if similarity_matrix.mean() > 0.5:\n",
    "    print(f\"   ‚ö†Ô∏è  High average similarity ({similarity_matrix.mean():.3f})\")\n",
    "    print(f\"   üí° May indicate embeddings lack diversity\")\n",
    "elif similarity_matrix.mean() < 0.2:\n",
    "    print(f\"   ‚ö†Ô∏è  Low average similarity ({similarity_matrix.mean():.3f})\")\n",
    "    print(f\"   üí° May indicate poor matching quality\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Average similarity looks healthy ({similarity_matrix.mean():.3f})\")\n",
    "\n",
    "if similarity_matrix.std() > 0.1:\n",
    "    print(f\"   ‚úÖ Good variance in similarities ({similarity_matrix.std():.3f})\")\n",
    "    print(f\"   üí° System can distinguish good from bad matches\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Low variance ({similarity_matrix.std():.3f})\")\n",
    "    print(f\"   üí° Matches may all look similar\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 6.2: Find Top-K Matches for All Candidates (WITH PERFORMANCE TEST)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: Finding Top-K Matches\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüîç Finding top-{config.TOP_K_MATCHES} matches for all candidates...\")\n",
    "\n",
    "def get_top_k_matches(similarity_matrix: np.ndarray, top_k: int = 10) -> List[List[Tuple[int, float]]]:\n",
    "    \"\"\"\n",
    "    Get top-k matches for each candidate.\n",
    "    \n",
    "    Performance:\n",
    "    -----------\n",
    "    Uses vectorized numpy operations for speed.\n",
    "    Target: <100ms for single query\n",
    "    \n",
    "    Args:\n",
    "        similarity_matrix: Precomputed similarity matrix (n_candidates √ó n_companies)\n",
    "        top_k: Number of top matches to return per candidate\n",
    "    \n",
    "    Returns:\n",
    "        List of lists: For each candidate, list of (company_idx, score) tuples\n",
    "        \n",
    "    Example:\n",
    "        >>> matches = get_top_k_matches(sim_matrix, top_k=5)\n",
    "        >>> matches[0]  # Top 5 matches for first candidate\n",
    "        [(142, 0.876), (593, 0.854), ...]\n",
    "    \"\"\"\n",
    "    all_matches = []\n",
    "    \n",
    "    for i, sim_row in enumerate(similarity_matrix):\n",
    "        # Get top-k indices (highest similarity scores)\n",
    "        # argsort sorts ascending, so we take last k and reverse\n",
    "        top_indices = np.argsort(sim_row)[-top_k:][::-1]\n",
    "        top_scores = sim_row[top_indices]\n",
    "        \n",
    "        # Create list of (index, score) tuples\n",
    "        matches = list(zip(top_indices.tolist(), top_scores.tolist()))\n",
    "        all_matches.append(matches)\n",
    "    \n",
    "    return all_matches\n",
    "\n",
    "# Get matches\n",
    "print(f\"   ‚è±Ô∏è  Computing matches...\")\n",
    "start_time = time.time()\n",
    "\n",
    "all_matches = get_top_k_matches(similarity_matrix, config.TOP_K_MATCHES)\n",
    "\n",
    "batch_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Matches computed for all {len(all_matches):,} candidates\")\n",
    "print(f\"   ‚Ä¢ Total time: {batch_time:.3f} seconds\")\n",
    "print(f\"   ‚Ä¢ Avg per candidate: {(batch_time / len(all_matches)) * 1000:.2f} ms\")\n",
    "\n",
    "# ====================================================================\n",
    "# PERFORMANCE TEST: Single Query Speed\n",
    "# ====================================================================\n",
    "print(f\"\\n‚ö° Performance test (single query):\")\n",
    "\n",
    "# Test query time for one candidate\n",
    "test_runs = 100\n",
    "times = []\n",
    "\n",
    "for _ in range(test_runs):\n",
    "    start = time.time()\n",
    "    \n",
    "    # Simulate single query\n",
    "    test_row = similarity_matrix[0]\n",
    "    top_indices = np.argsort(test_row)[-config.TOP_K_MATCHES:][::-1]\n",
    "    top_scores = test_row[top_indices]\n",
    "    \n",
    "    elapsed = (time.time() - start) * 1000  # Convert to ms\n",
    "    times.append(elapsed)\n",
    "\n",
    "avg_query_time = np.mean(times)\n",
    "p95_query_time = np.percentile(times, 95)\n",
    "\n",
    "print(f\"   ‚Ä¢ Average query time: {avg_query_time:.2f} ms\")\n",
    "print(f\"   ‚Ä¢ P95 query time: {p95_query_time:.2f} ms\")\n",
    "print(f\"   ‚Ä¢ Target: <100 ms\")\n",
    "\n",
    "if avg_query_time < 100:\n",
    "    print(f\"   ‚úÖ Performance target MET! ({avg_query_time:.1f}ms < 100ms)\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Performance target MISSED! ({avg_query_time:.1f}ms > 100ms)\")\n",
    "\n",
    "# ====================================================================\n",
    "# MATCH QUALITY ANALYSIS\n",
    "# ====================================================================\n",
    "print(f\"\\nüìä Match quality analysis:\")\n",
    "\n",
    "# Get all top scores\n",
    "all_top_scores = [matches[0][1] for matches in all_matches]  # Best match per candidate\n",
    "\n",
    "print(f\"   Best match scores:\")\n",
    "print(f\"      ‚Ä¢ Mean: {np.mean(all_top_scores):.4f}\")\n",
    "print(f\"      ‚Ä¢ Median: {np.median(all_top_scores):.4f}\")\n",
    "print(f\"      ‚Ä¢ Min: {np.min(all_top_scores):.4f}\")\n",
    "print(f\"      ‚Ä¢ Max: {np.max(all_top_scores):.4f}\")\n",
    "\n",
    "# Count excellent matches (score > 0.7)\n",
    "excellent = sum(1 for score in all_top_scores if score > 0.7)\n",
    "good = sum(1 for score in all_top_scores if 0.5 < score <= 0.7)\n",
    "poor = sum(1 for score in all_top_scores if score <= 0.5)\n",
    "\n",
    "print(f\"\\n   Match quality distribution:\")\n",
    "print(f\"      ‚Ä¢ Excellent (>0.7): {excellent:,} ({excellent/len(all_top_scores)*100:.1f}%)\")\n",
    "print(f\"      ‚Ä¢ Good (0.5-0.7): {good:,} ({good/len(all_top_scores)*100:.1f}%)\")\n",
    "print(f\"      ‚Ä¢ Poor (‚â§0.5): {poor:,} ({poor/len(all_top_scores)*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 6.3: Display Sample Matches (ENHANCED WITH ENRICHMENT INFO!)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: Sample Match Inspection\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìã Showing matches for 3 random candidates (with enrichment details):\")\n",
    "\n",
    "# Sample random candidates (not always 0, 1, 2!)\n",
    "import random\n",
    "random.seed(42)\n",
    "sample_indices = random.sample(range(len(candidates_df)), min(3, len(candidates_df)))\n",
    "\n",
    "for idx, cand_idx in enumerate(sample_indices, 1):\n",
    "    cand_row = candidates_df.iloc[cand_idx]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SAMPLE #{idx} - CANDIDATE #{cand_idx}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Show candidate info\n",
    "    # ====================================================================\n",
    "    career = str(cand_row.get('career_objective', 'Not specified'))[:100]\n",
    "    \n",
    "    skills = cand_row.get('skills', [])\n",
    "    if isinstance(skills, list):\n",
    "        skills_str = ', '.join(str(s) for s in skills[:8])  # Show more skills\n",
    "    else:\n",
    "        skills_str = str(skills)[:150]\n",
    "    \n",
    "    print(f\"\\nüë§ CANDIDATE PROFILE:\")\n",
    "    print(f\"   Career objective: {career}{'...' if len(str(cand_row.get('career_objective', ''))) > 100 else ''}\")\n",
    "    print(f\"   Skills: {skills_str}{'...' if len(skills_str) >= 150 else ''}\")\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Show top 5 matches with ENRICHMENT details!\n",
    "    # ====================================================================\n",
    "    print(f\"\\nüéØ TOP 5 COMPANY MATCHES:\")\n",
    "    print(f\"{'#':<4} {'Score':<8} {'Company':<35} {'Enriched Skills (Bridge!)':<50}\")\n",
    "    print(\"-\" * 110)\n",
    "    \n",
    "    for rank, (comp_idx, score) in enumerate(all_matches[cand_idx][:5], 1):\n",
    "        comp_row = companies_df.iloc[comp_idx]\n",
    "        \n",
    "        # Company description\n",
    "        comp_desc = str(comp_row.get('description', 'N/A'))[:35]\n",
    "        \n",
    "        # ENRICHED SKILLS (THE BRIDGE!)\n",
    "        enriched_skills = str(comp_row.get('enriched_skills', 'Not specified'))\n",
    "        \n",
    "        # Show first 50 chars of skills\n",
    "        if enriched_skills != 'Not specified' and len(enriched_skills) > 50:\n",
    "            skills_display = enriched_skills[:47] + '...'\n",
    "        else:\n",
    "            skills_display = enriched_skills[:50]\n",
    "        \n",
    "        # Emoji based on score\n",
    "        if score > 0.7:\n",
    "            emoji = 'üåü'\n",
    "        elif score > 0.5:\n",
    "            emoji = '‚úÖ'\n",
    "        else:\n",
    "            emoji = 'üü°'\n",
    "        \n",
    "        print(f\"{emoji} {rank:<2} {score:<8.4f} {comp_desc:<35} {skills_display:<50}\")\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Show match explanation for best match\n",
    "    # ====================================================================\n",
    "    best_comp_idx, best_score = all_matches[cand_idx][0]\n",
    "    best_comp = companies_df.iloc[best_comp_idx]\n",
    "    \n",
    "    print(f\"\\nüí° Best Match Analysis:\")\n",
    "    print(f\"   Score: {best_score:.4f}\")\n",
    "    print(f\"   Company: {str(best_comp.get('description', 'N/A'))[:80]}...\")\n",
    "    \n",
    "    if 'enriched_skills' in best_comp and best_comp['enriched_skills'] != 'Not specified':\n",
    "        print(f\"   Enriched Skills: {str(best_comp['enriched_skills'])[:100]}...\")\n",
    "        print(f\"   ‚úÖ Job posting bridge ACTIVE (enriched with real skills!)\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  No enriched skills (bridge not active for this company)\")\n",
    "    \n",
    "    if 'industries_list' in best_comp:\n",
    "        print(f\"   Industries: {str(best_comp['industries_list'])[:60]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ MATCHING SYSTEM COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä Summary:\")\n",
    "print(f\"   ‚Ä¢ Similarity matrix: {similarity_matrix.shape}\")\n",
    "print(f\"   ‚Ä¢ Query performance: {avg_query_time:.1f}ms (target: <100ms)\")\n",
    "print(f\"   ‚Ä¢ Match quality: {excellent/len(all_top_scores)*100:.1f}% excellent matches\")\n",
    "print(f\"   ‚Ä¢ Ready for evaluation (Section 7)\")\n",
    "\n",
    "print(\"\\nüìù Variables available:\")\n",
    "print(f\"   ‚Ä¢ similarity_matrix: {similarity_matrix.shape} array\")\n",
    "print(f\"   ‚Ä¢ all_matches: List of {len(all_matches):,} match lists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SECTION 7: Evaluation & Metrics (CRITICAL FOR ACADEMIC!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 7: EVALUATION & METRICS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "METRIC 1: Bilateral Fairness\n",
      "================================================================================\n",
      "\n",
      "üìä Candidate-side analysis:\n",
      "   ‚Ä¢ Total candidates: 9,544\n",
      "   ‚Ä¢ With match > 0.5: 9,460\n",
      "   ‚Ä¢ Coverage: 0.991 (99.1%)\n",
      "\n",
      "üìä Company-side analysis:\n",
      "   ‚Ä¢ Total companies: 24,473\n",
      "   ‚Ä¢ Appearing in top-10: 366\n",
      "   ‚Ä¢ Coverage: 0.015 (1.5%)\n",
      "\n",
      "‚öñÔ∏è  Bilateral Fairness Score:\n",
      "   ‚Ä¢ Fairness: 0.015\n",
      "   ‚Ä¢ Interpretation: 1.5% of BOTH sides are served\n",
      "   ‚Ä¢ Status: üî¥ POOR\n",
      "   ‚Ä¢ Assessment: Many entities on one or both sides not served\n",
      "\n",
      "   üí° Bottleneck: Company-side (0.015 < 0.991)\n",
      "      Recommendation: Enrich more company profiles or expand company dataset\n",
      "\n",
      "================================================================================\n",
      "METRIC 2: Match Quality Distribution\n",
      "================================================================================\n",
      "\n",
      "üìä Analyzing all match scores...\n",
      "   ‚Ä¢ Total match scores: 95,440\n",
      "\n",
      "üìà Score statistics:\n",
      "   ‚Ä¢ Mean: 0.5360\n",
      "   ‚Ä¢ Median: 0.5345\n",
      "   ‚Ä¢ Std: 0.0399\n",
      "   ‚Ä¢ Min: 0.4090\n",
      "   ‚Ä¢ Max: 0.6857\n",
      "\n",
      "üìä Percentiles:\n",
      "   ‚Ä¢ 10th: 0.4860\n",
      "   ‚Ä¢ 25th: 0.5087\n",
      "   ‚Ä¢ 50th: 0.5345\n",
      "   ‚Ä¢ 75th: 0.5625\n",
      "   ‚Ä¢ 90th: 0.5890\n",
      "   ‚Ä¢ 95th: 0.6045\n",
      "   ‚Ä¢ 99th: 0.6361\n",
      "\n",
      "üéØ Match quality categories:\n",
      "   ‚Ä¢ Excellent (>0.8):       0 (  0.0%)\n",
      "   ‚Ä¢ Very Good (0.7-0.8):       0 (  0.0%)\n",
      "   ‚Ä¢ Good (0.6-0.7):   5,920 (  6.2%)\n",
      "   ‚Ä¢ Moderate (0.5-0.6):  71,836 ( 75.3%)\n",
      "   ‚Ä¢ Poor (‚â§0.5):  17,684 ( 18.5%)\n",
      "\n",
      "   üü° Moderate quality matches (mean: 0.536)\n",
      "\n",
      "================================================================================\n",
      "METRIC 3: Job Posting Bridge Coverage\n",
      "================================================================================\n",
      "\n",
      "üåâ Job Posting Bridge Impact:\n",
      "   ‚Ä¢ Total companies: 24,473\n",
      "   ‚Ä¢ With enriched skills: 23,528\n",
      "   ‚Ä¢ Without enriched skills: 945\n",
      "   ‚Ä¢ Coverage: 96.1%\n",
      "   ‚Ä¢ Status: ‚úÖ EXCELLENT\n",
      "   ‚Ä¢ Impact: Job posting bridge highly effective\n",
      "\n",
      "üìä Enrichment impact on match quality:\n",
      "   ‚Ä¢ Avg score (enriched companies): 0.5361\n",
      "   ‚Ä¢ Avg score (non-enriched companies): 0.5207\n",
      "   ‚Ä¢ Improvement: +3.0%\n",
      "   üü¢ Enrichment provides modest improvement\n",
      "\n",
      "================================================================================\n",
      "METRIC 4: System Performance\n",
      "================================================================================\n",
      "\n",
      "‚ö° Query Performance:\n",
      "   ‚Ä¢ Average query time: 2.11 ms\n",
      "   ‚Ä¢ Target: <100 ms\n",
      "   ‚úÖ Performance target MET! (2.1ms < 100ms)\n",
      "\n",
      "üíæ Memory Usage:\n",
      "   ‚Ä¢ Candidate embeddings: 14.0 MB\n",
      "   ‚Ä¢ Company embeddings: 35.8 MB\n",
      "   ‚Ä¢ Similarity matrix: 891.0 MB\n",
      "   ‚Ä¢ Total: 940.8 MB\n",
      "   ‚ö†Ô∏è  High memory usage (>941 MB)\n",
      "\n",
      "üìä System Scale:\n",
      "   ‚Ä¢ Candidates: 9,544\n",
      "   ‚Ä¢ Companies: 24,473\n",
      "   ‚Ä¢ Total comparisons: 233,570,312\n",
      "   ‚Ä¢ Matches generated: 95,440\n",
      "\n",
      "================================================================================\n",
      "SAVING EVALUATION METRICS\n",
      "================================================================================\n",
      "\n",
      "üíæ Saved metrics:\n",
      "   ‚úÖ ../results/evaluation_metrics.json\n",
      "   ‚úÖ ../results/match_scores.npy\n",
      "\n",
      "================================================================================\n",
      "üìä EVALUATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Key Metrics:\n",
      "   ‚Ä¢ Bilateral Fairness: 0.015 üü°\n",
      "   ‚Ä¢ Mean Match Score: 0.536\n",
      "   ‚Ä¢ Job Posting Coverage: 96.1% ‚úÖ\n",
      "   ‚Ä¢ Query Performance: 2.1ms ‚úÖ\n",
      "\n",
      "üìà System Characteristics:\n",
      "   ‚Ä¢ Dataset: 9,544 candidates √ó 24,473 companies\n",
      "   ‚Ä¢ Matches: 95,440 total\n",
      "   ‚Ä¢ Memory: 941 MB\n",
      "\n",
      "üéØ Quality Assessment:\n",
      "   ‚Ä¢ Overall: üü° MODERATE QUALITY\n",
      "   ‚Ä¢ 0.0% matches are excellent (>0.8)\n",
      "\n",
      "üíæ Results saved to: ../results/\n",
      "================================================================================\n",
      "\n",
      "üìù Next steps:\n",
      "   ‚Ä¢ Section 7.5: Synthetic Validation (ground truth testing)\n",
      "   ‚Ä¢ Section 8: Save for Production\n",
      "   ‚Ä¢ Batch 5: LLM Features (optional)\n",
      "   ‚Ä¢ Batch 6: Visualizations\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 7: EVALUATION & METRICS (COMPLETE WITH SAVES!)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECTION 7: EVALUATION & METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create results directory if needed\n",
    "results_dir = config.RESULTS_PATH\n",
    "Path(results_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 7.1: Bilateral Fairness Score\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METRIC 1: Bilateral Fairness\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def compute_bilateral_fairness(similarity_matrix: np.ndarray, \n",
    "                               top_k: int = 10,\n",
    "                               threshold: float = 0.5) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Compute bilateral fairness: How balanced are matches from both sides?\n",
    "    \n",
    "    Bilateral Fairness = min(candidate_coverage, company_coverage)\n",
    "    \n",
    "    Why This Matters:\n",
    "    ----------------\n",
    "    Traditional matching favors one side (usually companies).\n",
    "    Bilateral fairness ensures BOTH candidates AND companies get good matches.\n",
    "    \n",
    "    Algorithm:\n",
    "    ---------\n",
    "    1. Candidate-side: % of candidates with at least one match > threshold\n",
    "    2. Company-side: % of companies that appear in at least one top-k list\n",
    "    3. Fairness: Take the minimum (ensures BOTH sides are served)\n",
    "    \n",
    "    Args:\n",
    "        similarity_matrix: Precomputed similarities (n_candidates √ó n_companies)\n",
    "        top_k: Number of top matches to consider\n",
    "        threshold: Minimum similarity score to count as \"matched\"\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (fairness, candidate_coverage, company_coverage)\n",
    "        \n",
    "    Example:\n",
    "        >>> fairness, cand_cov, comp_cov = compute_bilateral_fairness(sim_matrix)\n",
    "        >>> print(f\"Fairness: {fairness:.3f}\")\n",
    "    \"\"\"\n",
    "    n_candidates, n_companies = similarity_matrix.shape\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Candidate-side coverage: How many candidates find good matches?\n",
    "    # ====================================================================\n",
    "    candidate_max_scores = similarity_matrix.max(axis=1)\n",
    "    candidates_matched = (candidate_max_scores > threshold).sum()\n",
    "    candidate_coverage = candidates_matched / n_candidates\n",
    "    \n",
    "    print(f\"\\nüìä Candidate-side analysis:\")\n",
    "    print(f\"   ‚Ä¢ Total candidates: {n_candidates:,}\")\n",
    "    print(f\"   ‚Ä¢ With match > {threshold}: {candidates_matched:,}\")\n",
    "    print(f\"   ‚Ä¢ Coverage: {candidate_coverage:.3f} ({candidate_coverage*100:.1f}%)\")\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Company-side coverage: How many companies appear in top-k?\n",
    "    # ====================================================================\n",
    "    # Get all companies that appear in ANY top-k list\n",
    "    top_k_indices = np.argsort(similarity_matrix, axis=1)[:, -top_k:]\n",
    "    unique_companies = np.unique(top_k_indices)\n",
    "    company_coverage = len(unique_companies) / n_companies\n",
    "    \n",
    "    print(f\"\\nüìä Company-side analysis:\")\n",
    "    print(f\"   ‚Ä¢ Total companies: {n_companies:,}\")\n",
    "    print(f\"   ‚Ä¢ Appearing in top-{top_k}: {len(unique_companies):,}\")\n",
    "    print(f\"   ‚Ä¢ Coverage: {company_coverage:.3f} ({company_coverage*100:.1f}%)\")\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Bilateral fairness: minimum of both sides\n",
    "    # ====================================================================\n",
    "    fairness = min(candidate_coverage, company_coverage)\n",
    "    \n",
    "    print(f\"\\n‚öñÔ∏è  Bilateral Fairness Score:\")\n",
    "    print(f\"   ‚Ä¢ Fairness: {fairness:.3f}\")\n",
    "    print(f\"   ‚Ä¢ Interpretation: {fairness*100:.1f}% of BOTH sides are served\")\n",
    "    \n",
    "    # Status assessment\n",
    "    if fairness > 0.85:\n",
    "        status = \"‚úÖ EXCELLENT\"\n",
    "        assessment = \"Both candidates and companies well-served\"\n",
    "    elif fairness > 0.70:\n",
    "        status = \"üü¢ GOOD\"\n",
    "        assessment = \"Majority of both sides served\"\n",
    "    elif fairness > 0.50:\n",
    "        status = \"üü° MODERATE\"\n",
    "        assessment = \"Half of both sides served, room for improvement\"\n",
    "    else:\n",
    "        status = \"üî¥ POOR\"\n",
    "        assessment = \"Many entities on one or both sides not served\"\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Status: {status}\")\n",
    "    print(f\"   ‚Ä¢ Assessment: {assessment}\")\n",
    "    \n",
    "    # Identify the bottleneck\n",
    "    if candidate_coverage < company_coverage:\n",
    "        print(f\"\\n   üí° Bottleneck: Candidate-side ({candidate_coverage:.3f} < {company_coverage:.3f})\")\n",
    "        print(f\"      Recommendation: Improve candidate profile quality or matching algorithm\")\n",
    "    elif company_coverage < candidate_coverage:\n",
    "        print(f\"\\n   üí° Bottleneck: Company-side ({company_coverage:.3f} < {candidate_coverage:.3f})\")\n",
    "        print(f\"      Recommendation: Enrich more company profiles or expand company dataset\")\n",
    "    else:\n",
    "        print(f\"\\n   ‚úÖ Balanced coverage on both sides!\")\n",
    "    \n",
    "    return fairness, candidate_coverage, company_coverage\n",
    "\n",
    "# Compute fairness\n",
    "fairness, cand_cov, comp_cov = compute_bilateral_fairness(\n",
    "    similarity_matrix,\n",
    "    top_k=config.TOP_K_MATCHES,\n",
    "    threshold=config.SIMILARITY_THRESHOLD\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 7.2: Match Quality Distribution\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METRIC 2: Match Quality Distribution\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract all scores from all_matches\n",
    "print(\"\\nüìä Analyzing all match scores...\")\n",
    "\n",
    "all_scores = []\n",
    "for matches in all_matches:\n",
    "    scores = [score for _, score in matches]\n",
    "    all_scores.extend(scores)\n",
    "\n",
    "all_scores = np.array(all_scores)\n",
    "\n",
    "print(f\"   ‚Ä¢ Total match scores: {len(all_scores):,}\")\n",
    "\n",
    "# ====================================================================\n",
    "# Statistics\n",
    "# ====================================================================\n",
    "print(f\"\\nüìà Score statistics:\")\n",
    "print(f\"   ‚Ä¢ Mean: {all_scores.mean():.4f}\")\n",
    "print(f\"   ‚Ä¢ Median: {np.median(all_scores):.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {all_scores.std():.4f}\")\n",
    "print(f\"   ‚Ä¢ Min: {all_scores.min():.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {all_scores.max():.4f}\")\n",
    "\n",
    "# Percentiles\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "print(f\"\\nüìä Percentiles:\")\n",
    "for p in percentiles:\n",
    "    val = np.percentile(all_scores, p)\n",
    "    print(f\"   ‚Ä¢ {p:2d}th: {val:.4f}\")\n",
    "\n",
    "# ====================================================================\n",
    "# Quality Categories\n",
    "# ====================================================================\n",
    "print(f\"\\nüéØ Match quality categories:\")\n",
    "\n",
    "excellent = (all_scores > 0.8).sum()\n",
    "very_good = ((all_scores > 0.7) & (all_scores <= 0.8)).sum()\n",
    "good = ((all_scores > 0.6) & (all_scores <= 0.7)).sum()\n",
    "moderate = ((all_scores > 0.5) & (all_scores <= 0.6)).sum()\n",
    "poor = (all_scores <= 0.5).sum()\n",
    "\n",
    "total = len(all_scores)\n",
    "\n",
    "print(f\"   ‚Ä¢ Excellent (>0.8): {excellent:>7,} ({excellent/total*100:>5.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Very Good (0.7-0.8): {very_good:>7,} ({very_good/total*100:>5.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Good (0.6-0.7): {good:>7,} ({good/total*100:>5.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Moderate (0.5-0.6): {moderate:>7,} ({moderate/total*100:>5.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Poor (‚â§0.5): {poor:>7,} ({poor/total*100:>5.1f}%)\")\n",
    "\n",
    "# Assessment\n",
    "if all_scores.mean() > 0.7:\n",
    "    print(f\"\\n   ‚úÖ High quality matches overall (mean: {all_scores.mean():.3f})\")\n",
    "elif all_scores.mean() > 0.6:\n",
    "    print(f\"\\n   üü¢ Good quality matches (mean: {all_scores.mean():.3f})\")\n",
    "else:\n",
    "    print(f\"\\n   üü° Moderate quality matches (mean: {all_scores.mean():.3f})\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 7.3: Job Posting Bridge Impact\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METRIC 3: Job Posting Bridge Coverage\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use coverage from ETL (already calculated!)\n",
    "coverage_pct = etl_results['stats']['skills_coverage_pct']\n",
    "has_skills_count = (companies_df['enriched_skills'] != 'Not specified').sum()\n",
    "total_companies = len(companies_df)\n",
    "\n",
    "print(f\"\\nüåâ Job Posting Bridge Impact:\")\n",
    "print(f\"   ‚Ä¢ Total companies: {total_companies:,}\")\n",
    "print(f\"   ‚Ä¢ With enriched skills: {has_skills_count:,}\")\n",
    "print(f\"   ‚Ä¢ Without enriched skills: {total_companies - has_skills_count:,}\")\n",
    "print(f\"   ‚Ä¢ Coverage: {coverage_pct:.1f}%\")\n",
    "\n",
    "# Status\n",
    "if coverage_pct > 90:\n",
    "    status = \"‚úÖ EXCELLENT\"\n",
    "    impact = \"Job posting bridge highly effective\"\n",
    "elif coverage_pct > 70:\n",
    "    status = \"üü¢ GOOD\"\n",
    "    impact = \"Majority of companies enriched\"\n",
    "else:\n",
    "    status = \"üü° LIMITED\"\n",
    "    impact = \"Many companies lack skill enrichment\"\n",
    "\n",
    "print(f\"   ‚Ä¢ Status: {status}\")\n",
    "print(f\"   ‚Ä¢ Impact: {impact}\")\n",
    "\n",
    "# ====================================================================\n",
    "# Compare matches with vs without enrichment\n",
    "# ====================================================================\n",
    "print(f\"\\nüìä Enrichment impact on match quality:\")\n",
    "\n",
    "# Get companies with/without enrichment\n",
    "companies_with_skills = companies_df['enriched_skills'] != 'Not specified'\n",
    "\n",
    "# Get average scores for companies with/without skills\n",
    "scores_with_skills = []\n",
    "scores_without_skills = []\n",
    "\n",
    "for matches in all_matches:\n",
    "    for comp_idx, score in matches:\n",
    "        if companies_with_skills.iloc[comp_idx]:\n",
    "            scores_with_skills.append(score)\n",
    "        else:\n",
    "            scores_without_skills.append(score)\n",
    "\n",
    "if scores_with_skills:\n",
    "    avg_with = np.mean(scores_with_skills)\n",
    "    print(f\"   ‚Ä¢ Avg score (enriched companies): {avg_with:.4f}\")\n",
    "\n",
    "if scores_without_skills:\n",
    "    avg_without = np.mean(scores_without_skills)\n",
    "    print(f\"   ‚Ä¢ Avg score (non-enriched companies): {avg_without:.4f}\")\n",
    "\n",
    "if scores_with_skills and scores_without_skills:\n",
    "    improvement = ((avg_with - avg_without) / avg_without) * 100\n",
    "    print(f\"   ‚Ä¢ Improvement: {improvement:+.1f}%\")\n",
    "    \n",
    "    if improvement > 5:\n",
    "        print(f\"   ‚úÖ Enrichment significantly improves match quality!\")\n",
    "    elif improvement > 0:\n",
    "        print(f\"   üü¢ Enrichment provides modest improvement\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Enrichment not showing clear improvement\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 7.4: System Performance Metrics\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METRIC 4: System Performance\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use query time from Section 6 (if available in globals)\n",
    "if 'avg_query_time' in globals():\n",
    "    print(f\"\\n‚ö° Query Performance:\")\n",
    "    print(f\"   ‚Ä¢ Average query time: {avg_query_time:.2f} ms\")\n",
    "    print(f\"   ‚Ä¢ Target: <100 ms\")\n",
    "    \n",
    "    if avg_query_time < 100:\n",
    "        print(f\"   ‚úÖ Performance target MET! ({avg_query_time:.1f}ms < 100ms)\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Performance target MISSED! ({avg_query_time:.1f}ms > 100ms)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Query performance not measured in Section 6\")\n",
    "\n",
    "# Memory usage\n",
    "print(f\"\\nüíæ Memory Usage:\")\n",
    "print(f\"   ‚Ä¢ Candidate embeddings: {candidate_embeddings.nbytes / (1024**2):.1f} MB\")\n",
    "print(f\"   ‚Ä¢ Company embeddings: {company_embeddings.nbytes / (1024**2):.1f} MB\")\n",
    "print(f\"   ‚Ä¢ Similarity matrix: {similarity_matrix.nbytes / (1024**2):.1f} MB\")\n",
    "total_memory = (candidate_embeddings.nbytes + company_embeddings.nbytes + similarity_matrix.nbytes) / (1024**2)\n",
    "print(f\"   ‚Ä¢ Total: {total_memory:.1f} MB\")\n",
    "\n",
    "if total_memory < 500:\n",
    "    print(f\"   ‚úÖ Reasonable memory footprint (<500 MB)\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  High memory usage (>{total_memory:.0f} MB)\")\n",
    "\n",
    "# Scale\n",
    "print(f\"\\nüìä System Scale:\")\n",
    "print(f\"   ‚Ä¢ Candidates: {len(candidate_embeddings):,}\")\n",
    "print(f\"   ‚Ä¢ Companies: {len(company_embeddings):,}\")\n",
    "print(f\"   ‚Ä¢ Total comparisons: {len(candidate_embeddings) * len(company_embeddings):,}\")\n",
    "print(f\"   ‚Ä¢ Matches generated: {len(all_matches) * config.TOP_K_MATCHES:,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 7.5: Save All Metrics (CRITICAL!)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING EVALUATION METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compile all metrics\n",
    "evaluation_metrics = {\n",
    "    'bilateral_fairness': {\n",
    "        'fairness_score': float(fairness),\n",
    "        'candidate_coverage': float(cand_cov),\n",
    "        'company_coverage': float(comp_cov),\n",
    "        'threshold': float(config.SIMILARITY_THRESHOLD),\n",
    "        'top_k': int(config.TOP_K_MATCHES)\n",
    "    },\n",
    "    'match_quality': {\n",
    "        'mean_score': float(all_scores.mean()),\n",
    "        'median_score': float(np.median(all_scores)),\n",
    "        'std_score': float(all_scores.std()),\n",
    "        'min_score': float(all_scores.min()),\n",
    "        'max_score': float(all_scores.max()),\n",
    "        'percentiles': {\n",
    "            f'p{p}': float(np.percentile(all_scores, p))\n",
    "            for p in [10, 25, 50, 75, 90, 95, 99]\n",
    "        },\n",
    "        'quality_distribution': {\n",
    "            'excellent': int(excellent),\n",
    "            'very_good': int(very_good),\n",
    "            'good': int(good),\n",
    "            'moderate': int(moderate),\n",
    "            'poor': int(poor)\n",
    "        }\n",
    "    },\n",
    "    'enrichment': {\n",
    "        'total_companies': int(total_companies),\n",
    "        'companies_with_skills': int(has_skills_count),\n",
    "        'coverage_pct': float(coverage_pct),\n",
    "        'avg_score_enriched': float(avg_with) if scores_with_skills else None,\n",
    "        'avg_score_non_enriched': float(avg_without) if scores_without_skills else None\n",
    "    },\n",
    "    'performance': {\n",
    "        'query_time_ms': float(avg_query_time) if 'avg_query_time' in globals() else None,\n",
    "        'memory_mb': float(total_memory),\n",
    "        'n_candidates': int(len(candidate_embeddings)),\n",
    "        'n_companies': int(len(company_embeddings)),\n",
    "        'total_matches': int(len(all_matches) * config.TOP_K_MATCHES)\n",
    "    },\n",
    "    'model_info': {\n",
    "        'embedding_model': config.EMBEDDING_MODEL,\n",
    "        'embedding_dimension': int(candidate_embeddings.shape[1]),\n",
    "        'similarity_metric': 'cosine'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save as JSON\n",
    "metrics_file = f'{results_dir}evaluation_metrics.json'\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(evaluation_metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Saved metrics:\")\n",
    "print(f\"   ‚úÖ {metrics_file}\")\n",
    "\n",
    "# Also save detailed score distribution\n",
    "scores_file = f'{results_dir}match_scores.npy'\n",
    "np.save(scores_file, all_scores)\n",
    "print(f\"   ‚úÖ {scores_file}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 7.6: Summary Report\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä EVALUATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n‚úÖ Key Metrics:\")\n",
    "print(f\"   ‚Ä¢ Bilateral Fairness: {fairness:.3f} {'‚úÖ' if fairness > 0.85 else 'üü°'}\")\n",
    "print(f\"   ‚Ä¢ Mean Match Score: {all_scores.mean():.3f}\")\n",
    "print(f\"   ‚Ä¢ Job Posting Coverage: {coverage_pct:.1f}% {'‚úÖ' if coverage_pct > 90 else 'üü°'}\")\n",
    "print(f\"   ‚Ä¢ Query Performance: {avg_query_time:.1f}ms {'‚úÖ' if 'avg_query_time' in globals() and avg_query_time < 100 else '‚ö†Ô∏è'}\")\n",
    "\n",
    "print(f\"\\nüìà System Characteristics:\")\n",
    "print(f\"   ‚Ä¢ Dataset: {len(candidates_df):,} candidates √ó {len(companies_df):,} companies\")\n",
    "print(f\"   ‚Ä¢ Matches: {len(all_matches) * config.TOP_K_MATCHES:,} total\")\n",
    "print(f\"   ‚Ä¢ Memory: {total_memory:.0f} MB\")\n",
    "\n",
    "print(f\"\\nüéØ Quality Assessment:\")\n",
    "excellent_pct = (excellent / total) * 100\n",
    "if excellent_pct > 50:\n",
    "    quality = \"‚úÖ HIGH QUALITY\"\n",
    "elif excellent_pct > 30:\n",
    "    quality = \"üü¢ GOOD QUALITY\"\n",
    "else:\n",
    "    quality = \"üü° MODERATE QUALITY\"\n",
    "\n",
    "print(f\"   ‚Ä¢ Overall: {quality}\")\n",
    "print(f\"   ‚Ä¢ {excellent_pct:.1f}% matches are excellent (>0.8)\")\n",
    "\n",
    "print(f\"\\nüíæ Results saved to: {results_dir}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìù Next steps:\")\n",
    "print(f\"   ‚Ä¢ Section 7.5: Synthetic Validation (ground truth testing)\")\n",
    "print(f\"   ‚Ä¢ Section 8: Save for Production\")\n",
    "print(f\"   ‚Ä¢ Batch 5: LLM Features (optional)\")\n",
    "print(f\"   ‚Ä¢ Batch 6: Visualizations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üíæ SAVING FOR PRODUCTION\n",
      "================================================================================\n",
      "\n",
      "1Ô∏è‚É£  Saving embeddings...\n",
      "   ‚úÖ candidate_embeddings.npy saved\n",
      "   ‚úÖ company_embeddings.npy saved\n",
      "\n",
      "2Ô∏è‚É£  Saving metadata...\n",
      "   ‚úÖ candidates_metadata.pkl saved\n",
      "   ‚úÖ companies_metadata.pkl saved\n",
      "\n",
      "3Ô∏è‚É£  Saving model info...\n",
      "   ‚úÖ model_info.json saved\n",
      "\n",
      "4Ô∏è‚É£  Saving sample matches...\n",
      "   ‚úÖ sample_matches.json saved\n",
      "\n",
      "================================================================================\n",
      "üì¶ DEPLOYMENT PACKAGE READY\n",
      "================================================================================\n",
      "\n",
      "üìÇ Files saved:\n",
      "   ‚úÖ Candidate embeddings: 13.98 MB\n",
      "   ‚úÖ Company embeddings: 35.85 MB\n",
      "   ‚úÖ Candidate metadata: 2.33 MB\n",
      "   ‚úÖ Company metadata: 22.78 MB\n",
      "   ‚úÖ Model info: 0.00 MB\n",
      "   ‚úÖ Sample matches: 0.12 MB\n",
      "\n",
      "   üì¶ Total package size: 75.06 MB\n",
      "\n",
      "================================================================================\n",
      "üéâ HRHUB v4.0 PIPELINE COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "‚úÖ System ready for:\n",
      "   ‚Ä¢ Streamlit deployment\n",
      "   ‚Ä¢ Academic report\n",
      "   ‚Ä¢ Presentation demo\n",
      "\n",
      "üìä Final Statistics:\n",
      "   ‚Ä¢ 9,544 candidates processed\n",
      "   ‚Ä¢ 24,473 companies processed\n",
      "   ‚Ä¢ 0.015 bilateral fairness\n",
      "   ‚Ä¢ 96.1% coverage\n",
      "\n",
      "üöÄ Next steps:\n",
      "   1. Review sample_matches.json\n",
      "   2. Create visualizations (optional)\n",
      "   3. Write academic report\n",
      "   4. Deploy to Streamlit (optional)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 8: SAVE FOR PRODUCTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üíæ SAVING FOR PRODUCTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 8.1: Save Embeddings\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£  Saving embeddings...\")\n",
    "\n",
    "np.save(f'{config.PROCESSED_PATH}candidate_embeddings.npy', candidate_embeddings)\n",
    "np.save(f'{config.PROCESSED_PATH}company_embeddings.npy', company_embeddings)\n",
    "\n",
    "print(f\"   ‚úÖ candidate_embeddings.npy saved\")\n",
    "print(f\"   ‚úÖ company_embeddings.npy saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 8.2: Save Metadata\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£  Saving metadata...\")\n",
    "\n",
    "candidates_df.to_pickle(f'{config.PROCESSED_PATH}candidates_metadata.pkl')\n",
    "companies_df.to_pickle(f'{config.PROCESSED_PATH}companies_metadata.pkl')\n",
    "\n",
    "print(f\"   ‚úÖ candidates_metadata.pkl saved\")\n",
    "print(f\"   ‚úÖ companies_metadata.pkl saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 8.3: Save Model Info & Metrics\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£  Saving model info...\")\n",
    "\n",
    "model_info = {\n",
    "    'model_name': config.EMBEDDING_MODEL,\n",
    "    'embedding_dim': config.EMBEDDING_DIM,\n",
    "    'n_candidates': len(candidates_df),\n",
    "    'n_companies': len(companies_df),\n",
    "    'bilateral_fairness': float(fairness),\n",
    "    'mean_match_score': float(all_scores.mean()),\n",
    "    'coverage_pct': float(coverage_pct),\n",
    "    'top_k': config.TOP_K_MATCHES,\n",
    "    'similarity_threshold': config.SIMILARITY_THRESHOLD\n",
    "}\n",
    "\n",
    "with open(f'{config.PROCESSED_PATH}model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "print(f\"   ‚úÖ model_info.json saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 8.4: Save Sample Matches\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£  Saving sample matches...\")\n",
    "\n",
    "# Save first 100 candidates' matches as JSON for inspection\n",
    "sample_matches = []\n",
    "for i in range(min(100, len(all_matches))):\n",
    "    cand_career = str(candidates_df.iloc[i].get('career_objective', 'N/A'))[:100]\n",
    "    \n",
    "    matches_data = []\n",
    "    for comp_idx, score in all_matches[i][:5]:\n",
    "        comp_desc = str(companies_df.iloc[comp_idx].get('description', 'N/A'))[:100]\n",
    "        matches_data.append({\n",
    "            'company_idx': int(comp_idx),\n",
    "            'score': float(score),\n",
    "            'company_description': comp_desc\n",
    "        })\n",
    "    \n",
    "    sample_matches.append({\n",
    "        'candidate_idx': i,\n",
    "        'candidate_career': cand_career,\n",
    "        'top_matches': matches_data\n",
    "    })\n",
    "\n",
    "with open(f'{config.RESULTS_PATH}sample_matches.json', 'w') as f:\n",
    "    json.dump(sample_matches, f, indent=2)\n",
    "\n",
    "print(f\"   ‚úÖ sample_matches.json saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 8.5: File Summary\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üì¶ DEPLOYMENT PACKAGE READY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import os\n",
    "\n",
    "files_to_check = [\n",
    "    (f'{config.PROCESSED_PATH}candidate_embeddings.npy', 'Candidate embeddings'),\n",
    "    (f'{config.PROCESSED_PATH}company_embeddings.npy', 'Company embeddings'),\n",
    "    (f'{config.PROCESSED_PATH}candidates_metadata.pkl', 'Candidate metadata'),\n",
    "    (f'{config.PROCESSED_PATH}companies_metadata.pkl', 'Company metadata'),\n",
    "    (f'{config.PROCESSED_PATH}model_info.json', 'Model info'),\n",
    "    (f'{config.RESULTS_PATH}sample_matches.json', 'Sample matches')\n",
    "]\n",
    "\n",
    "print(f\"\\nüìÇ Files saved:\")\n",
    "total_size = 0\n",
    "\n",
    "for filepath, description in files_to_check:\n",
    "    if os.path.exists(filepath):\n",
    "        size_mb = os.path.getsize(filepath) / (1024**2)\n",
    "        total_size += size_mb\n",
    "        print(f\"   ‚úÖ {description}: {size_mb:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {description}: NOT FOUND\")\n",
    "\n",
    "print(f\"\\n   üì¶ Total package size: {total_size:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ HRHUB v4.0 PIPELINE COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n‚úÖ System ready for:\")\n",
    "print(f\"   ‚Ä¢ Streamlit deployment\")\n",
    "print(f\"   ‚Ä¢ Academic report\")\n",
    "print(f\"   ‚Ä¢ Presentation demo\")\n",
    "\n",
    "print(f\"\\nüìä Final Statistics:\")\n",
    "print(f\"   ‚Ä¢ {len(candidates_df):,} candidates processed\")\n",
    "print(f\"   ‚Ä¢ {len(companies_df):,} companies processed\")\n",
    "print(f\"   ‚Ä¢ {fairness:.3f} bilateral fairness\")\n",
    "print(f\"   ‚Ä¢ {coverage_pct:.1f}% coverage\")\n",
    "\n",
    "print(\"\\nüöÄ Next steps:\")\n",
    "print(\"   1. Review sample_matches.json\")\n",
    "print(\"   2. Create visualizations (optional)\")\n",
    "print(\"   3. Write academic report\")\n",
    "print(\"   4. Deploy to Streamlit (optional)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ü§ñ SECTION 6: LLM Features\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6.1: Initialize LLM Client\n",
    "\n",
    "**Purpose:** Set up Hugging Face Inference API for LLM features.\n",
    "\n",
    "**Cost:** $0.00 (free tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BATCH 5: LLM ENHANCEMENT LAYER (OPTIONAL)\n",
      "================================================================================\n",
      "\n",
      "üì¶ Importing LLM dependencies...\n",
      "   ‚úÖ InferenceClient imported\n",
      "   ‚úÖ Pydantic imported\n",
      "\n",
      "ü§ñ Initializing LLM Client...\n",
      "‚úÖ Hugging Face client initialized!\n",
      "   ‚Ä¢ Model: meta-llama/Llama-3.2-3B-Instruct\n",
      "   ‚Ä¢ Cost: $0.00 (FREE tier)\n",
      "   ‚Ä¢ Connection: ‚úÖ Tested successfully\n",
      "\n",
      "üîß Defining helper functions...\n",
      "   ‚úÖ call_llm() defined\n",
      "\n",
      "üìã Defining Pydantic schemas...\n",
      "   ‚úÖ JobLevelClassification schema defined\n",
      "   ‚úÖ SkillsTaxonomy schema defined\n",
      "\n",
      "üõ°Ô∏è  Defining robust parsing functions...\n",
      "   ‚úÖ parse_job_level_robust() defined\n",
      "   ‚úÖ parse_skills_taxonomy_robust() defined\n",
      "\n",
      "üéØ Defining LLM feature functions...\n",
      "   ‚úÖ classify_job_level_zero_shot() defined\n",
      "   ‚úÖ classify_job_level_few_shot() defined\n",
      "   ‚úÖ extract_skills_taxonomy() defined (ROBUST - 3 strategies!)\n",
      "   ‚úÖ explain_match() defined\n",
      "\n",
      "================================================================================\n",
      "üß™ TESTING LLM FUNCTIONS\n",
      "================================================================================\n",
      "\n",
      "üìù Test 1: Job Level Classification (Zero-Shot)\n",
      "   Input: Senior software engineer with 10 years experience. Python expert. Led teams of 5+ developers.\n",
      "   Level: Senior\n",
      "   Confidence: 0.90\n",
      "   Reasoning: Extracted via regex\n",
      "\n",
      "üìù Test 2: Match Explanation\n",
      "   Match Score: 0.85\n",
      "   Explanation: The candidate matches the company with a score of 0.85 due to their strong alignment with the required skills and experience. The candidate's 10 years of experience, proficiency in Python, and leadership experience in leading teams of 5+ developers align perfectly with the company's need for Python developers with Machine Learning (ML) experience. This suggests a high likelihood of the candidate being a valuable asset to the company.\n",
      "\n",
      "‚úÖ LLM functions tested successfully!\n",
      "\n",
      "================================================================================\n",
      "BATCH 5 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "‚úÖ LLM Enhancement Layer ACTIVE\n",
      "   ‚Ä¢ Model: meta-llama/Llama-3.2-3B-Instruct\n",
      "   ‚Ä¢ Features: 4 functions available\n",
      "   ‚Ä¢ Cost: $0.00 (free tier)\n",
      "   ‚Ä¢ Robust parsing: ‚úÖ Enabled (triple-fallback)\n",
      "\n",
      "üìù Available functions:\n",
      "   ‚Ä¢ classify_job_level_zero_shot()\n",
      "   ‚Ä¢ classify_job_level_few_shot()\n",
      "   ‚Ä¢ extract_skills_taxonomy()\n",
      "   ‚Ä¢ explain_match()\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BATCH 5: LLM ENHANCEMENT LAYER (OPTIONAL FEATURES)\n",
    "# ============================================================================\n",
    "# Purpose: Add LLM-powered features for job classification and explainability\n",
    "# Provider: Hugging Face Inference API (FREE tier)\n",
    "# Cost: $0.00\n",
    "# Note: This is OPTIONAL - system works without it\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH 5: LLM ENHANCEMENT LAYER (OPTIONAL)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 5.1: Imports and Configuration\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüì¶ Importing LLM dependencies...\")\n",
    "\n",
    "try:\n",
    "    from huggingface_hub import InferenceClient\n",
    "    print(\"   ‚úÖ InferenceClient imported\")\n",
    "except ImportError:\n",
    "    print(\"   ‚ùå huggingface_hub not installed!\")\n",
    "    print(\"   üí° Install with: pip install huggingface_hub\")\n",
    "    InferenceClient = None\n",
    "\n",
    "try:\n",
    "    from pydantic import BaseModel, Field\n",
    "    from typing import Literal\n",
    "    print(\"   ‚úÖ Pydantic imported\")\n",
    "except ImportError:\n",
    "    print(\"   ‚ùå pydantic not installed!\")\n",
    "    print(\"   üí° Install with: pip install pydantic\")\n",
    "    BaseModel = None\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 5.2: Initialize LLM Client\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nü§ñ Initializing LLM Client...\")\n",
    "\n",
    "# LLM Model to use (free tier)\n",
    "LLM_MODEL = \"meta-llama/Llama-3.2-3B-Instruct\"  # Free on HF\n",
    "\n",
    "# Check if HF token exists\n",
    "HF_TOKEN = config.HF_TOKEN if hasattr(config, 'HF_TOKEN') else None\n",
    "\n",
    "if not HF_TOKEN:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: No Hugging Face token found!\")\n",
    "    print(\"   LLM features will be DISABLED\")\n",
    "    print(\"\\n   To enable LLM features:\")\n",
    "    print(\"   1. Get free token at: https://huggingface.co/settings/tokens\")\n",
    "    print(\"   2. Add to Config: HF_TOKEN = 'your_token_here'\")\n",
    "    print(\"   3. Re-run this cell\")\n",
    "    LLM_AVAILABLE = False\n",
    "    hf_client = None\n",
    "else:\n",
    "    try:\n",
    "        hf_client = InferenceClient(token=HF_TOKEN)\n",
    "        \n",
    "        # Test the connection\n",
    "        test_response = hf_client.chat_completion(\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "            model=LLM_MODEL,\n",
    "            max_tokens=10\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Hugging Face client initialized!\")\n",
    "        print(f\"   ‚Ä¢ Model: {LLM_MODEL}\")\n",
    "        print(f\"   ‚Ä¢ Cost: $0.00 (FREE tier)\")\n",
    "        print(f\"   ‚Ä¢ Connection: ‚úÖ Tested successfully\")\n",
    "        LLM_AVAILABLE = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to initialize LLM client!\")\n",
    "        print(f\"   Error: {e}\")\n",
    "        print(f\"\\n   Troubleshooting:\")\n",
    "        print(f\"   1. Check your HF token is valid\")\n",
    "        print(f\"   2. Ensure you have internet connection\")\n",
    "        print(f\"   3. Try regenerating your token\")\n",
    "        LLM_AVAILABLE = False\n",
    "        hf_client = None\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 5.3: Helper Functions\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüîß Defining helper functions...\")\n",
    "\n",
    "def call_llm(prompt: str, max_tokens: int = 1000, temperature: float = 0.7) -> str:\n",
    "    \"\"\"\n",
    "    Generic LLM call wrapper.\n",
    "    \n",
    "    Handles errors gracefully and returns empty string on failure.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Text prompt for the LLM\n",
    "        max_tokens: Maximum response length\n",
    "        temperature: Sampling temperature (0.0 = deterministic, 1.0 = creative)\n",
    "    \n",
    "    Returns:\n",
    "        LLM response text or error message\n",
    "    \"\"\"\n",
    "    if not LLM_AVAILABLE:\n",
    "        return \"[LLM not available - check HF_TOKEN]\"\n",
    "    \n",
    "    try:\n",
    "        response = hf_client.chat_completion(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=LLM_MODEL,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  LLM call failed: {e}\")\n",
    "        return f\"[Error: {str(e)[:100]}]\"\n",
    "\n",
    "print(\"   ‚úÖ call_llm() defined\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 5.4: Pydantic Schemas (Data Validation)\n",
    "# ============================================================================\n",
    "\n",
    "if BaseModel is not None:\n",
    "    print(\"\\nüìã Defining Pydantic schemas...\")\n",
    "    \n",
    "    class JobLevelClassification(BaseModel):\n",
    "        \"\"\"\n",
    "        Schema for job level classification output.\n",
    "        \n",
    "        Validates LLM responses match expected structure.\n",
    "        \"\"\"\n",
    "        level: Literal[\"Entry\", \"Mid\", \"Senior\", \"Executive\"]\n",
    "        confidence: float = Field(ge=0.0, le=1.0, description=\"Confidence score 0-1\")\n",
    "        reasoning: str = Field(description=\"Brief explanation of classification\")\n",
    "    \n",
    "    class SkillsTaxonomy(BaseModel):\n",
    "        \"\"\"\n",
    "        Schema for skills taxonomy extraction.\n",
    "        \n",
    "        Categorizes skills into meaningful groups.\n",
    "        \"\"\"\n",
    "        technical_skills: List[str] = Field(default_factory=list, description=\"Hard/technical skills\")\n",
    "        soft_skills: List[str] = Field(default_factory=list, description=\"Soft/interpersonal skills\")\n",
    "        certifications: List[str] = Field(default_factory=list, description=\"Certifications and qualifications\")\n",
    "        languages: List[str] = Field(default_factory=list, description=\"Programming or spoken languages\")\n",
    "    \n",
    "    print(\"   ‚úÖ JobLevelClassification schema defined\")\n",
    "    print(\"   ‚úÖ SkillsTaxonomy schema defined\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Pydantic not available - schemas disabled\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 5.5: Robust Parsing Functions (CRITICAL!)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüõ°Ô∏è  Defining robust parsing functions...\")\n",
    "\n",
    "def parse_job_level_robust(response: str) -> dict:\n",
    "    \"\"\"\n",
    "    ROBUST parser for job level classification.\n",
    "    \n",
    "    Triple-fallback strategy:\n",
    "    1. Try JSON parsing\n",
    "    2. Try regex extraction\n",
    "    3. Keyword fallback (ALWAYS succeeds)\n",
    "    \n",
    "    This prevents the system from crashing on malformed LLM outputs!\n",
    "    \n",
    "    Args:\n",
    "        response: LLM response text\n",
    "    \n",
    "    Returns:\n",
    "        Dict with level, confidence, reasoning\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # ====================================================================\n",
    "    # STRATEGY 1: Try JSON parsing\n",
    "    # ====================================================================\n",
    "    try:\n",
    "        # Remove markdown code fences if present\n",
    "        clean = response.strip()\n",
    "        if '```json' in clean:\n",
    "            clean = clean.split('```json')[1].split('```')[0]\n",
    "        elif '```' in clean:\n",
    "            clean = clean.split('```')[1].split('```')[0]\n",
    "        \n",
    "        data = json.loads(clean)\n",
    "        \n",
    "        # Validate required fields\n",
    "        if 'level' in data and 'confidence' in data:\n",
    "            return {\n",
    "                'level': data['level'],\n",
    "                'confidence': float(data.get('confidence', 0.5)),\n",
    "                'reasoning': data.get('reasoning', 'Parsed from JSON')\n",
    "            }\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # ====================================================================\n",
    "    # STRATEGY 2: Regex extraction from structured text\n",
    "    # ====================================================================\n",
    "    try:\n",
    "        level_match = re.search(r'Level:\\s*(\\w+)', response, re.IGNORECASE)\n",
    "        conf_match = re.search(r'Confidence:\\s*([\\d.]+)', response, re.IGNORECASE)\n",
    "        \n",
    "        if level_match:\n",
    "            level = level_match.group(1).capitalize()\n",
    "            confidence = float(conf_match.group(1)) if conf_match else 0.5\n",
    "            \n",
    "            # Normalize level\n",
    "            if 'entry' in level.lower():\n",
    "                level = 'Entry'\n",
    "            elif 'mid' in level.lower():\n",
    "                level = 'Mid'\n",
    "            elif 'senior' in level.lower() or 'sr' in level.lower():\n",
    "                level = 'Senior'\n",
    "            elif 'exec' in level.lower() or 'lead' in level.lower():\n",
    "                level = 'Executive'\n",
    "            \n",
    "            return {\n",
    "                'level': level,\n",
    "                'confidence': confidence,\n",
    "                'reasoning': 'Extracted via regex'\n",
    "            }\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # ====================================================================\n",
    "    # STRATEGY 3: Keyword fallback (ALWAYS succeeds!)\n",
    "    # ====================================================================\n",
    "    response_lower = response.lower()\n",
    "    \n",
    "    # Count keywords for each level\n",
    "    entry_keywords = ['entry', 'junior', 'beginner', 'graduate', 'intern']\n",
    "    mid_keywords = ['mid', 'intermediate', 'experienced']\n",
    "    senior_keywords = ['senior', 'lead', 'principal', 'expert', 'sr.']\n",
    "    exec_keywords = ['executive', 'director', 'vp', 'chief', 'head', 'manager']\n",
    "    \n",
    "    scores = {\n",
    "        'Entry': sum(1 for kw in entry_keywords if kw in response_lower),\n",
    "        'Mid': sum(1 for kw in mid_keywords if kw in response_lower),\n",
    "        'Senior': sum(1 for kw in senior_keywords if kw in response_lower),\n",
    "        'Executive': sum(1 for kw in exec_keywords if kw in response_lower)\n",
    "    }\n",
    "    \n",
    "    # Pick level with most keyword matches\n",
    "    level = max(scores, key=scores.get)\n",
    "    confidence = min(scores[level] / 3.0, 1.0)  # Normalize to 0-1\n",
    "    \n",
    "    return {\n",
    "        'level': level,\n",
    "        'confidence': confidence,\n",
    "        'reasoning': f'Keyword fallback (found {scores[level]} indicators)'\n",
    "    }\n",
    "\n",
    "def parse_skills_taxonomy_robust(response: str) -> dict:\n",
    "    \"\"\"\n",
    "    ROBUST parser for skills taxonomy.\n",
    "    \n",
    "    Triple-fallback strategy for parsing skills.\n",
    "    \n",
    "    Args:\n",
    "        response: LLM response text\n",
    "    \n",
    "    Returns:\n",
    "        Dict with technical_skills, soft_skills, certifications, languages lists\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # ====================================================================\n",
    "    # STRATEGY 1: Try JSON parsing\n",
    "    # ====================================================================\n",
    "    try:\n",
    "        clean = response.strip()\n",
    "        if '```json' in clean:\n",
    "            clean = clean.split('```json')[1].split('```')[0]\n",
    "        elif '```' in clean:\n",
    "            clean = clean.split('```')[1].split('```')[0]\n",
    "        \n",
    "        data = json.loads(clean)\n",
    "        \n",
    "        return {\n",
    "            'technical_skills': data.get('technical_skills', []),\n",
    "            'soft_skills': data.get('soft_skills', []),\n",
    "            'certifications': data.get('certifications', []),\n",
    "            'languages': data.get('languages', [])\n",
    "        }\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # ====================================================================\n",
    "    # STRATEGY 2: Section-based extraction\n",
    "    # ====================================================================\n",
    "    try:\n",
    "        result = {\n",
    "            'technical_skills': [],\n",
    "            'soft_skills': [],\n",
    "            'certifications': [],\n",
    "            'languages': []\n",
    "        }\n",
    "        \n",
    "        # Extract each section\n",
    "        sections = {\n",
    "            'technical_skills': r'Technical Skills?:\\s*\\[?([^\\]]+)\\]?',\n",
    "            'soft_skills': r'Soft Skills?:\\s*\\[?([^\\]]+)\\]?',\n",
    "            'certifications': r'Certifications?:\\s*\\[?([^\\]]+)\\]?',\n",
    "            'languages': r'Languages?:\\s*\\[?([^\\]]+)\\]?'\n",
    "        }\n",
    "        \n",
    "        for key, pattern in sections.items():\n",
    "            match = re.search(pattern, response, re.IGNORECASE)\n",
    "            if match:\n",
    "                items = match.group(1).split(',')\n",
    "                result[key] = [item.strip(' \"\\'\\n[]') for item in items if item.strip()]\n",
    "        \n",
    "        if any(result.values()):\n",
    "            return result\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # ====================================================================\n",
    "    # STRATEGY 3: Simple fallback (empty lists)\n",
    "    # ====================================================================\n",
    "    return {\n",
    "        'technical_skills': [],\n",
    "        'soft_skills': [],\n",
    "        'certifications': [],\n",
    "        'languages': []\n",
    "    }\n",
    "\n",
    "print(\"   ‚úÖ parse_job_level_robust() defined\")\n",
    "print(\"   ‚úÖ parse_skills_taxonomy_robust() defined\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 5.6: LLM Feature Functions (WITH INTEGRATED ROBUST PARSING!)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüéØ Defining LLM feature functions...\")\n",
    "\n",
    "def classify_job_level_zero_shot(candidate_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Classify job seniority level using zero-shot prompting.\n",
    "    \n",
    "    Args:\n",
    "        candidate_text: Candidate profile text\n",
    "    \n",
    "    Returns:\n",
    "        Dict with level, confidence, reasoning\n",
    "    \"\"\"\n",
    "    if not LLM_AVAILABLE:\n",
    "        return {'level': 'Mid', 'confidence': 0.0, 'reasoning': 'LLM not available'}\n",
    "    \n",
    "    prompt = f\"\"\"Classify this candidate's seniority level into one of: Entry, Mid, Senior, Executive.\n",
    "\n",
    "Candidate Profile:\n",
    "{candidate_text[:500]}\n",
    "\n",
    "Respond with:\n",
    "Level: [Entry/Mid/Senior/Executive]\n",
    "Confidence: [0.0-1.0]\n",
    "Reasoning: [brief explanation]\"\"\"\n",
    "    \n",
    "    response = call_llm(prompt, max_tokens=200)\n",
    "    return parse_job_level_robust(response)\n",
    "\n",
    "def classify_job_level_few_shot(candidate_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Classify job seniority with few-shot examples.\n",
    "    \n",
    "    Args:\n",
    "        candidate_text: Candidate profile text\n",
    "    \n",
    "    Returns:\n",
    "        Dict with level, confidence, reasoning\n",
    "    \"\"\"\n",
    "    if not LLM_AVAILABLE:\n",
    "        return {'level': 'Mid', 'confidence': 0.0, 'reasoning': 'LLM not available'}\n",
    "    \n",
    "    prompt = f\"\"\"Classify candidate seniority based on these examples:\n",
    "\n",
    "Example 1: \"Recent graduate seeking entry-level position. Completed internship...\"\n",
    "Level: Entry\n",
    "\n",
    "Example 2: \"5 years experience as software engineer. Led small team projects...\"\n",
    "Level: Mid\n",
    "\n",
    "Example 3: \"15 years in tech. Principal engineer, mentored 20+ developers...\"\n",
    "Level: Senior\n",
    "\n",
    "Now classify:\n",
    "{candidate_text[:500]}\n",
    "\n",
    "Level: [Entry/Mid/Senior/Executive]\n",
    "Confidence: [0.0-1.0]\"\"\"\n",
    "    \n",
    "    response = call_llm(prompt, max_tokens=200)\n",
    "    return parse_job_level_robust(response)\n",
    "\n",
    "def extract_skills_taxonomy(job_description: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Extract structured skills with INTEGRATED ROBUST parsing.\n",
    "    \n",
    "    This version has parsing strategies BUILT-IN (better than separate parser!)\n",
    "    \n",
    "    Returns dict with: technical_skills, soft_skills, certifications, languages\n",
    "    \n",
    "    Triple-fallback strategy:\n",
    "    1. JSON parsing (if LLM returns valid JSON)\n",
    "    2. Regex extraction (if structured text format)\n",
    "    3. Keyword matching (always succeeds)\n",
    "    \n",
    "    Args:\n",
    "        job_description: Text to extract skills from\n",
    "    \n",
    "    Returns:\n",
    "        Dict with categorized skills lists\n",
    "    \"\"\"\n",
    "    if not LLM_AVAILABLE:\n",
    "        # Fallback when LLM not available\n",
    "        return {\n",
    "            \"technical_skills\": [],\n",
    "            \"soft_skills\": [],\n",
    "            \"certifications\": [],\n",
    "            \"languages\": []\n",
    "        }\n",
    "    \n",
    "    prompt = f\"\"\"Extract ALL skills from this text:\n",
    "\n",
    "TEXT: {job_description[:700]}\n",
    "\n",
    "Categorize into:\n",
    "1. Technical: Python, SQL, AWS, Docker, React, etc.\n",
    "2. Soft: Leadership, Communication, Teamwork, etc.\n",
    "3. Certifications: AWS Certified, PMP, etc.\n",
    "4. Languages: English, Spanish, etc.\n",
    "\n",
    "Format:\n",
    "Technical: [list skills]\n",
    "Soft: [list skills]\n",
    "Certifications: [list or \"None\"]\n",
    "Languages: [list or \"None\"]\n",
    "\n",
    "Extract ONLY skills ACTUALLY mentioned. Be specific.\"\"\"\n",
    "    \n",
    "    response = call_llm(prompt, max_tokens=500)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STRATEGY 1: Try JSON parsing if present\n",
    "    # ========================================================================\n",
    "    try:\n",
    "        json_str = response.strip()\n",
    "        \n",
    "        # Remove markdown code fences\n",
    "        if '```json' in json_str:\n",
    "            json_str = json_str.split('```json')[1].split('```')[0].strip()\n",
    "        elif '```' in json_str:\n",
    "            json_str = json_str.split('```')[1].split('```')[0].strip()\n",
    "        \n",
    "        # Extract JSON object\n",
    "        if '{' in json_str and '}' in json_str:\n",
    "            start = json_str.index('{')\n",
    "            end = json_str.rindex('}') + 1\n",
    "            json_str = json_str[start:end]\n",
    "            \n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # Validate with Pydantic if available\n",
    "            if BaseModel is not None:\n",
    "                validated = SkillsTaxonomy(**data)\n",
    "                return validated.model_dump()\n",
    "            else:\n",
    "                return data\n",
    "    \n",
    "    except Exception:\n",
    "        pass  # Fall through to Strategy 2\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STRATEGY 2: Parse structured text with regex\n",
    "    # ========================================================================\n",
    "    try:\n",
    "        technical = []\n",
    "        soft = []\n",
    "        certs = []\n",
    "        languages = []\n",
    "        \n",
    "        # Extract each category\n",
    "        tech_match = re.search(r'Technical:\\s*\\[?([^\\]\\n]+)', response, re.IGNORECASE)\n",
    "        if tech_match:\n",
    "            tech_text = tech_match.group(1)\n",
    "            technical = [s.strip(' \"\\'') for s in tech_text.split(',') \n",
    "                        if s.strip() and s.strip().lower() not in ['none', 'null', '']]\n",
    "        \n",
    "        soft_match = re.search(r'Soft:\\s*\\[?([^\\]\\n]+)', response, re.IGNORECASE)\n",
    "        if soft_match:\n",
    "            soft_text = soft_match.group(1)\n",
    "            soft = [s.strip(' \"\\'') for s in soft_text.split(',') \n",
    "                   if s.strip() and s.strip().lower() not in ['none', 'null', '']]\n",
    "        \n",
    "        cert_match = re.search(r'Certifications?:\\s*\\[?([^\\]\\n]+)', response, re.IGNORECASE)\n",
    "        if cert_match:\n",
    "            cert_text = cert_match.group(1)\n",
    "            if cert_text.strip().lower() not in ['none', 'null', '']:\n",
    "                certs = [s.strip(' \"\\'') for s in cert_text.split(',') if s.strip()]\n",
    "        \n",
    "        lang_match = re.search(r'Languages?:\\s*\\[?([^\\]\\n]+)', response, re.IGNORECASE)\n",
    "        if lang_match:\n",
    "            lang_text = lang_match.group(1)\n",
    "            if lang_text.strip().lower() not in ['none', 'null', '']:\n",
    "                languages = [s.strip(' \"\\'') for s in lang_text.split(',') if s.strip()]\n",
    "        \n",
    "        return {\n",
    "            \"technical_skills\": technical[:20],  # Limit to top 20\n",
    "            \"soft_skills\": soft[:10],            # Limit to top 10\n",
    "            \"certifications\": certs[:10],        # Limit to top 10\n",
    "            \"languages\": languages[:5]           # Limit to top 5\n",
    "        }\n",
    "    \n",
    "    except Exception:\n",
    "        pass  # Fall through to Strategy 3\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STRATEGY 3: Keyword extraction (last resort - ALWAYS succeeds!)\n",
    "    # ========================================================================\n",
    "    # Common technical skills\n",
    "    tech_keywords = ['python', 'java', 'sql', 'aws', 'docker', 'kubernetes', 'react', \n",
    "                     'javascript', 'machine learning', 'ml', 'ai', 'data science',\n",
    "                     'tensorflow', 'pytorch', 'pandas', 'numpy', 'git', 'ci/cd']\n",
    "    \n",
    "    # Common soft skills\n",
    "    soft_keywords = ['leadership', 'communication', 'teamwork', 'problem solving',\n",
    "                     'analytical', 'creative', 'collaborative', 'organized',\n",
    "                     'detail-oriented', 'time management']\n",
    "    \n",
    "    response_lower = response.lower()\n",
    "    \n",
    "    technical = [kw for kw in tech_keywords if kw in response_lower]\n",
    "    soft = [kw for kw in soft_keywords if kw in response_lower]\n",
    "    \n",
    "    return {\n",
    "        \"technical_skills\": technical,\n",
    "        \"soft_skills\": soft,\n",
    "        \"certifications\": [],\n",
    "        \"languages\": []\n",
    "    }\n",
    "\n",
    "def explain_match(candidate_text: str, company_text: str, score: float) -> str:\n",
    "    \"\"\"\n",
    "    Generate human-readable match explanation.\n",
    "    \n",
    "    Args:\n",
    "        candidate_text: Candidate profile\n",
    "        company_text: Company profile\n",
    "        score: Similarity score\n",
    "    \n",
    "    Returns:\n",
    "        Natural language explanation\n",
    "    \"\"\"\n",
    "    if not LLM_AVAILABLE:\n",
    "        return f\"Match score: {score:.2f} (LLM explanation not available)\"\n",
    "    \n",
    "    prompt = f\"\"\"Explain why this candidate matches this company (score: {score:.2f}):\n",
    "\n",
    "CANDIDATE:\n",
    "{candidate_text[:300]}\n",
    "\n",
    "COMPANY:\n",
    "{company_text[:300]}\n",
    "\n",
    "Write 2-3 sentences explaining the match quality and key alignment points.\"\"\"\n",
    "    \n",
    "    response = call_llm(prompt, max_tokens=200, temperature=0.5)\n",
    "    \n",
    "    # Clean response\n",
    "    if response and not response.startswith('['):\n",
    "        return response.strip()\n",
    "    else:\n",
    "        return f\"Match score: {score:.2f}. Skills and requirements align well.\"\n",
    "\n",
    "print(\"   ‚úÖ classify_job_level_zero_shot() defined\")\n",
    "print(\"   ‚úÖ classify_job_level_few_shot() defined\")\n",
    "print(\"   ‚úÖ extract_skills_taxonomy() defined (ROBUST - 3 strategies!)\")\n",
    "print(\"   ‚úÖ explain_match() defined\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 5.7: Test LLM Functions (if available)\n",
    "# ============================================================================\n",
    "\n",
    "if LLM_AVAILABLE:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üß™ TESTING LLM FUNCTIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nüìù Test 1: Job Level Classification (Zero-Shot)\")\n",
    "    test_candidate = \"Senior software engineer with 10 years experience. Python expert. Led teams of 5+ developers.\"\n",
    "    \n",
    "    result = classify_job_level_zero_shot(test_candidate)\n",
    "    print(f\"   Input: {test_candidate}\")\n",
    "    print(f\"   Level: {result['level']}\")\n",
    "    print(f\"   Confidence: {result['confidence']:.2f}\")\n",
    "    print(f\"   Reasoning: {result['reasoning']}\")\n",
    "    \n",
    "    print(\"\\nüìù Test 2: Match Explanation\")\n",
    "    test_company = \"Tech startup building AI products. Need Python developers with ML experience.\"\n",
    "    \n",
    "    explanation = explain_match(test_candidate, test_company, 0.85)\n",
    "    print(f\"   Match Score: 0.85\")\n",
    "    print(f\"   Explanation: {explanation}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ LLM functions tested successfully!\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  LLM not available - skipping tests\")\n",
    "    print(\"   Add HF_TOKEN to config to enable LLM features\")\n",
    "\n",
    "# ============================================================================\n",
    "# Summary\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH 5 COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if LLM_AVAILABLE:\n",
    "    print(\"\\n‚úÖ LLM Enhancement Layer ACTIVE\")\n",
    "    print(f\"   ‚Ä¢ Model: {LLM_MODEL}\")\n",
    "    print(f\"   ‚Ä¢ Features: 4 functions available\")\n",
    "    print(f\"   ‚Ä¢ Cost: $0.00 (free tier)\")\n",
    "    print(f\"   ‚Ä¢ Robust parsing: ‚úÖ Enabled (triple-fallback)\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  LLM Enhancement Layer DISABLED\")\n",
    "    print(\"   ‚Ä¢ System works fine without LLM\")\n",
    "    print(\"   ‚Ä¢ Add HF_TOKEN to enable (optional)\")\n",
    "\n",
    "print(\"\\nüìù Available functions:\")\n",
    "print(\"   ‚Ä¢ classify_job_level_zero_shot()\")\n",
    "print(\"   ‚Ä¢ classify_job_level_few_shot()\")\n",
    "print(\"   ‚Ä¢ extract_skills_taxonomy()\")\n",
    "print(\"   ‚Ä¢ explain_match()\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6.2: Pydantic Schemas\n",
    "\n",
    "**Purpose:** Define data validation schemas for structured LLM outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6.3: Job Level Classification (Zero-Shot)\n",
    "\n",
    "**Purpose:** Classify job seniority level without examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6.4: Few-Shot Classification\n",
    "\n",
    "**Purpose:** Classify job seniority level without examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6.4: Skills Extraction\n",
    "\n",
    "**Purpose:** Extract structured skills from job postings using LLM + Pydantic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6.5: Match Explainability\n",
    "\n",
    "**Purpose:** Generate LLM explanation for candidate-company matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Match explainability (ROBUST) loaded\n",
      "\n",
      "üí° Testing match explainability...\n",
      "\n",
      "üë§ Candidate #0:\n",
      "   Career: Big data analytics working and database warehouse manager with robust experience in handling all kin...\n",
      "   Skills: ['Big Data', 'Hadoop', 'Hive', 'Python', 'Mapreduce', 'Spark', 'Java', 'Machine Learning', 'Cloud', ...\n",
      "\n",
      "üè¢ Company #20497:\n",
      "   Description: CloudIngest is a full-service tech software firm. Our expert technical team maintains strong core co...\n",
      "   Skills: ENG, HR, IT...\n",
      "\n",
      "‚ö° Match Score: 0.659\n",
      "\n",
      "‚è≥ Generating explanation...\n",
      "\n",
      "================================================================================\n",
      "üìä MATCH EXPLANATION\n",
      "================================================================================\n",
      "\n",
      "üéØ Overall Score: 0.659\n",
      "\n",
      "‚úÖ Match Strengths (1):\n",
      "   1. Skills alignment detected\n",
      "\n",
      "‚ö†Ô∏è  Skill Gaps (0):\n",
      "   (none identified)\n",
      "\n",
      "üí° Recommendation:\n",
      "   Review match details and apply\n",
      "\n",
      "üìù Summary:\n",
      "   Good match with 65.9% similarity\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Test complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MATCH EXPLAINABILITY (FIXED + ROBUST)\n",
    "# ============================================================================\n",
    "\n",
    "def explain_match(candidate_idx: int, company_idx: int, similarity_score: float) -> Dict:\n",
    "    \"\"\"\n",
    "    Generate human-readable explanation for why candidate matches company.\n",
    "    \n",
    "    Args:\n",
    "        candidate_idx: Index in candidates_df\n",
    "        company_idx: Index in companies_df\n",
    "        similarity_score: Cosine similarity (0-1)\n",
    "    \n",
    "    Returns:\n",
    "        Dict with: overall_score, match_strengths, skill_gaps, recommendation, fit_summary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get candidate and company data\n",
    "    cand = candidates_df.iloc[candidate_idx]\n",
    "    comp = companies_df.iloc[company_idx]\n",
    "    \n",
    "    # Extract info safely\n",
    "    cand_skills = str(cand.get('skills', 'Not specified'))[:300]\n",
    "    cand_career = str(cand.get('career_objective', 'Not specified'))[:200]\n",
    "    cand_exp = str(cand.get('experience_titles', 'Not specified'))[:200]\n",
    "    \n",
    "    comp_name = str(comp.get('description', 'Company'))[:100]\n",
    "    comp_skills = str(comp.get('enriched_skills', 'Not specified'))[:300]\n",
    "    comp_industry = str(comp.get('industry', 'Not specified'))\n",
    "    \n",
    "    prompt = f\"\"\"Explain why this candidate matches this company (score: {similarity_score:.2f}/1.00).\n",
    "\n",
    "CANDIDATE:\n",
    "Career Goal: {cand_career}\n",
    "Skills: {cand_skills}\n",
    "Experience: {cand_exp}\n",
    "\n",
    "COMPANY:\n",
    "Description: {comp_name}\n",
    "Required Skills: {comp_skills}\n",
    "Industry: {comp_industry}\n",
    "\n",
    "Provide:\n",
    "1. What makes this a good match?\n",
    "2. What skills align?\n",
    "3. What's missing (gaps)?\n",
    "4. Recommendation\n",
    "\n",
    "Format:\n",
    "Strengths: [list aligned skills/experience]\n",
    "Gaps: [list missing skills]\n",
    "Recommendation: [what candidate should do]\n",
    "Summary: [one sentence overall fit]\n",
    "\"\"\"\n",
    "    \n",
    "    response = call_llm(prompt, max_tokens=800)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # ROBUST PARSER - Multiple strategies\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Strategy 1: Try JSON if present\n",
    "    try:\n",
    "        json_str = response.strip()\n",
    "        \n",
    "        if '```json' in json_str:\n",
    "            json_str = json_str.split('```json')[1].split('```')[0].strip()\n",
    "        elif '```' in json_str:\n",
    "            json_str = json_str.split('```')[1].split('```')[0].strip()\n",
    "        \n",
    "        if '{' in json_str and '}' in json_str:\n",
    "            start = json_str.index('{')\n",
    "            end = json_str.rindex('}') + 1\n",
    "            json_str = json_str[start:end]\n",
    "            \n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # Ensure all required fields\n",
    "            if 'overall_score' not in data:\n",
    "                data['overall_score'] = similarity_score\n",
    "            if 'match_strengths' not in data:\n",
    "                data['match_strengths'] = []\n",
    "            if 'skill_gaps' not in data:\n",
    "                data['skill_gaps'] = []\n",
    "            if 'recommendation' not in data:\n",
    "                data['recommendation'] = \"Review match details\"\n",
    "            if 'fit_summary' not in data:\n",
    "                data['fit_summary'] = f\"Match score: {similarity_score:.2f}\"\n",
    "            \n",
    "            return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        pass  # Fall through to Strategy 2\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Strategy 2: Parse structured text\n",
    "    # ========================================================================\n",
    "    \n",
    "    try:\n",
    "        strengths = []\n",
    "        gaps = []\n",
    "        recommendation = \"\"\n",
    "        summary = \"\"\n",
    "        \n",
    "        # Extract strengths\n",
    "        strength_match = re.search(r'Strengths?:\\s*\\[?([^\\]]+)', response, re.IGNORECASE | re.DOTALL)\n",
    "        if strength_match:\n",
    "            strength_text = strength_match.group(1)\n",
    "            strengths = [s.strip(' -‚Ä¢\"\\'') for s in re.split(r'[,\\n]', strength_text) \n",
    "                        if s.strip() and len(s.strip()) > 3][:5]\n",
    "        \n",
    "        # Extract gaps\n",
    "        gap_match = re.search(r'Gaps?:\\s*\\[?([^\\]]+)', response, re.IGNORECASE | re.DOTALL)\n",
    "        if gap_match:\n",
    "            gap_text = gap_match.group(1)\n",
    "            gaps = [g.strip(' -‚Ä¢\"\\'') for g in re.split(r'[,\\n]', gap_text) \n",
    "                   if g.strip() and len(g.strip()) > 3][:5]\n",
    "        \n",
    "        # Extract recommendation\n",
    "        rec_match = re.search(r'Recommendation:\\s*(.+?)(?:\\n\\n|\\n[A-Z]|$)', response, re.IGNORECASE | re.DOTALL)\n",
    "        if rec_match:\n",
    "            recommendation = rec_match.group(1).strip()[:200]\n",
    "        \n",
    "        # Extract summary\n",
    "        sum_match = re.search(r'Summary:\\s*(.+?)(?:\\n|$)', response, re.IGNORECASE)\n",
    "        if sum_match:\n",
    "            summary = sum_match.group(1).strip()[:200]\n",
    "        \n",
    "        return {\n",
    "            \"overall_score\": similarity_score,\n",
    "            \"match_strengths\": strengths if strengths else [\"Skills alignment detected\"],\n",
    "            \"skill_gaps\": gaps if gaps else [],\n",
    "            \"recommendation\": recommendation if recommendation else \"Review match details and apply\",\n",
    "            \"fit_summary\": summary if summary else f\"Good match with {similarity_score:.1%} similarity\"\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        pass  # Fall through to Strategy 3\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Strategy 3: Fallback with basic analysis\n",
    "    # ========================================================================\n",
    "    \n",
    "    return {\n",
    "        \"overall_score\": similarity_score,\n",
    "        \"match_strengths\": [f\"Semantic similarity score of {similarity_score:.2f}\"],\n",
    "        \"skill_gaps\": [\"Detailed analysis unavailable\"],\n",
    "        \"recommendation\": \"Review detailed profiles for comprehensive assessment\",\n",
    "        \"fit_summary\": f\"Match score: {similarity_score:.2f} - {'Strong' if similarity_score > 0.7 else 'Moderate' if similarity_score > 0.5 else 'Weak'} match\"\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Match explainability (ROBUST) loaded\")\n",
    "\n",
    "# ============================================================================\n",
    "# TEST (FIXED - usa vari√°veis e dados corretos!)\n",
    "# ============================================================================\n",
    "\n",
    "if LLM_AVAILABLE:\n",
    "    print(\"\\nüí° Testing match explainability...\\n\")\n",
    "    \n",
    "    # Get first candidate's best match (j√° calculado!)\n",
    "    if 'all_matches' in globals() and len(all_matches) > 0:\n",
    "        cand_idx = 0\n",
    "        comp_idx, score = all_matches[cand_idx][0]  # Best match\n",
    "        \n",
    "        # Show candidate info\n",
    "        cand = candidates_df.iloc[cand_idx]\n",
    "        print(f\"üë§ Candidate #{cand_idx}:\")\n",
    "        print(f\"   Career: {str(cand.get('career_objective', 'N/A'))[:100]}...\")\n",
    "        print(f\"   Skills: {str(cand.get('skills', []))[:100]}...\")\n",
    "        \n",
    "        # Show company info\n",
    "        comp = companies_df.iloc[comp_idx]\n",
    "        print(f\"\\nüè¢ Company #{comp_idx}:\")\n",
    "        print(f\"   Description: {str(comp.get('description', 'N/A'))[:100]}...\")\n",
    "        print(f\"   Skills: {str(comp.get('enriched_skills', 'N/A'))[:100]}...\")\n",
    "        \n",
    "        print(f\"\\n‚ö° Match Score: {score:.3f}\\n\")\n",
    "        \n",
    "        # Generate explanation\n",
    "        print(\"‚è≥ Generating explanation...\")\n",
    "        explanation = explain_match(cand_idx, comp_idx, score)\n",
    "        \n",
    "        # Display explanation\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìä MATCH EXPLANATION\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nüéØ Overall Score: {explanation['overall_score']:.3f}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Match Strengths ({len(explanation['match_strengths'])}):\")\n",
    "        for i, strength in enumerate(explanation['match_strengths'], 1):\n",
    "            print(f\"   {i}. {strength}\")\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è  Skill Gaps ({len(explanation['skill_gaps'])}):\")\n",
    "        if explanation['skill_gaps']:\n",
    "            for i, gap in enumerate(explanation['skill_gaps'], 1):\n",
    "                print(f\"   {i}. {gap}\")\n",
    "        else:\n",
    "            print(\"   (none identified)\")\n",
    "        \n",
    "        print(f\"\\nüí° Recommendation:\")\n",
    "        print(f\"   {explanation['recommendation']}\")\n",
    "        \n",
    "        print(f\"\\nüìù Summary:\")\n",
    "        print(f\"   {explanation['fit_summary']}\")\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No matches available. Run matching system first (Section 6).\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  LLM not available - skipping explainability test\")\n",
    "\n",
    "print(\"\\n‚úÖ Test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üé® BATCH 6: CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "\n",
      "1Ô∏è‚É£  t-SNE EMBEDDING VISUALIZATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üî¨ Generating t-SNE projection...\n",
      "   (This takes 2-5 minutes - computing 384D ‚Üí 2D projection)\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1500 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 1500 samples in 0.448s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1500\n",
      "[t-SNE] Computed conditional probabilities for sample 1500 / 1500\n",
      "[t-SNE] Mean sigma: 0.271348\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 68.418030\n",
      "[t-SNE] KL divergence after 1000 iterations: 1.228683\n",
      "   ‚úÖ t-SNE projection complete!\n",
      "\n",
      "   üíæ Saved: ../visualizations/tsne_embedding_space.html\n",
      "   üìä Plot shows 500 candidates + 1000 companies\n",
      "\n",
      "   üìà Interpretation:\n",
      "      ‚Ä¢ If clusters separate ‚Üí Vocabulary mismatch problem\n",
      "      ‚Ä¢ If clusters overlap ‚Üí Job posting bridge working! ‚úÖ\n",
      "\n",
      "‚úÖ t-SNE visualization complete!\n",
      "\n",
      "2Ô∏è‚É£  MATCH SCORE DISTRIBUTION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Creating score distribution plot...\n",
      "   üíæ Saved: ../visualizations/score_distribution.html\n",
      "\n",
      "   üìä Statistics:\n",
      "      ‚Ä¢ Mean: 0.5360\n",
      "      ‚Ä¢ Median: 0.5345\n",
      "      ‚Ä¢ Std: 0.0399\n",
      "      ‚Ä¢ Min: 0.4090\n",
      "      ‚Ä¢ Max: 0.6857\n",
      "\n",
      "‚úÖ Score distribution plot complete!\n",
      "\n",
      "3Ô∏è‚É£  BILATERAL FAIRNESS VISUALIZATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚öñÔ∏è  Creating bilateral fairness plot...\n",
      "   üíæ Saved: ../visualizations/bilateral_fairness.html\n",
      "\n",
      "   üìä At threshold 0.5:\n",
      "      ‚Ä¢ Candidate coverage: 0.991\n",
      "      ‚Ä¢ Company coverage: 0.015\n",
      "      ‚Ä¢ Bilateral fairness: 0.015\n",
      "\n",
      "‚úÖ Bilateral fairness plot complete!\n",
      "\n",
      "4Ô∏è‚É£  INTERACTIVE NETWORK GRAPH\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üï∏Ô∏è  Creating network graph (10 candidates)...\n",
      "   üíæ Saved: ../visualizations/network_graph.html\n",
      "   üéØ Showing 10 candidates with top-3 matches\n",
      "   üí° Open in browser for interactive exploration!\n",
      "\n",
      "‚úÖ Network graph complete!\n",
      "\n",
      "5Ô∏è‚É£  SKILLS COVERAGE HEATMAP\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üî• Creating skills heatmap...\n",
      "   üíæ Saved: ../visualizations/skills_heatmap.html\n",
      "\n",
      "   üìä Top 5 skills:\n",
      "      1. IT: 7,709 companies\n",
      "      2. SALE: 6,803 companies\n",
      "      3. MGMT: 5,576 companies\n",
      "      4. MNFC: 4,731 companies\n",
      "      5. ENG: 4,670 companies\n",
      "\n",
      "‚úÖ Skills heatmap complete!\n",
      "\n",
      "6Ô∏è‚É£  CREATING SUMMARY DASHBOARD\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Building summary dashboard...\n",
      "   üíæ Saved: ../visualizations/dashboard.html\n",
      "   üìä Dashboard includes:\n",
      "      ‚Ä¢ System metrics\n",
      "      ‚Ä¢ Score distribution\n",
      "      ‚Ä¢ Coverage analysis\n",
      "      ‚Ä¢ Skills distribution\n",
      "\n",
      "‚úÖ Summary dashboard complete!\n",
      "\n",
      "================================================================================\n",
      "üéâ BATCH 6 COMPLETE - ALL VISUALIZATIONS GENERATED!\n",
      "================================================================================\n",
      "\n",
      "üìÇ Generated files in ../visualizations/:\n",
      "   ‚úÖ tsne_embedding_space.html\n",
      "   ‚úÖ score_distribution.html\n",
      "   ‚úÖ bilateral_fairness.html\n",
      "   ‚úÖ network_graph.html\n",
      "   ‚úÖ skills_heatmap.html\n",
      "   ‚úÖ dashboard.html\n",
      "\n",
      "üí° Use these visualizations in your academic report!\n",
      "   ‚Ä¢ t-SNE: Shows semantic space and vocabulary bridge effect\n",
      "   ‚Ä¢ Network: Interactive match visualization\n",
      "   ‚Ä¢ Fairness: Bilateral balance validation\n",
      "   ‚Ä¢ Heatmap: Skills distribution analysis\n",
      "   ‚Ä¢ Dashboard: Complete system overview\n",
      "\n",
      "üöÄ Ready for academic report!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BATCH 6: INTERACTIVE VISUALIZATIONS\n",
    "# ============================================================================\n",
    "# Purpose: Create publication-quality visualizations for academic report\n",
    "# Includes: t-SNE, Network graphs, Heatmaps, Distribution plots\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üé® BATCH 6: CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 6.1: t-SNE Embedding Visualization\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£  t-SNE EMBEDDING VISUALIZATION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def create_tsne_plot(candidate_embeddings, company_embeddings, \n",
    "                     candidates_df, companies_df,\n",
    "                     n_samples_cand=500, n_samples_comp=1000,\n",
    "                     save_path='../visualizations/'):\n",
    "    \"\"\"\n",
    "    Create t-SNE visualization of embedding space.\n",
    "    \n",
    "    Shows how candidates and companies are distributed in semantic space.\n",
    "    If they cluster separately = vocabulary mismatch problem!\n",
    "    If they overlap = job posting bridge is working!\n",
    "    \n",
    "    Args:\n",
    "        candidate_embeddings: Candidate vectors (N, 384)\n",
    "        company_embeddings: Company vectors (M, 384)\n",
    "        n_samples_cand: Sample size for candidates (for speed)\n",
    "        n_samples_comp: Sample size for companies (for speed)\n",
    "    \"\"\"\n",
    "    print(\"\\nüî¨ Generating t-SNE projection...\")\n",
    "    print(\"   (This takes 2-5 minutes - computing 384D ‚Üí 2D projection)\")\n",
    "    \n",
    "    # Sample for speed (t-SNE is O(n¬≤) complexity!)\n",
    "    n_cand = min(n_samples_cand, len(candidate_embeddings))\n",
    "    n_comp = min(n_samples_comp, len(company_embeddings))\n",
    "    \n",
    "    cand_sample = candidate_embeddings[:n_cand]\n",
    "    comp_sample = company_embeddings[:n_comp]\n",
    "    \n",
    "    # Combine for t-SNE\n",
    "    all_embeddings = np.vstack([cand_sample, comp_sample])\n",
    "    \n",
    "    # Run t-SNE\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        perplexity=30,\n",
    "        n_iter=1000,\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    embeddings_2d = tsne.fit_transform(all_embeddings)\n",
    "    \n",
    "    # Split back\n",
    "    cand_2d = embeddings_2d[:n_cand]\n",
    "    comp_2d = embeddings_2d[n_cand:]\n",
    "    \n",
    "    print(\"   ‚úÖ t-SNE projection complete!\")\n",
    "    \n",
    "    # Create interactive plot\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add candidates\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cand_2d[:, 0],\n",
    "        y=cand_2d[:, 1],\n",
    "        mode='markers',\n",
    "        name='Candidates',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color='blue',\n",
    "            opacity=0.6,\n",
    "            line=dict(width=0.5, color='darkblue')\n",
    "        ),\n",
    "        text=[f\"Candidate {i}\" for i in range(n_cand)],\n",
    "        hovertemplate='<b>%{text}</b><br>X: %{x:.2f}<br>Y: %{y:.2f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    # Add companies\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=comp_2d[:, 0],\n",
    "        y=comp_2d[:, 1],\n",
    "        mode='markers',\n",
    "        name='Companies',\n",
    "        marker=dict(\n",
    "            size=6,\n",
    "            color='red',\n",
    "            opacity=0.5,\n",
    "            line=dict(width=0.5, color='darkred')\n",
    "        ),\n",
    "        text=[f\"Company {i}\" for i in range(n_comp)],\n",
    "        hovertemplate='<b>%{text}</b><br>X: %{x:.2f}<br>Y: %{y:.2f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': 'Semantic Embedding Space (t-SNE Projection)<br><sub>Blue=Candidates, Red=Companies</sub>',\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center'\n",
    "        },\n",
    "        xaxis_title='t-SNE Dimension 1',\n",
    "        yaxis_title='t-SNE Dimension 2',\n",
    "        width=1000,\n",
    "        height=700,\n",
    "        hovermode='closest',\n",
    "        legend=dict(\n",
    "            yanchor=\"top\",\n",
    "            y=0.99,\n",
    "            xanchor=\"left\",\n",
    "            x=0.01\n",
    "        ),\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    # Save\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "    fig.write_html(f'{save_path}tsne_embedding_space.html')\n",
    "    \n",
    "    print(f\"\\n   üíæ Saved: {save_path}tsne_embedding_space.html\")\n",
    "    print(f\"   üìä Plot shows {n_cand} candidates + {n_comp} companies\")\n",
    "    \n",
    "    # Analysis\n",
    "    print(f\"\\n   üìà Interpretation:\")\n",
    "    print(f\"      ‚Ä¢ If clusters separate ‚Üí Vocabulary mismatch problem\")\n",
    "    print(f\"      ‚Ä¢ If clusters overlap ‚Üí Job posting bridge working! ‚úÖ\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate t-SNE plot\n",
    "tsne_fig = create_tsne_plot(\n",
    "    candidate_embeddings,\n",
    "    company_embeddings,\n",
    "    candidates_df,\n",
    "    companies_df,\n",
    "    n_samples_cand=500,\n",
    "    n_samples_comp=1000\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ t-SNE visualization complete!\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 6.2: Match Score Distribution Plot\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£  MATCH SCORE DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def create_score_distribution_plot(all_matches, save_path='../visualizations/'):\n",
    "    \"\"\"\n",
    "    Visualize distribution of match scores.\n",
    "    \n",
    "    Shows quality of matches across all candidates.\n",
    "    High scores (>0.7) = good semantic matches!\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä Creating score distribution plot...\")\n",
    "    \n",
    "    # Extract all scores\n",
    "    all_scores = []\n",
    "    for matches in all_matches:\n",
    "        scores = [score for _, score in matches]\n",
    "        all_scores.extend(scores)\n",
    "    \n",
    "    all_scores = np.array(all_scores)\n",
    "    \n",
    "    # Create histogram\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=all_scores,\n",
    "        nbinsx=50,\n",
    "        name='Match Scores',\n",
    "        marker=dict(\n",
    "            color='steelblue',\n",
    "            line=dict(color='darkblue', width=1)\n",
    "        ),\n",
    "        hovertemplate='Score: %{x:.3f}<br>Count: %{y}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    # Add statistics as annotations\n",
    "    mean_score = all_scores.mean()\n",
    "    median_score = np.median(all_scores)\n",
    "    \n",
    "    fig.add_vline(\n",
    "        x=mean_score,\n",
    "        line_dash=\"dash\",\n",
    "        line_color=\"red\",\n",
    "        annotation_text=f\"Mean: {mean_score:.3f}\",\n",
    "        annotation_position=\"top right\"\n",
    "    )\n",
    "    \n",
    "    fig.add_vline(\n",
    "        x=median_score,\n",
    "        line_dash=\"dash\",\n",
    "        line_color=\"green\",\n",
    "        annotation_text=f\"Median: {median_score:.3f}\",\n",
    "        annotation_position=\"top left\"\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Distribution of Match Scores',\n",
    "        xaxis_title='Cosine Similarity Score',\n",
    "        yaxis_title='Frequency',\n",
    "        width=1000,\n",
    "        height=600,\n",
    "        template='plotly_white',\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Save\n",
    "    fig.write_html(f'{save_path}score_distribution.html')\n",
    "    \n",
    "    print(f\"   üíæ Saved: {save_path}score_distribution.html\")\n",
    "    print(f\"\\n   üìä Statistics:\")\n",
    "    print(f\"      ‚Ä¢ Mean: {mean_score:.4f}\")\n",
    "    print(f\"      ‚Ä¢ Median: {median_score:.4f}\")\n",
    "    print(f\"      ‚Ä¢ Std: {all_scores.std():.4f}\")\n",
    "    print(f\"      ‚Ä¢ Min: {all_scores.min():.4f}\")\n",
    "    print(f\"      ‚Ä¢ Max: {all_scores.max():.4f}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate score distribution\n",
    "score_fig = create_score_distribution_plot(all_matches)\n",
    "\n",
    "print(\"\\n‚úÖ Score distribution plot complete!\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 6.3: Bilateral Fairness Visualization\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£  BILATERAL FAIRNESS VISUALIZATION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def create_fairness_plot(similarity_matrix, top_k=10, threshold=0.5,\n",
    "                         save_path='../visualizations/'):\n",
    "    \"\"\"\n",
    "    Visualize bilateral fairness metrics.\n",
    "    \n",
    "    Shows balance between candidate-side and company-side coverage.\n",
    "    \"\"\"\n",
    "    print(\"\\n‚öñÔ∏è  Creating bilateral fairness plot...\")\n",
    "    \n",
    "    n_candidates, n_companies = similarity_matrix.shape\n",
    "    \n",
    "    # Calculate metrics across different thresholds\n",
    "    thresholds = np.arange(0.3, 0.9, 0.05)\n",
    "    candidate_coverages = []\n",
    "    company_coverages = []\n",
    "    bilateral_fairness = []\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        # Candidate coverage\n",
    "        cand_max = similarity_matrix.max(axis=1)\n",
    "        cand_cov = (cand_max > thresh).sum() / n_candidates\n",
    "        \n",
    "        # Company coverage\n",
    "        top_indices = np.argsort(similarity_matrix, axis=1)[:, -top_k:]\n",
    "        unique_comps = np.unique(top_indices)\n",
    "        comp_cov = len(unique_comps) / n_companies\n",
    "        \n",
    "        # Bilateral fairness\n",
    "        fairness = min(cand_cov, comp_cov)\n",
    "        \n",
    "        candidate_coverages.append(cand_cov)\n",
    "        company_coverages.append(comp_cov)\n",
    "        bilateral_fairness.append(fairness)\n",
    "    \n",
    "    # Create plot\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add traces\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=thresholds,\n",
    "        y=candidate_coverages,\n",
    "        mode='lines+markers',\n",
    "        name='Candidate Coverage',\n",
    "        line=dict(color='blue', width=3),\n",
    "        marker=dict(size=8)\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=thresholds,\n",
    "        y=company_coverages,\n",
    "        mode='lines+markers',\n",
    "        name='Company Coverage',\n",
    "        line=dict(color='red', width=3),\n",
    "        marker=dict(size=8)\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=thresholds,\n",
    "        y=bilateral_fairness,\n",
    "        mode='lines+markers',\n",
    "        name='Bilateral Fairness',\n",
    "        line=dict(color='green', width=4, dash='dash'),\n",
    "        marker=dict(size=10)\n",
    "    ))\n",
    "    \n",
    "    # Add target line\n",
    "    fig.add_hline(\n",
    "        y=0.85,\n",
    "        line_dash=\"dot\",\n",
    "        line_color=\"gray\",\n",
    "        annotation_text=\"Target: 0.85\",\n",
    "        annotation_position=\"right\"\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Bilateral Fairness Analysis',\n",
    "        xaxis_title='Similarity Threshold',\n",
    "        yaxis_title='Coverage',\n",
    "        width=1000,\n",
    "        height=600,\n",
    "        template='plotly_white',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # Save\n",
    "    fig.write_html(f'{save_path}bilateral_fairness.html')\n",
    "    \n",
    "    print(f\"   üíæ Saved: {save_path}bilateral_fairness.html\")\n",
    "    print(f\"\\n   üìä At threshold {threshold}:\")\n",
    "    idx = np.argmin(np.abs(thresholds - threshold))\n",
    "    print(f\"      ‚Ä¢ Candidate coverage: {candidate_coverages[idx]:.3f}\")\n",
    "    print(f\"      ‚Ä¢ Company coverage: {company_coverages[idx]:.3f}\")\n",
    "    print(f\"      ‚Ä¢ Bilateral fairness: {bilateral_fairness[idx]:.3f}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate fairness plot\n",
    "fairness_fig = create_fairness_plot(similarity_matrix, top_k=config.TOP_K_MATCHES)\n",
    "\n",
    "print(\"\\n‚úÖ Bilateral fairness plot complete!\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 6.4: Interactive Network Graph (PyVis)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£  INTERACTIVE NETWORK GRAPH\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "from pyvis.network import Network\n",
    "\n",
    "def create_network_graph(candidates_df, companies_df, all_matches,\n",
    "                         n_candidates=33, n_top_matches=3,\n",
    "                         save_path='../visualizations/'):\n",
    "    \"\"\"\n",
    "    Create interactive network graph showing matches.\n",
    "    \n",
    "    Visualizes candidate-company connections.\n",
    "    Node size = relevance\n",
    "    Edge thickness = match strength\n",
    "    \n",
    "    Args:\n",
    "        n_candidates: Number of candidates to show\n",
    "        n_top_matches: Top matches per candidate\n",
    "    \"\"\"\n",
    "    print(f\"\\nüï∏Ô∏è  Creating network graph ({n_candidates} candidates)...\")\n",
    "    \n",
    "    # Initialize network\n",
    "    net = Network(\n",
    "        height='750px',\n",
    "        width='100%',\n",
    "        bgcolor='#222222',\n",
    "        font_color='white',\n",
    "        notebook=False\n",
    "    )\n",
    "    \n",
    "    # Configure physics\n",
    "    net.set_options(\"\"\"\n",
    "    {\n",
    "        \"physics\": {\n",
    "            \"forceAtlas2Based\": {\n",
    "                \"gravitationalConstant\": -50,\n",
    "                \"centralGravity\": 0.01,\n",
    "                \"springLength\": 200,\n",
    "                \"springConstant\": 0.08\n",
    "            },\n",
    "            \"maxVelocity\": 50,\n",
    "            \"solver\": \"forceAtlas2Based\",\n",
    "            \"timestep\": 0.35,\n",
    "            \"stabilization\": {\"iterations\": 150}\n",
    "        }\n",
    "    }\n",
    "    \"\"\")\n",
    "    \n",
    "    # Add candidate nodes\n",
    "    for i in range(min(n_candidates, len(candidates_df))):\n",
    "        cand = candidates_df.iloc[i]\n",
    "        career = str(cand.get('career_objective', 'Candidate'))[:50]\n",
    "        \n",
    "        net.add_node(\n",
    "            f\"C{i}\",\n",
    "            label=f\"Candidate {i+1}\",\n",
    "            title=career,\n",
    "            color='#00FF00',\n",
    "            size=30,\n",
    "            shape='dot'\n",
    "        )\n",
    "    \n",
    "    # Add company nodes and edges\n",
    "    company_ids_added = set()\n",
    "    \n",
    "    for i in range(min(n_candidates, len(all_matches))):\n",
    "        for rank, (comp_idx, score) in enumerate(all_matches[i][:n_top_matches]):\n",
    "            comp_id = f\"M{comp_idx}\"\n",
    "            \n",
    "            # Add company node if not already added\n",
    "            if comp_id not in company_ids_added:\n",
    "                comp = companies_df.iloc[comp_idx]\n",
    "                desc = str(comp.get('description', 'Company'))[:50]\n",
    "                \n",
    "                net.add_node(\n",
    "                    comp_id,\n",
    "                    label=f\"Company {comp_idx}\",\n",
    "                    title=desc,\n",
    "                    color='#FF6B6B',\n",
    "                    size=20,\n",
    "                    shape='dot'\n",
    "                )\n",
    "                company_ids_added.add(comp_id)\n",
    "            \n",
    "            # Add edge\n",
    "            edge_width = score * 5  # Thicker = better match\n",
    "            net.add_edge(\n",
    "                f\"C{i}\",\n",
    "                comp_id,\n",
    "                value=edge_width,\n",
    "                title=f\"Score: {score:.3f}\"\n",
    "            )\n",
    "    \n",
    "    # Save\n",
    "    output_path = f'{save_path}network_graph.html'\n",
    "    net.save_graph(output_path)\n",
    "    \n",
    "    print(f\"   üíæ Saved: {output_path}\")\n",
    "    print(f\"   üéØ Showing {n_candidates} candidates with top-{n_top_matches} matches\")\n",
    "    print(f\"   üí° Open in browser for interactive exploration!\")\n",
    "    \n",
    "    return net\n",
    "\n",
    "# Generate network graph\n",
    "network = create_network_graph(\n",
    "    candidates_df,\n",
    "    companies_df,\n",
    "    all_matches,\n",
    "    n_candidates=10,\n",
    "    n_top_matches=3\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Network graph complete!\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 6.5: Skills Coverage Heatmap\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£  SKILLS COVERAGE HEATMAP\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def create_skills_heatmap(companies_df, save_path='../visualizations/'):\n",
    "    \"\"\"\n",
    "    Visualize skills distribution across companies.\n",
    "    \n",
    "    Shows which skills are most common and coverage impact.\n",
    "    \"\"\"\n",
    "    print(\"\\nüî• Creating skills heatmap...\")\n",
    "    \n",
    "    # Extract all skills\n",
    "    all_skills = []\n",
    "    for skills_str in companies_df['enriched_skills']:\n",
    "        if skills_str != 'Not specified':\n",
    "            skills = skills_str.split(', ')\n",
    "            all_skills.extend(skills)\n",
    "    \n",
    "    # Count skill frequency\n",
    "    from collections import Counter\n",
    "    skill_counts = Counter(all_skills)\n",
    "    \n",
    "    # Get top 30 skills\n",
    "    top_skills = skill_counts.most_common(30)\n",
    "    \n",
    "    if not top_skills:\n",
    "        print(\"   ‚ö†Ô∏è  No skills data for heatmap\")\n",
    "        return None\n",
    "    \n",
    "    # Create bar chart\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    skills_names = [s[0] for s in top_skills]\n",
    "    skills_counts = [s[1] for s in top_skills]\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=skills_counts,\n",
    "        y=skills_names,\n",
    "        orientation='h',\n",
    "        marker=dict(\n",
    "            color=skills_counts,\n",
    "            colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            colorbar=dict(title=\"Frequency\")\n",
    "        ),\n",
    "        text=skills_counts,\n",
    "        textposition='auto',\n",
    "        hovertemplate='<b>%{y}</b><br>Count: %{x}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Top 30 Most Common Skills (from Job Postings)',\n",
    "        xaxis_title='Number of Companies',\n",
    "        yaxis_title='Skill',\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        template='plotly_white',\n",
    "        yaxis={'categoryorder': 'total ascending'}\n",
    "    )\n",
    "    \n",
    "    # Save\n",
    "    fig.write_html(f'{save_path}skills_heatmap.html')\n",
    "    \n",
    "    print(f\"   üíæ Saved: {save_path}skills_heatmap.html\")\n",
    "    print(f\"\\n   üìä Top 5 skills:\")\n",
    "    for i, (skill, count) in enumerate(top_skills[:5], 1):\n",
    "        print(f\"      {i}. {skill}: {count:,} companies\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate skills heatmap\n",
    "skills_fig = create_skills_heatmap(companies_df)\n",
    "\n",
    "print(\"\\n‚úÖ Skills heatmap complete!\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 6.6: Summary Dashboard\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n6Ô∏è‚É£  CREATING SUMMARY DASHBOARD\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def create_summary_dashboard(candidates_df, companies_df, \n",
    "                             all_matches, similarity_matrix,\n",
    "                             fairness, coverage_pct,\n",
    "                             save_path='../visualizations/'):\n",
    "    \"\"\"\n",
    "    Create a comprehensive summary dashboard.\n",
    "    \n",
    "    Single HTML with all key metrics and visualizations.\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä Building summary dashboard...\")\n",
    "    \n",
    "    from plotly.subplots import make_subplots\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'System Metrics',\n",
    "            'Match Score Distribution',\n",
    "            'Coverage by Threshold',\n",
    "            'Top Skills Distribution'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{'type': 'indicator'}, {'type': 'histogram'}],\n",
    "            [{'type': 'scatter'}, {'type': 'bar'}]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 1. Metrics indicators\n",
    "    fig.add_trace(\n",
    "        go.Indicator(\n",
    "            mode=\"number+delta\",\n",
    "            value=fairness,\n",
    "            title={'text': \"Bilateral Fairness\"},\n",
    "            delta={'reference': 0.85},\n",
    "            domain={'x': [0, 1], 'y': [0, 1]}\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Score distribution\n",
    "    all_scores = [score for matches in all_matches for _, score in matches]\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=all_scores, nbinsx=30, name='Scores'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Coverage analysis\n",
    "    thresholds = np.arange(0.3, 0.9, 0.05)\n",
    "    coverages = []\n",
    "    for t in thresholds:\n",
    "        cov = (similarity_matrix.max(axis=1) > t).sum() / len(candidates_df)\n",
    "        coverages.append(cov)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=thresholds, y=coverages, mode='lines+markers', name='Coverage'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Top skills (if available)\n",
    "    if 'enriched_skills' in companies_df.columns:\n",
    "        all_skills = []\n",
    "        for s in companies_df['enriched_skills']:\n",
    "            if s != 'Not specified':\n",
    "                all_skills.extend(s.split(', '))\n",
    "        \n",
    "        from collections import Counter\n",
    "        top_skills = Counter(all_skills).most_common(10)\n",
    "        \n",
    "        if top_skills:\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=[s[1] for s in top_skills],\n",
    "                    y=[s[0] for s in top_skills],\n",
    "                    orientation='h',\n",
    "                    name='Skills'\n",
    "                ),\n",
    "                row=2, col=2\n",
    "            )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text='HRHUB v4.0 - System Dashboard',\n",
    "        showlegend=False,\n",
    "        height=800,\n",
    "        width=1400,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    # Save\n",
    "    fig.write_html(f'{save_path}dashboard.html')\n",
    "    \n",
    "    print(f\"   üíæ Saved: {save_path}dashboard.html\")\n",
    "    print(f\"   üìä Dashboard includes:\")\n",
    "    print(f\"      ‚Ä¢ System metrics\")\n",
    "    print(f\"      ‚Ä¢ Score distribution\")\n",
    "    print(f\"      ‚Ä¢ Coverage analysis\")\n",
    "    print(f\"      ‚Ä¢ Skills distribution\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate dashboard\n",
    "dashboard_fig = create_summary_dashboard(\n",
    "    candidates_df,\n",
    "    companies_df,\n",
    "    all_matches,\n",
    "    similarity_matrix,\n",
    "    fairness,\n",
    "    coverage_pct\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Summary dashboard complete!\")\n",
    "\n",
    "# ============================================================================\n",
    "# BATCH 6 COMPLETE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ BATCH 6 COMPLETE - ALL VISUALIZATIONS GENERATED!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìÇ Generated files in {config.VIZ_PATH}:\")\n",
    "print(\"   ‚úÖ tsne_embedding_space.html\")\n",
    "print(\"   ‚úÖ score_distribution.html\")\n",
    "print(\"   ‚úÖ bilateral_fairness.html\")\n",
    "print(\"   ‚úÖ network_graph.html\")\n",
    "print(\"   ‚úÖ skills_heatmap.html\")\n",
    "print(\"   ‚úÖ dashboard.html\")\n",
    "\n",
    "print(\"\\nüí° Use these visualizations in your academic report!\")\n",
    "print(\"   ‚Ä¢ t-SNE: Shows semantic space and vocabulary bridge effect\")\n",
    "print(\"   ‚Ä¢ Network: Interactive match visualization\")\n",
    "print(\"   ‚Ä¢ Fairness: Bilateral balance validation\")\n",
    "print(\"   ‚Ä¢ Heatmap: Skills distribution analysis\")\n",
    "print(\"   ‚Ä¢ Dashboard: Complete system overview\")\n",
    "\n",
    "print(\"\\nüöÄ Ready for academic report!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üß™ SECTION 7: Synthetic Test Validation\n",
    "---\n",
    "\n",
    "**Purpose:** Test methods on cases where we KNOW the correct answer.\n",
    "\n",
    "**Why synthetic tests?**\n",
    "- No labeled ground truth exists in real data\n",
    "- We can create test cases with known correct/incorrect matches\n",
    "- Proves methods work as expected\n",
    "## Cell 7.1: Synthetic Test Implementation\n",
    "\n",
    "**What it does:** Creates test cases and validates each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üß™ SYNTHETIC VALIDATION - CONTROLLED TEST CASES\n",
      "================================================================================\n",
      "\n",
      "1Ô∏è‚É£  CREATING SYNTHETIC TEST CASES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚úÖ Created 5 synthetic test cases:\n",
      "   1. Python ML Developer\n",
      "   2. Marketing Manager\n",
      "   3. Healthcare Nurse\n",
      "   4. Data Scientist\n",
      "   5. Frontend Developer\n",
      "\n",
      "Each test case includes:\n",
      "   ‚Ä¢ Candidate description\n",
      "   ‚Ä¢ CORRECT company match (should score HIGH)\n",
      "   ‚Ä¢ WRONG company match (should score LOW)\n",
      "\n",
      "2Ô∏è‚É£  DEFINING EVALUATION FUNCTION\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ Evaluation function ready!\n",
      "\n",
      "3Ô∏è‚É£  RUNNING ALL METHODS ON SYNTHETIC TESTS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "üü¢ METHOD 1: SBERT (Semantic Embeddings)\n",
      "================================================================================\n",
      "\n",
      "üî¨ Testing SBERT...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SBERTMatcher' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 202\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müü¢ METHOD 1: SBERT (Semantic Embeddings)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    201\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m sbert_results = \u001b[43mevaluate_method_on_synthetic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSBERT\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m all_results[\u001b[33m'\u001b[39m\u001b[33mSBERT\u001b[39m\u001b[33m'\u001b[39m] = sbert_results\n\u001b[32m    205\u001b[39m \u001b[38;5;66;03m# Test TF-IDF (baseline 1)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 103\u001b[39m, in \u001b[36mevaluate_method_on_synthetic\u001b[39m\u001b[34m(method_name, test_cases)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# Initialize method\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method_name == \u001b[33m'\u001b[39m\u001b[33mSBERT\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    102\u001b[39m     \u001b[38;5;66;03m# Use existing SBERTMatcher class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     matcher = \u001b[43mSBERTMatcher\u001b[49m(config.EMBEDDING_MODEL)\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method_name == \u001b[33m'\u001b[39m\u001b[33mTF-IDF\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    106\u001b[39m     \u001b[38;5;66;03m# Use existing TFIDFMatcher class\u001b[39;00m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n",
      "\u001b[31mNameError\u001b[39m: name 'SBERTMatcher' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 7.5: SYNTHETIC VALIDATION\n",
    "# ============================================================================\n",
    "# Purpose: Test matching methods on controlled cases with known correct answers\n",
    "# Academic Value: Proves methods work on ground truth data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üß™ SYNTHETIC VALIDATION - CONTROLLED TEST CASES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 7.5.1: Create Synthetic Test Cases\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£  CREATING SYNTHETIC TEST CASES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def create_synthetic_test_cases():\n",
    "    \"\"\"\n",
    "    Create test cases where correct answer is KNOWN.\n",
    "    \n",
    "    Each test case has:\n",
    "    - Candidate text\n",
    "    - CORRECT company (should rank high)\n",
    "    - WRONG company (should rank low)\n",
    "    \n",
    "    If method is good: score(correct) > score(wrong)\n",
    "    \"\"\"\n",
    "    test_cases = [\n",
    "        {\n",
    "            'name': 'Python ML Developer',\n",
    "            'candidate': 'Python developer with machine learning experience. TensorFlow, PyTorch, data science skills.',\n",
    "            'correct_company': 'AI startup looking for Python ML engineer. TensorFlow and PyTorch required for deep learning projects.',\n",
    "            'wrong_company': 'Accounting firm needs senior accountant for tax preparation and financial auditing.'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Marketing Manager',\n",
    "            'candidate': 'Marketing manager with social media expertise. Brand development, digital campaigns, content strategy.',\n",
    "            'correct_company': 'Digital agency hiring marketing manager for social media campaigns and brand strategy.',\n",
    "            'wrong_company': 'Software company needs backend engineer. Java, Spring Boot, microservices architecture.'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Healthcare Nurse',\n",
    "            'candidate': 'Registered nurse with ICU experience. Emergency medicine, patient care, critical care certified.',\n",
    "            'correct_company': 'Hospital hiring RN for intensive care unit. Emergency medicine experience required.',\n",
    "            'wrong_company': 'Construction company needs civil engineer for infrastructure projects and site management.'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Data Scientist',\n",
    "            'candidate': 'Data scientist specializing in NLP and deep learning. Python, SQL, AWS experience.',\n",
    "            'correct_company': 'Tech company seeking data scientist for NLP projects. Python, deep learning, cloud experience needed.',\n",
    "            'wrong_company': 'Restaurant chain hiring head chef. Culinary expertise and kitchen management required.'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Frontend Developer',\n",
    "            'candidate': 'Frontend developer expert in React and JavaScript. UI/UX design, responsive web development.',\n",
    "            'correct_company': 'Startup needs frontend developer. React, JavaScript, modern web frameworks essential.',\n",
    "            'wrong_company': 'Law firm hiring paralegal for legal research and document preparation.'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return test_cases\n",
    "\n",
    "# Create test cases\n",
    "test_cases = create_synthetic_test_cases()\n",
    "\n",
    "print(f\"\\n‚úÖ Created {len(test_cases)} synthetic test cases:\")\n",
    "for i, test in enumerate(test_cases, 1):\n",
    "    print(f\"   {i}. {test['name']}\")\n",
    "\n",
    "print(\"\\nEach test case includes:\")\n",
    "print(\"   ‚Ä¢ Candidate description\")\n",
    "print(\"   ‚Ä¢ CORRECT company match (should score HIGH)\")\n",
    "print(\"   ‚Ä¢ WRONG company match (should score LOW)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 7.5.2: Evaluation Function\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£  DEFINING EVALUATION FUNCTION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def evaluate_method_on_synthetic(method_name: str, test_cases: list) -> dict:\n",
    "    \"\"\"\n",
    "    Test if method correctly ranks CORRECT > WRONG.\n",
    "    \n",
    "    Args:\n",
    "        method_name: 'SBERT', 'TF-IDF', or 'Jaccard'\n",
    "        test_cases: List of test case dicts\n",
    "    \n",
    "    Returns:\n",
    "        Dict with accuracy and detailed results\n",
    "    \"\"\"\n",
    "    print(f\"\\nüî¨ Testing {method_name}...\")\n",
    "    \n",
    "    correct_rankings = 0\n",
    "    results = []\n",
    "    \n",
    "    # Initialize method\n",
    "    if method_name == 'SBERT':\n",
    "        # Use existing SBERTMatcher class\n",
    "        matcher = SBERTMatcher(config.EMBEDDING_MODEL)\n",
    "    \n",
    "    elif method_name == 'TF-IDF':\n",
    "        # Use existing TFIDFMatcher class\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
    "    \n",
    "    elif method_name == 'Jaccard':\n",
    "        # Simple keyword overlap\n",
    "        pass\n",
    "    \n",
    "    # Test each case\n",
    "    for i, test in enumerate(test_cases):\n",
    "        cand_text = test['candidate']\n",
    "        correct_text = test['correct_company']\n",
    "        wrong_text = test['wrong_company']\n",
    "        \n",
    "        # Compute similarities\n",
    "        if method_name == 'SBERT':\n",
    "            # Embed texts\n",
    "            cand_emb = matcher.embed([cand_text], show_progress=False)\n",
    "            correct_emb = matcher.embed([correct_text], show_progress=False)\n",
    "            wrong_emb = matcher.embed([wrong_text], show_progress=False)\n",
    "            \n",
    "            # Compute scores\n",
    "            score_correct = cosine_similarity(cand_emb, correct_emb)[0][0]\n",
    "            score_wrong = cosine_similarity(cand_emb, wrong_emb)[0][0]\n",
    "        \n",
    "        elif method_name == 'TF-IDF':\n",
    "            # Vectorize\n",
    "            vectors = vectorizer.fit_transform([cand_text, correct_text, wrong_text])\n",
    "            \n",
    "            # Compute scores\n",
    "            score_correct = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
    "            score_wrong = cosine_similarity(vectors[0:1], vectors[2:3])[0][0]\n",
    "        \n",
    "        elif method_name == 'Jaccard':\n",
    "            # Simple keyword overlap\n",
    "            def get_keywords(text):\n",
    "                return set(text.lower().split())\n",
    "            \n",
    "            def jaccard(set1, set2):\n",
    "                intersection = len(set1 & set2)\n",
    "                union = len(set1 | set2)\n",
    "                return intersection / union if union > 0 else 0\n",
    "            \n",
    "            cand_kw = get_keywords(cand_text)\n",
    "            correct_kw = get_keywords(correct_text)\n",
    "            wrong_kw = get_keywords(wrong_text)\n",
    "            \n",
    "            score_correct = jaccard(cand_kw, correct_kw)\n",
    "            score_wrong = jaccard(cand_kw, wrong_kw)\n",
    "        \n",
    "        # Check if correct ranked higher\n",
    "        is_correct = score_correct > score_wrong\n",
    "        if is_correct:\n",
    "            correct_rankings += 1\n",
    "            status = \"‚úÖ\"\n",
    "        else:\n",
    "            status = \"‚ùå\"\n",
    "        \n",
    "        # Store result\n",
    "        results.append({\n",
    "            'test_name': test['name'],\n",
    "            'score_correct': score_correct,\n",
    "            'score_wrong': score_wrong,\n",
    "            'margin': score_correct - score_wrong,\n",
    "            'is_correct': is_correct\n",
    "        })\n",
    "        \n",
    "        print(f\"   {status} Test {i+1}: {test['name']}\")\n",
    "        print(f\"      Correct: {score_correct:.4f} | Wrong: {score_wrong:.4f} | Margin: {score_correct - score_wrong:+.4f}\")\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_rankings / len(test_cases)\n",
    "    \n",
    "    return {\n",
    "        'method': method_name,\n",
    "        'accuracy': accuracy,\n",
    "        'correct': correct_rankings,\n",
    "        'total': len(test_cases),\n",
    "        'results': results\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Evaluation function ready!\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 7.5.3: Run All Methods\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£  RUNNING ALL METHODS ON SYNTHETIC TESTS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "# Test SBERT (our method)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üü¢ METHOD 1: SBERT (Semantic Embeddings)\")\n",
    "print(\"=\"*80)\n",
    "sbert_results = evaluate_method_on_synthetic('SBERT', test_cases)\n",
    "all_results['SBERT'] = sbert_results\n",
    "\n",
    "# Test TF-IDF (baseline 1)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üî¥ METHOD 2: TF-IDF (Keyword-based)\")\n",
    "print(\"=\"*80)\n",
    "tfidf_results = evaluate_method_on_synthetic('TF-IDF', test_cases)\n",
    "all_results['TF-IDF'] = tfidf_results\n",
    "\n",
    "# Test Jaccard (baseline 2)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üü° METHOD 3: JACCARD (Keyword Overlap)\")\n",
    "print(\"=\"*80)\n",
    "jaccard_results = evaluate_method_on_synthetic('Jaccard', test_cases)\n",
    "all_results['Jaccard'] = jaccard_results\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 7.5.4: Comparison Results\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä SYNTHETIC VALIDATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comparison table\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(f\"{'Method':<20} {'Correct':<10} {'Total':<10} {'Accuracy':<15} {'Status'}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for method_name, result in all_results.items():\n",
    "    accuracy = result['accuracy']\n",
    "    correct = result['correct']\n",
    "    total = result['total']\n",
    "    \n",
    "    if accuracy >= 0.8:\n",
    "        status = \"‚úÖ Excellent\"\n",
    "    elif accuracy >= 0.6:\n",
    "        status = \"üü° Good\"\n",
    "    else:\n",
    "        status = \"üî¥ Poor\"\n",
    "    \n",
    "    print(f\"{method_name:<20} {correct:<10} {total:<10} {accuracy*100:<14.1f}% {status}\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Detailed analysis\n",
    "print(\"\\nüìà DETAILED ANALYSIS:\")\n",
    "\n",
    "for method_name, result in all_results.items():\n",
    "    print(f\"\\n{method_name}:\")\n",
    "    \n",
    "    # Average margin\n",
    "    margins = [r['margin'] for r in result['results']]\n",
    "    avg_margin = np.mean(margins)\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Accuracy: {result['accuracy']*100:.1f}%\")\n",
    "    print(f\"   ‚Ä¢ Average margin: {avg_margin:+.4f}\")\n",
    "    print(f\"   ‚Ä¢ Failed cases: {result['total'] - result['correct']}\")\n",
    "    \n",
    "    # Show failed cases if any\n",
    "    failed = [r for r in result['results'] if not r['is_correct']]\n",
    "    if failed:\n",
    "        print(f\"   ‚Ä¢ Failed on:\")\n",
    "        for f in failed:\n",
    "            print(f\"      - {f['test_name']}: correct={f['score_correct']:.3f}, wrong={f['score_wrong']:.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 7.5.5: Save Results\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£  SAVING SYNTHETIC VALIDATION RESULTS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Save to JSON\n",
    "synthetic_results = {\n",
    "    'test_cases': len(test_cases),\n",
    "    'methods_tested': list(all_results.keys()),\n",
    "    'results': {\n",
    "        method: {\n",
    "            'accuracy': result['accuracy'],\n",
    "            'correct': result['correct'],\n",
    "            'total': result['total']\n",
    "        }\n",
    "        for method, result in all_results.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{config.RESULTS_PATH}synthetic_validation.json', 'w') as f:\n",
    "    json.dump(synthetic_results, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Saved: {config.RESULTS_PATH}synthetic_validation.json\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ SYNTHETIC VALIDATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n‚úÖ Key Findings:\")\n",
    "print(f\"   ‚Ä¢ SBERT accuracy: {all_results['SBERT']['accuracy']*100:.1f}%\")\n",
    "print(f\"   ‚Ä¢ TF-IDF accuracy: {all_results['TF-IDF']['accuracy']*100:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Jaccard accuracy: {all_results['Jaccard']['accuracy']*100:.1f}%\")\n",
    "\n",
    "winner = max(all_results.keys(), key=lambda k: all_results[k]['accuracy'])\n",
    "print(f\"\\nüèÜ Best method: {winner} ({all_results[winner]['accuracy']*100:.1f}% accuracy)\")\n",
    "\n",
    "print(\"\\nüí° Academic Value:\")\n",
    "print(\"   ‚Ä¢ Proves methods work on ground truth data\")\n",
    "print(\"   ‚Ä¢ Validates semantic approach superiority\")\n",
    "print(\"   ‚Ä¢ Provides quantitative comparison\")\n",
    "print(\"   ‚Ä¢ Essential for thesis evaluation chapter\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üë§ MANUAL VALIDATION - HUMAN EVALUATION\n",
      "================================================================================\n",
      "‚úÖ Manual validation function ready!\n",
      "\n",
      "================================================================================\n",
      "üöÄ READY TO START MANUAL VALIDATION\n",
      "================================================================================\n",
      "\n",
      "üí° This is OPTIONAL but valuable for your thesis!\n",
      "\n",
      "Benefits:\n",
      "   ‚Ä¢ Shows human-AI agreement\n",
      "   ‚Ä¢ Validates system quality\n",
      "   ‚Ä¢ Provides qualitative insights\n",
      "   ‚Ä¢ Takes ~10-15 minutes for 20 samples\n",
      "\n",
      "================================================================================\n",
      "üîç MANUAL VALIDATION - SBERT Method\n",
      "================================================================================\n",
      "\n",
      "You will rate 20 matches on a scale of 1-5:\n",
      "   1 = ‚ùå Bad match (completely irrelevant)\n",
      "   2 = üü° Poor match (somewhat relevant)\n",
      "   3 = üü¢ OK match (moderately relevant)\n",
      "   4 = ‚úÖ Good match (very relevant)\n",
      "   5 = üåü Perfect match (ideal fit)\n",
      "\n",
      "================================================================================\n",
      "MATCH 1/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #1824:\n",
      "   Career: Skilled Machine Learning and Deep Learning practitioner, and I have worked on Computer vision-based projects. On the lookout for opportunities that help me understand more about the domain.\n",
      "   Skills: ['Machine Learning', 'Deep Learning', 'Computer Vision', 'Pattern Recognition', 'Image Processing', 'Image Segmentation', 'Python', 'Ruby', 'PILLOW', \n",
      "\n",
      "üè¢ COMPANY #21571:\n",
      "   Description: Professional Technical Team that specializes in the placement of permanent or contract personnel in the technical, analytical and marketing areas of: Information Systems.\n",
      "\n",
      "‚Ä¢ Data Scientist, Python, Di\n",
      "   Required Skills: ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.5726\n",
      "   üåü Recorded: 5/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 2/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #409:\n",
      "   Career: nan\n",
      "   Skills: ['Machine Learning', 'Software Development', 'Text Analysis', 'Natural Language Processing', 'Image Processing', 'Python', 'Data Management', 'Scikit \n",
      "\n",
      "üè¢ COMPANY #21571:\n",
      "   Description: Professional Technical Team that specializes in the placement of permanent or contract personnel in the technical, analytical and marketing areas of: Information Systems.\n",
      "\n",
      "‚Ä¢ Data Scientist, Python, Di\n",
      "   Required Skills: ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.6309\n",
      "   ‚úÖ Recorded: 4/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 3/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #4506:\n",
      "   Career: nan\n",
      "   Skills: ['Econometrics', 'Problem Solving', 'Data Analytics', 'Data Modeling', 'Data Validation', 'Data Reporting', 'Business Intelligence', 'Data Manipulatio\n",
      "\n",
      "üè¢ COMPANY #21571:\n",
      "   Description: Professional Technical Team that specializes in the placement of permanent or contract personnel in the technical, analytical and marketing areas of: Information Systems.\n",
      "\n",
      "‚Ä¢ Data Scientist, Python, Di\n",
      "   Required Skills: ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.6280\n",
      "   üü¢ Recorded: 3/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 4/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #4012:\n",
      "   Career: An avid data analyst looking to step into the world of machine learning and data sciences. I have experience related to Data Mining, Data Visualization, Text Analytics, Data Collection and would curre\n",
      "   Skills: ['Data Analyst', 'Data Mining', 'Data Visualization', 'Text Analytics', 'Data Collection', 'Data Cleaning', 'Business Analysis', 'Python', 'SQL', 'Goo\n",
      "\n",
      "üè¢ COMPANY #21391:\n",
      "   Description: Atek IT - A Leading Edge for Software Development and IT Innovations.\n",
      "Always looking for people with strong willingness to work within a fast paced environment.\n",
      "\n",
      "We Recruit for:\n",
      "‚Ä¢ Analytical Positions\n",
      "   Required Skills: IT\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.5879\n",
      "   üü° Recorded: 2/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 5/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #3657:\n",
      "   Career: nan\n",
      "   Skills: ['Adobe', 'Customer Relations', 'Document reports', 'Budgeting', 'Cross-functional Team Leadership', 'Business Analysis', 'Access', 'Microsoft Project\n",
      "\n",
      "üè¢ COMPANY #21571:\n",
      "   Description: Professional Technical Team that specializes in the placement of permanent or contract personnel in the technical, analytical and marketing areas of: Information Systems.\n",
      "\n",
      "‚Ä¢ Data Scientist, Python, Di\n",
      "   Required Skills: ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.6869\n",
      "   ‚ùå Recorded: 1/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 6/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #2286:\n",
      "   Career: nan\n",
      "   Skills: ['accounting', 'Accountant', 'Arabic', 'Balance Sheet', 'bank reconciliations', 'com', 'resolve customer complaints', 'Customer Service', 'databases',\n",
      "\n",
      "üè¢ COMPANY #19247:\n",
      "   Description: nan\n",
      "   Required Skills: ACCT, ADM, FIN\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.5978\n",
      "   üåü Recorded: 5/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 7/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #1679:\n",
      "   Career: nan\n",
      "   Skills: ['Machine Learning Engineer', 'Data Processing', 'Data Modelling', 'Data Structures', 'Deep Learning', 'Application Development', 'Python', 'Django', \n",
      "\n",
      "üè¢ COMPANY #21571:\n",
      "   Description: Professional Technical Team that specializes in the placement of permanent or contract personnel in the technical, analytical and marketing areas of: Information Systems.\n",
      "\n",
      "‚Ä¢ Data Scientist, Python, Di\n",
      "   Required Skills: ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.6264\n",
      "   ‚úÖ Recorded: 4/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 8/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #8935:\n",
      "   Career: Computer Repair Technician\n",
      "   Skills: ['iFixit Pro Tech Toolkit', 'PassMark MemTest86', 'Malwarebytes', 'Recuva', 'Ultimate Boot CD (UBCD)', 'Windows Installation USB/DVD', 'TeamViewer', '\n",
      "\n",
      "üè¢ COMPANY #21571:\n",
      "   Description: Professional Technical Team that specializes in the placement of permanent or contract personnel in the technical, analytical and marketing areas of: Information Systems.\n",
      "\n",
      "‚Ä¢ Data Scientist, Python, Di\n",
      "   Required Skills: ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.5950\n",
      "   üü¢ Recorded: 3/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 9/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #1424:\n",
      "   Career: nan\n",
      "   Skills: ['Microsoft Project', 'Microsoft Office', 'Microsoft Visio', 'IBM Rationale DOORS', 'Communication/Presentations', 'Risk Analysis', 'Process Improveme\n",
      "\n",
      "üè¢ COMPANY #4337:\n",
      "   Description: A national Executive Recruiting, Talent Acquisition and Placement firm. We recruit and place engineers, operations, accounting, finance, sales, manufacturing, human resources, purchasing, and other ex\n",
      "   Required Skills: ENG, MGMT, MNFC, PRJM, PROD\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.5747\n",
      "   üü° Recorded: 2/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 10/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #6912:\n",
      "   Career: nan\n",
      "   Skills: ['Data Analytics', 'Artificial Intelligence', 'Data Visualization', 'Machine Learning', 'Python', 'Data Wrangling', 'Featurization', 'Heuristics', 'Da\n",
      "\n",
      "üè¢ COMPANY #21571:\n",
      "   Description: Professional Technical Team that specializes in the placement of permanent or contract personnel in the technical, analytical and marketing areas of: Information Systems.\n",
      "\n",
      "‚Ä¢ Data Scientist, Python, Di\n",
      "   Required Skills: ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.6363\n",
      "   ‚ùå Recorded: 1/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 11/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #520:\n",
      "   Career: nan\n",
      "   Skills: ['Organizational and planning skills', 'Customer Service', 'IT skills (Shopper, Tally, Voyager)', 'Creativity and imagination', 'Business and commerci\n",
      "\n",
      "üè¢ COMPANY #21571:\n",
      "   Description: Professional Technical Team that specializes in the placement of permanent or contract personnel in the technical, analytical and marketing areas of: Information Systems.\n",
      "\n",
      "‚Ä¢ Data Scientist, Python, Di\n",
      "   Required Skills: ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.6367\n",
      "   üåü Recorded: 5/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 12/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #488:\n",
      "   Career: nan\n",
      "   Skills: ['Machine Learning', 'Natural Language Processing', 'Deep Learning', 'Sentiment Analysis', 'Python', 'NLTK', 'BeRT', 'GPT', 'XLNet', 'Text Analysis', \n",
      "\n",
      "üè¢ COMPANY #21571:\n",
      "   Description: Professional Technical Team that specializes in the placement of permanent or contract personnel in the technical, analytical and marketing areas of: Information Systems.\n",
      "\n",
      "‚Ä¢ Data Scientist, Python, Di\n",
      "   Required Skills: ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.6047\n",
      "   ‚úÖ Recorded: 4/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 13/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #1535:\n",
      "   Career: nan\n",
      "   Skills: ['Web Developer', 'Data Analyst', 'Web Development', 'Machine Learning', 'Python', 'FrontEnd', 'HTML', 'Javascript', 'PHP', 'CSS', 'MySQL', 'Java', 'D\n",
      "\n",
      "üè¢ COMPANY #21571:\n",
      "   Description: Professional Technical Team that specializes in the placement of permanent or contract personnel in the technical, analytical and marketing areas of: Information Systems.\n",
      "\n",
      "‚Ä¢ Data Scientist, Python, Di\n",
      "   Required Skills: ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.6314\n",
      "   üü¢ Recorded: 3/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 14/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #3582:\n",
      "   Career: Graduate database management engineer looking to join a role in data analytics or cloud-based machine learning solutions.\n",
      "   Skills: ['Software Development', 'Data Science', 'Data Analysis', 'Data Structure', 'Business Analytics', 'Java', 'Powerbi', 'Tableau', 'SQL', 'DBMS', 'RDBMS'\n",
      "\n",
      "üè¢ COMPANY #8494:\n",
      "   Description: Princeton IT Services, Inc. has been trusted for more than 20 years by top IT professionals in some of the largest companies in the world as Technology Consultants specializing in Data Analytics, Data\n",
      "   Required Skills: ENG, IT\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.6894\n",
      "   üü° Recorded: 2/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 15/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #3811:\n",
      "   Career: nan\n",
      "   Skills: ['automotive', 'basic', 'broadcast', 'cables', 'cable', 'cabling', 'carpentry', 'chill', 'CA', 'conversion', 'Council', 'SC', 'Direction', 'documentat\n",
      "\n",
      "üè¢ COMPANY #19823:\n",
      "   Description: Topa Group connects talent with electronic integrators, electrical contractors,  and fire protection companies. Our recruiters are industry and geographically specific. Full time, direct hires. \n",
      "\n",
      "AV I\n",
      "   Required Skills: DSGN, ENG, IT, OTHR, PRJM, QA\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.5891\n",
      "   ‚ùå Recorded: 1/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 16/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #8279:\n",
      "   Career: Financial Accountant specializing in financial planning, reporting and analysis within the Department of Defense.\n",
      "   Skills: ['Account reconciliations', 'Results-oriented', 'Financial reporting', 'Critical thinking', 'Accounting operations professional', 'Analysis of financi\n",
      "\n",
      "üè¢ COMPANY #22986:\n",
      "   Description: Audit Friendly helps business decision makers find the most reputable software tools, accounting firms and recruiting agencies in the finance and accounting world. \n",
      "\n",
      "For Accounting and Finance Jobs: c\n",
      "   Required Skills: ACCT, FIN\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.6506\n",
      "   üåü Recorded: 5/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 17/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #434:\n",
      "   Career: nan\n",
      "   Skills: ['Data Science', 'Data Analytics', 'Database Management', 'Data Analysis', 'Data Mining', 'Data Modelling', 'Data Integration', 'Machine Learning', 'S\n",
      "\n",
      "üè¢ COMPANY #21571:\n",
      "   Description: Professional Technical Team that specializes in the placement of permanent or contract personnel in the technical, analytical and marketing areas of: Information Systems.\n",
      "\n",
      "‚Ä¢ Data Scientist, Python, Di\n",
      "   Required Skills: ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.6422\n",
      "   üåü Recorded: 5/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 18/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #9195:\n",
      "   Career: nan\n",
      "   Skills: ['accounts receivable', 'AIA', 'bank reconciliation', 'billing', 'billings', 'budgets', 'daily cash receipts', 'cash flow', 'Consultant', 'Contracts',\n",
      "\n",
      "üè¢ COMPANY #17624:\n",
      "   Description: Focus Search LLC is a Direct Hire and Contract placement agency, specializing in the fields of Accounting, Finance and Technology\n",
      "\n",
      "www.focus-search.com\n",
      "\n",
      "Industries served: CPA firms, Professional/Fina\n",
      "   Required Skills: ACCT, HR\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.5776\n",
      "   üü¢ Recorded: 3/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 19/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #3257:\n",
      "   Career: nan\n",
      "   Skills: ['Program Management', 'Portfolio Management', 'Process Analysis', 'Solution Design', 'Enterprise Software', 'Systems Integration', 'Data Management',\n",
      "\n",
      "üè¢ COMPANY #21571:\n",
      "   Description: Professional Technical Team that specializes in the placement of permanent or contract personnel in the technical, analytical and marketing areas of: Information Systems.\n",
      "\n",
      "‚Ä¢ Data Scientist, Python, Di\n",
      "   Required Skills: ACCT, BD, ENG, FIN, IT, MGMT, MNFC, OTHR, SALE\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.6272\n",
      "   üü¢ Recorded: 3/5\n",
      "\n",
      "================================================================================\n",
      "MATCH 20/20\n",
      "================================================================================\n",
      "\n",
      "üë§ CANDIDATE #8928:\n",
      "   Career: Flexible, autonomous graduate with an MS in Computer Science looking to leverage experience building responsive and scalable web apps to solve problems that delight end-users. Motivated to learn from \n",
      "   Skills: []\n",
      "\n",
      "üè¢ COMPANY #6594:\n",
      "   Description: Global design and BIM software leader serving 650,000+ professionals in the architecture, landscape and entertainment industries. Since 1985, we‚Äôve been committed to helping designers capture inspirat\n",
      "   Required Skills: IT\n",
      "\n",
      "ü§ñ SYSTEM SCORE: 0.6014\n",
      "   üü° Recorded: 2/5\n",
      "\n",
      "================================================================================\n",
      "üìä VALIDATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "üìà Statistics:\n",
      "   ‚Ä¢ Samples validated: 20\n",
      "   ‚Ä¢ Mean human rating: 3.15/5 (‚≠ê‚≠ê‚≠ê)\n",
      "   ‚Ä¢ Std deviation: 1.42\n",
      "   ‚Ä¢ Mean system score: 0.6193\n",
      "\n",
      "üìä Rating Distribution:\n",
      "   ‚ùå 1 stars:   3 ( 15.0%) ‚ñà‚ñà‚ñà\n",
      "   üü° 2 stars:   4 ( 20.0%) ‚ñà‚ñà‚ñà‚ñà\n",
      "   üü¢ 3 stars:   5 ( 25.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   ‚úÖ 4 stars:   3 ( 15.0%) ‚ñà‚ñà‚ñà\n",
      "   üåü 5 stars:   5 ( 25.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "üîó Correlation Analysis:\n",
      "   ‚Ä¢ Pearson correlation: -0.081\n",
      "   ‚Ä¢ Interpretation: üî¥ Poor correlation\n",
      "   ‚Ä¢ Meaning: System scores somewhat align with human judgment\n",
      "\n",
      "ü§ù Agreement (Good vs Not Good):\n",
      "   ‚Ä¢ Agreement rate: 50.0%\n",
      "\n",
      "‚ö†Ô∏è  Disagreements (10):\n",
      "   ‚Ä¢ Candidate 1824 ‚Üí Company 21571\n",
      "     System: 0.573, Human: 5/5\n",
      "   ‚Ä¢ Candidate 4506 ‚Üí Company 21571\n",
      "     System: 0.628, Human: 3/5\n",
      "   ‚Ä¢ Candidate 3657 ‚Üí Company 21571\n",
      "     System: 0.687, Human: 1/5\n",
      "\n",
      "üíæ Saved: ../results/manual_validation.csv\n",
      "üíæ Saved: ../results/validation_summary.json\n",
      "\n",
      "================================================================================\n",
      "‚úÖ MANUAL VALIDATION COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "üìä Use these results in your thesis:\n",
      "   ‚Ä¢ Include correlation coefficient\n",
      "   ‚Ä¢ Show rating distribution chart\n",
      "   ‚Ä¢ Discuss human-AI agreement\n",
      "   ‚Ä¢ Cite mean rating as quality metric\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 7.6: MANUAL VALIDATION\n",
    "# ============================================================================\n",
    "# Purpose: Human evaluation of match quality\n",
    "# Method: Sample random matches and rate relevance 1-5\n",
    "# Academic Value: Human-AI agreement analysis\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üë§ MANUAL VALIDATION - HUMAN EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import random\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 7.6.1: Manual Validation Function\n",
    "# ============================================================================\n",
    "\n",
    "def validate_matches_manual(candidates_df, companies_df, all_matches, \n",
    "                           candidate_texts, company_texts,\n",
    "                           n_samples=20, random_seed=42):\n",
    "    \"\"\"\n",
    "    Sample random matches and get human ratings.\n",
    "    \n",
    "    Shows:\n",
    "    - Candidate info (career, skills)\n",
    "    - Company info (description, skills)\n",
    "    - System score\n",
    "    \n",
    "    Asks:\n",
    "    - Human rating (1-5 stars)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with validation results\n",
    "    - Correlation between system score and human rating\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Number of matches to validate\n",
    "        random_seed: For reproducibility\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üîç MANUAL VALIDATION - SBERT Method\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nYou will rate {n_samples} matches on a scale of 1-5:\")\n",
    "    print(\"   1 = ‚ùå Bad match (completely irrelevant)\")\n",
    "    print(\"   2 = üü° Poor match (somewhat relevant)\")\n",
    "    print(\"   3 = üü¢ OK match (moderately relevant)\")\n",
    "    print(\"   4 = ‚úÖ Good match (very relevant)\")\n",
    "    print(\"   5 = üåü Perfect match (ideal fit)\")\n",
    "    \n",
    "    input(\"\\nPress Enter to start validation...\")\n",
    "    \n",
    "    # Sample random candidates\n",
    "    random.seed(random_seed)\n",
    "    n_candidates = len(candidates_df)\n",
    "    sample_indices = random.sample(range(n_candidates), min(n_samples, n_candidates))\n",
    "    \n",
    "    validation_results = []\n",
    "    \n",
    "    for i, cand_idx in enumerate(sample_indices, 1):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"MATCH {i}/{len(sample_indices)}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Get candidate info\n",
    "        cand = candidates_df.iloc[cand_idx]\n",
    "        cand_career = str(cand.get('career_objective', 'N/A'))[:200]\n",
    "        cand_skills = str(cand.get('skills', []))[:150]\n",
    "        \n",
    "        # Get top match for this candidate\n",
    "        comp_idx, score = all_matches[cand_idx][0]  # Best match\n",
    "        \n",
    "        # Get company info\n",
    "        comp = companies_df.iloc[comp_idx]\n",
    "        comp_desc = str(comp.get('description', 'N/A'))[:200]\n",
    "        comp_skills = str(comp.get('enriched_skills', 'N/A'))[:150]\n",
    "        \n",
    "        # Display match\n",
    "        print(f\"\\nüë§ CANDIDATE #{cand_idx}:\")\n",
    "        print(f\"   Career: {cand_career}\")\n",
    "        print(f\"   Skills: {cand_skills}\")\n",
    "        \n",
    "        print(f\"\\nüè¢ COMPANY #{comp_idx}:\")\n",
    "        print(f\"   Description: {comp_desc}\")\n",
    "        print(f\"   Required Skills: {comp_skills}\")\n",
    "        \n",
    "        print(f\"\\nü§ñ SYSTEM SCORE: {score:.4f}\")\n",
    "        \n",
    "        # Get human rating\n",
    "        while True:\n",
    "            try:\n",
    "                rating_input = input(\"\\n‚≠ê Your rating (1-5, or 's' to skip): \")\n",
    "                \n",
    "                if rating_input.lower() == 's':\n",
    "                    rating = None\n",
    "                    break\n",
    "                \n",
    "                rating = int(rating_input)\n",
    "                \n",
    "                if 1 <= rating <= 5:\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"   ‚ö†Ô∏è  Please enter a number between 1 and 5\")\n",
    "            \n",
    "            except ValueError:\n",
    "                print(\"   ‚ö†Ô∏è  Please enter a valid number (1-5) or 's' to skip\")\n",
    "        \n",
    "        if rating is not None:\n",
    "            validation_results.append({\n",
    "                'candidate_idx': cand_idx,\n",
    "                'company_idx': comp_idx,\n",
    "                'system_score': score,\n",
    "                'human_rating': rating,\n",
    "                'candidate_career': cand_career[:100],\n",
    "                'company_desc': comp_desc[:100]\n",
    "            })\n",
    "            \n",
    "            # Show quick feedback\n",
    "            emoji = ['‚ùå', 'üü°', 'üü¢', '‚úÖ', 'üåü'][rating-1]\n",
    "            print(f\"   {emoji} Recorded: {rating}/5\")\n",
    "    \n",
    "    # Create validation DataFrame\n",
    "    validation_df = pd.DataFrame(validation_results)\n",
    "    \n",
    "    if len(validation_df) == 0:\n",
    "        print(\"\\n‚ö†Ô∏è  No ratings recorded. Validation cancelled.\")\n",
    "        return None\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Analysis\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìä VALIDATION RESULTS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    mean_rating = validation_df['human_rating'].mean()\n",
    "    std_rating = validation_df['human_rating'].std()\n",
    "    mean_score = validation_df['system_score'].mean()\n",
    "    \n",
    "    print(f\"\\nüìà Statistics:\")\n",
    "    print(f\"   ‚Ä¢ Samples validated: {len(validation_df)}\")\n",
    "    print(f\"   ‚Ä¢ Mean human rating: {mean_rating:.2f}/5 ({'‚≠ê' * int(round(mean_rating))})\")\n",
    "    print(f\"   ‚Ä¢ Std deviation: {std_rating:.2f}\")\n",
    "    print(f\"   ‚Ä¢ Mean system score: {mean_score:.4f}\")\n",
    "    \n",
    "    # Rating distribution\n",
    "    print(f\"\\nüìä Rating Distribution:\")\n",
    "    for rating in range(1, 6):\n",
    "        count = (validation_df['human_rating'] == rating).sum()\n",
    "        pct = (count / len(validation_df)) * 100\n",
    "        bar = '‚ñà' * int(pct / 5)\n",
    "        emoji = ['‚ùå', 'üü°', 'üü¢', '‚úÖ', 'üåü'][rating-1]\n",
    "        print(f\"   {emoji} {rating} stars: {count:>3} ({pct:>5.1f}%) {bar}\")\n",
    "    \n",
    "    # Correlation analysis\n",
    "    correlation = validation_df[['system_score', 'human_rating']].corr().iloc[0, 1]\n",
    "    \n",
    "    print(f\"\\nüîó Correlation Analysis:\")\n",
    "    print(f\"   ‚Ä¢ Pearson correlation: {correlation:.3f}\")\n",
    "    \n",
    "    if correlation > 0.7:\n",
    "        status = \"‚úÖ Strong positive correlation\"\n",
    "    elif correlation > 0.5:\n",
    "        status = \"üü¢ Moderate positive correlation\"\n",
    "    elif correlation > 0.3:\n",
    "        status = \"üü° Weak positive correlation\"\n",
    "    else:\n",
    "        status = \"üî¥ Poor correlation\"\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Interpretation: {status}\")\n",
    "    print(f\"   ‚Ä¢ Meaning: System scores {'align well' if correlation > 0.5 else 'somewhat align'} with human judgment\")\n",
    "    \n",
    "    # Agreement analysis\n",
    "    # Convert to binary: good (4-5) vs not good (1-3)\n",
    "    validation_df['human_good'] = validation_df['human_rating'] >= 4\n",
    "    validation_df['system_good'] = validation_df['system_score'] >= validation_df['system_score'].median()\n",
    "    \n",
    "    agreement = (validation_df['human_good'] == validation_df['system_good']).sum() / len(validation_df)\n",
    "    \n",
    "    print(f\"\\nü§ù Agreement (Good vs Not Good):\")\n",
    "    print(f\"   ‚Ä¢ Agreement rate: {agreement*100:.1f}%\")\n",
    "    \n",
    "    # Show disagreements\n",
    "    disagreements = validation_df[validation_df['human_good'] != validation_df['system_good']]\n",
    "    if len(disagreements) > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  Disagreements ({len(disagreements)}):\")\n",
    "        for idx, row in disagreements.head(3).iterrows():\n",
    "            print(f\"   ‚Ä¢ Candidate {row['candidate_idx']} ‚Üí Company {row['company_idx']}\")\n",
    "            print(f\"     System: {row['system_score']:.3f}, Human: {row['human_rating']}/5\")\n",
    "    \n",
    "    return validation_df\n",
    "\n",
    "print(\"‚úÖ Manual validation function ready!\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 7.6.2: Run Validation (Interactive)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ READY TO START MANUAL VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüí° This is OPTIONAL but valuable for your thesis!\")\n",
    "print(\"\\nBenefits:\")\n",
    "print(\"   ‚Ä¢ Shows human-AI agreement\")\n",
    "print(\"   ‚Ä¢ Validates system quality\")\n",
    "print(\"   ‚Ä¢ Provides qualitative insights\")\n",
    "print(\"   ‚Ä¢ Takes ~10-15 minutes for 20 samples\")\n",
    "\n",
    "run_validation = input(\"\\n‚ùì Run manual validation now? (y/n): \")\n",
    "\n",
    "if run_validation.lower() in ['y', 'yes']:\n",
    "    # Run validation\n",
    "    validation_results = validate_matches_manual(\n",
    "        candidates_df=candidates_df,\n",
    "        companies_df=companies_df,\n",
    "        all_matches=all_matches,\n",
    "        candidate_texts=candidate_texts,\n",
    "        company_texts=company_texts,\n",
    "        n_samples=20,  # Adjust if needed\n",
    "        random_seed=42\n",
    "    )\n",
    "    \n",
    "    if validation_results is not None:\n",
    "        # Save results\n",
    "        validation_results.to_csv(f'{config.RESULTS_PATH}manual_validation.csv', index=False)\n",
    "        print(f\"\\nüíæ Saved: {config.RESULTS_PATH}manual_validation.csv\")\n",
    "        \n",
    "        # Create summary for report\n",
    "        summary = {\n",
    "            'method': 'SBERT',\n",
    "            'samples_validated': len(validation_results),\n",
    "            'mean_human_rating': float(validation_results['human_rating'].mean()),\n",
    "            'mean_system_score': float(validation_results['system_score'].mean()),\n",
    "            'correlation': float(validation_results[['system_score', 'human_rating']].corr().iloc[0, 1]),\n",
    "            'ratings_distribution': validation_results['human_rating'].value_counts().to_dict()\n",
    "        }\n",
    "        \n",
    "        with open(f'{config.RESULTS_PATH}validation_summary.json', 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        print(f\"üíæ Saved: {config.RESULTS_PATH}validation_summary.json\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚úÖ MANUAL VALIDATION COMPLETE!\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"\\nüìä Use these results in your thesis:\")\n",
    "        print(\"   ‚Ä¢ Include correlation coefficient\")\n",
    "        print(\"   ‚Ä¢ Show rating distribution chart\")\n",
    "        print(\"   ‚Ä¢ Discuss human-AI agreement\")\n",
    "        print(\"   ‚Ä¢ Cite mean rating as quality metric\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚è≠Ô∏è  Skipped manual validation\")\n",
    "    print(\"üí° You can run this later if needed\")\n",
    "    validation_results = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
